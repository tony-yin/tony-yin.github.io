<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Tony&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://tony-yin.github.io/"/>
  <updated>2018-01-30T12:48:51.245Z</updated>
  <id>https://tony-yin.github.io/</id>
  
  <author>
    <name>Tony</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>实现RBD导出NFS高可用（二）：提供多虚拟IP访问</title>
    <link href="https://tony-yin.github.io/2018/01/28/RBD-HA-2/"/>
    <id>https://tony-yin.github.io/2018/01/28/RBD-HA-2/</id>
    <published>2018-01-28T05:07:06.000Z</published>
    <updated>2018-01-30T12:48:51.245Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/rbd2-600x450.jpg" alt="RBD-HA-2"></center><p>之前分享过一篇<a href="http://www.tony-yin.top/2017/12/07/RBD-HA/" target="_blank" rel="external">【通过 Keepalived 实现 Ceph RBD 的高可用】</a>，主要讲解了将<code>RBD</code>导出为<code>NFS</code>，然后通过<code>keepalived</code>实现高可用，保证当提供虚拟<code>IP</code>节点发生故障时，可以自动切换节点，使得业务不发生中断。</p><p>这样可以基本使用<code>RBD</code>代替<code>CephFS</code>对外提供<code>Ceph</code>服务，至于为什么不用<code>CephFS</code>就不多说了，不清楚的可以去看上一篇。虽然说这样可以保证无单点故障，但是有一点还是不如<code>CephFS</code>，那就是<code>CephFS</code>可以实现多节点同时提供服务，而<code>RBD</code>说白了其实同时只有一个节点能提供服务，当客户端流量高的时候，<code>RBD</code>方式的带宽并不能满足需求。就比如都是三个节点，<code>CephFS</code>可以将客户端流量分流到三个节点，而<code>RBD</code>只能用一个节点，而带宽上限又取决与网卡、磁盘和<code>IO</code>等等原因，所以同样的硬件设施<code>RBD</code>的带宽性能是跟不上的，本文就多虚拟<code>IP</code>暴露访问方式进行分享。</p><a id="more"></a><h2 id="CephFS-amp-RBD"><a href="#CephFS-amp-RBD" class="headerlink" title="CephFS &amp; RBD"></a>CephFS &amp; RBD</h2><p>此前的文章我们<code>Ceph</code>集群只有一个<code>RBD image</code>，并且只通过一个<code>vip</code>暴露这个<code>image</code>让客户端通过<code>NFS</code>访问。这与<code>CephFS</code>的差距就在没有充分利用每个节点的资源，所以我们可以大胆设想一下是否可以通过<code>RBD</code>对外提供多个<code>vip</code>，每个节点都能被<code>NFS</code>访问呢？理想很美好，现实很残酷。如果一个<code>RBD</code>对多个节点同时提供读写的话，会导致不一致的后果，现在<code>RBD</code>并不能做到<code>CephFS</code>那样多个节点同时提供服务且保证读写一致。那怎么办呢？</p><p>虽然一个<code>RBD image</code>不能同时被多客户端访问，但是我们是否可以创建多个<code>RBD image</code>，然后利用多个<code>vip</code>对外提供访问呢？这样听起来貌似可行，但是还是存在诸多问题，比如如何暴露多虚拟<code>IP</code>，如何将<code>IP</code>绑定到具体的<code>RBD image</code>，如何保证多<code>RBD image</code>的高可用等等，下文将就这些技术细节进行详细地分析。</p><h2 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h2><p>客户端有多种应用场景，对流量要求较高的情况下，我们可以为每一种应用场景都提供一个<code>vip</code>用于<code>NFS</code>方式访问<code>Ceph</code>存储集群。然后每个<code>vip</code>各自对应集群中的一个<code>RBD image</code>，<code>RBD image</code>尽量均匀的分布到各个节点上，这样才能把性能提升到最高，比如集群有三个节点的话，如果暴露三个<code>vip</code>，那么必须要分布到三个不同的节点上，如果要提供四个<code>vip</code>的话，那么前三个<code>vip</code>均匀地分布到三个节点上，第四个<code>vip</code>就在第一个节点上暴露，以此类推，这边说的第一个节点只是我们自己将三个节点进行逻辑上的排序，我们需要通过一些算法确保<code>vip</code>分布均匀，具体看下文分析。</p><h2 id="整体设计"><a href="#整体设计" class="headerlink" title="整体设计"></a>整体设计</h2><p>一般在完成一个<code>feature</code>之前，我们往往需要做一个<code>design</code>，对要做的事情和流程进行设计和评估，这样不但可以梳理流程，使得之后动手的时候思路清晰，更重要的是可以预见一些问题和难点，尽早与 团队成员进行交流，选择最佳方案，防止真正做的时候走弯路。这边涉及的技术点主要有：</p><h3 id="Keepalived暴露多个VIP"><a href="#Keepalived暴露多个VIP" class="headerlink" title="Keepalived暴露多个VIP"></a>Keepalived暴露多个VIP</h3><p><code>keepalived</code>暴露单个<code>vip</code>很常见，具体格式网上都有，而暴露多个<code>vip</code>就要注意一些细节，比如<code>router_id</code>，<code>ins_name</code>，<code>priority</code>等等，对于一个节点而言，它上面<code>keepalived</code>暴露<code>vip</code>的情况完全是由配置文件<code>keepalived.conf</code>所决定的，而对于<code>keepalived.conf</code>而言，一个<code>vip</code>其实就是<code>ins</code>，而<code>ins_name</code>和<code>router_id</code>要求同一个<code>keepalived</code>组内成员相同，我们这边就默认<code>router_id</code>就是<code>vip</code>隔着小数点的四位整数相加的和，而<code>ins_name</code>则是将<code>vip</code>的小数点换成下划线。</p><h3 id="VIP动态均匀分布"><a href="#VIP动态均匀分布" class="headerlink" title="VIP动态均匀分布"></a>VIP动态均匀分布</h3><p><code>vip</code>均匀分布要保证尽可能的均匀，比如三个节点，如果要提供两个<code>vip</code>的话，那就随意挑选两个节点作为<code>vip</code>绑定，如果四个<code>vip</code>的话，则是三个节点各自绑定一个<code>vip</code>后再任意选择一个节点作为第四个<code>vip</code>绑定。我们这边的做法是先将所有节点进行排序，将两个节点作为一个<code>keepalived</code>组，下两个节点为另外一组，假设有三个节点，我们设为<code>1, 2, 3</code>，那么如果要暴露三个<code>vip</code>，我们就需要三个<code>keepalived</code>组，这边三个组分别是<code>1, 2</code>，<code>3, 1</code>和<code>2, 3</code>，然后组内其中第一个节点为<code>master</code>，第二个节点为<code>backup</code>。这样可以基本保证所有<code>vip</code>的均匀分布，具体算法实现参见下文。</p><h3 id="多RBD高可用"><a href="#多RBD高可用" class="headerlink" title="多RBD高可用"></a>多RBD高可用</h3><p>上一篇文章中只有一个<code>RBD</code>，所以高可用就围绕它一个，发生故障后随意切换节点即可，因为我们每个节点都是一个<code>keepalived</code>组的成员。但是如果有多个<code>RBD</code>的话，我们如果随意切换的话，那么<code>RBD</code>分布就会变得不均匀。上文提及的算法可以保证<code>vip</code>的均匀分布，两两节点作为一个<code>keepalived</code>组，这样我们即使一个节点掉了，切换也只会在当前组内切换，而<code>vip</code>一开始绑定节点的时候就根据相应算法保证了每个<code>RBD</code>的均匀分布，所以这边组内切换不会影响分布的均匀性。</p><p>上一篇文章中提过<code>keepalived</code>的机制，当主节点<code>down</code>了，主节点会触发我们自己写的<code>ChangetoBackup.sh</code>，而副节点则会触发<code>ChangetoMaster.sh</code>。之前由于只有一个<code>RBD</code>，所以当时做的比较无脑，<code>ChangetoMaster.sh</code>直接遍历当前节点上面的所有<code>RBD</code>，然后通过之前记录的<code>RBD</code>和<code>UI</code>上创建的<code>目录</code>的映射关系进行挂载，而<code>ChangetoBackup.sh</code>也是一样的<code>umount</code>所有<code>RBD</code>的挂载点。针对目前的多<code>RBD</code>的情况，这样的做法肯定是不行的，因为现在我们一个节点可能是一个或多个<code>vip</code>的<code>master</code>，也可能是另外一个或多个<code>vip</code>的<code>backup</code>，如果我们还是像之前那样一股脑的全部卸载或者挂载，那么造成的后果显而易见，就是业务中断，暴露服务节点紊乱。所以最合理的应该对号入座，一个<code>vip</code>对应一个<code>RBD image</code>，哪个<code>vip</code>出现了问题，作为该<code>vip</code>的<code>master</code>节点，应该只<code>umount</code>该<code>vip</code>绑定<code>RBD</code>所对应的目录，而<code>backup</code>节点应该只<code>mount</code>对应的目录。其他不相关<code>RBD</code>和其对应的目录，我们都不应该有所操作。那么我们只有在触发<code>ChangetoMaster.sh</code>和<code>ChangetoBackup.sh</code>这两个脚本的时候加上“目录”这个参数，具体实现详见下文分析。</p><h3 id="大容量RBD-image的创建和删除"><a href="#大容量RBD-image的创建和删除" class="headerlink" title="大容量RBD image的创建和删除"></a>大容量RBD image的创建和删除</h3><p>我们系统的实现是<code>UI</code>上创建目录，后端<code>daemon</code>轮询根据目录信息做对应的事情，比如前端<code>UI</code>创建了目录，后端就是在创建<code>RBD image</code>，而生产环境上面的容量的要求都是很高的，往往都是几十<code>T</code>，甚至上百<code>T</code>,但是熟悉<code>RBD</code>的朋友都知道创建如此大的<code>RBD image</code>是需要很长的时间的，那这样就不但会影响当前目录能够提供服务的时间，也会阻塞住代码，影响之后目录的创建。之前我们的做法是一开始我们可以创建一个比较小的<code>image</code>，然后我们后台选择在业务不繁忙的时候进行定时扩容，这也可以算是暂时止血了。但是后来测试发现删除<code>image</code>才是真的慢，这边就不像创建那样有曲线救国的方式了，所以这边无论是创建还是删除<code>RBD image</code>我们都不能做成同步的方式了，我们采取了另起一个线程单独做这个事情，不影响后端业务的正常处理。</p><h3 id="快照保证扩容的安全性"><a href="#快照保证扩容的安全性" class="headerlink" title="快照保证扩容的安全性"></a>快照保证扩容的安全性</h3><p>在我们的测试过程中，发现对<code>RBD image</code>扩容会偶尔发生文件系统出错的情况，这种情况是很危险的，一旦文件系统发生问题，并且用<code>e2fsck</code>等工具修复不了的话，那么数据恢复是很困难的，我们必须要保证客户数据的安全性。所以我们用了<code>RBD</code>的<code>snapshot</code>的功能，在每次扩容之前为<code>RBD image</code>做快照，这样即使发生了问题，我们起码可以做到最小程度的损失。</p><h2 id="具体代码实现"><a href="#具体代码实现" class="headerlink" title="具体代码实现"></a>具体代码实现</h2><h3 id="Keepalived暴露多个VIP-1"><a href="#Keepalived暴露多个VIP-1" class="headerlink" title="Keepalived暴露多个VIP"></a>Keepalived暴露多个VIP</h3><p>当<code>UI</code>创建一个<code>vip</code>的时候，我们就要加一个<code>ins</code>，以下就是我们添加一个<code>ins</code>的<code>API</code>，本文所有代码都是<code>python</code>写的，大家凑合看吧。（部分代码和接口不是很全，文章尾部将会贴出详细代码的地址）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_keepalived_ins</span><span class="params">(self, vip, folder, state)</span>:</span></div><div class="line">    vrrp_ins = <span class="string">"""</span></div><div class="line"><span class="string">vrrp_instance VI_&#123;ins_name&#125; &#123;&#123;</span></div><div class="line"><span class="string">    state &#123;state&#125;</span></div><div class="line"><span class="string">    interface &#123;pubif&#125;</span></div><div class="line"><span class="string">    priority &#123;priority&#125;</span></div><div class="line"><span class="string">    virtual_router_id &#123;router_id&#125;</span></div><div class="line"><span class="string">    advert_int 1</span></div><div class="line"><span class="string">    authentication &#123;&#123;</span></div><div class="line"><span class="string">        auth_type PASS</span></div><div class="line"><span class="string">        auth_pass 1111</span></div><div class="line"><span class="string">    &#125;&#125;</span></div><div class="line"><span class="string">    track_script &#123;&#123;</span></div><div class="line"><span class="string">        chk_nfs</span></div><div class="line"><span class="string">    &#125;&#125;</span></div><div class="line"><span class="string">    notify_master "/etc/keepalived/ChangeToMaster.sh &#123;folder&#125;"</span></div><div class="line"><span class="string">    notify_backup "/etc/keepalived/ChangeToBackup.sh &#123;folder&#125;"</span></div><div class="line"><span class="string">    virtual_ipaddress &#123;&#123;</span></div><div class="line"><span class="string">        &#123;vip&#125;</span></div><div class="line"><span class="string">    &#125;&#125;</span></div><div class="line"><span class="string">&#125;&#125;</span></div><div class="line"><span class="string">"""</span>.format(ins_name = vip.replace(<span class="string">'.'</span>, <span class="string">'_'</span>).replace(<span class="string">'/'</span>, <span class="string">'_'</span>),</div><div class="line">           state = state,</div><div class="line">           priority =  <span class="number">200</span> <span class="keyword">if</span> state == <span class="string">"MASTER"</span> <span class="keyword">else</span> <span class="number">100</span>,</div><div class="line">           router_id = self.get_router_id(vip),</div><div class="line">           pubif = get_public_interface(),</div><div class="line">           folder = folder,</div><div class="line">           vip = vip)</div><div class="line">        <span class="keyword">return</span> vrrp_ins</div></pre></td></tr></table></figure><p>这边我们可以看到<code>ins_name</code>和<code>router_id</code>都是根据<code>vip</code>转换成特定格式，标识<code>ins</code>的唯一性。而<code>priority</code>则是根据<code>state</code>来决定，<code>state</code>为<code>master</code>时，<code>priority</code>为<code>200</code>，而<code>backup</code>的<code>priority</code>为<code>100</code>。至于如何获取<code>state</code>，这个涉及到<code>vip</code>均匀算法，后续会讲。</p><h3 id="VIP动态均匀分布-1"><a href="#VIP动态均匀分布-1" class="headerlink" title="VIP动态均匀分布"></a>VIP动态均匀分布</h3><p>假设三个节点，为<code>1, 2, 3</code>，三个<code>vip</code>，为<code>a, b, c</code>，那么最后<code>a</code>对应的节点为<code>1, 2</code>，<code>b</code>对应的节点为<code>3, 1</code>，<code>c</code>对应的节点为<code>2, 3</code>，具体实现算法是先将所有<code>vip</code>进行排序，获取要操作<code>vip</code>的<code>index</code>，然后获取集群内所有节点，然后将上面获取的<code>index</code>乘以<code>2</code>，再对所有节点的个数做余数，然后可以获得一个整数，这个整数就是<code>vip</code>对应<code>master</code>节点在所有节点数组中的<code>index</code>，这种算法大家应该很容易从规律中推算出来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_my_state</span><span class="params">(self, vip_idx)</span>:</span></div><div class="line">    nodes = get_all_nodes()</div><div class="line">    nodes.sort()</div><div class="line">    idx = vip_idx * <span class="number">2</span> % len(nodes)</div><div class="line">    my_ip = get_public_ip()</div><div class="line">    <span class="keyword">if</span> my_ip == nodes[idx]:</div><div class="line">        <span class="keyword">return</span> <span class="string">'MASTER'</span></div><div class="line">    <span class="keyword">elif</span> my_ip == nodes[(idx + <span class="number">1</span>) % len(nodes)]:</div><div class="line">        <span class="keyword">return</span> <span class="string">'BACKUP'</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="keyword">None</span></div></pre></td></tr></table></figure><h3 id="多RBD高可用-1"><a href="#多RBD高可用-1" class="headerlink" title="多RBD高可用"></a>多RBD高可用</h3><p>我们在创建目录的时候，需要获取当前节点是否为<code>master</code>，之前那个只有一个<code>vip</code>，所以当前节点要么是<code>master</code>，要么是<code>backup</code>，但是这边的话，一个节点可能是一个<code>vip</code>的<code>master</code>的同时也可能是另一个<code>vip</code>的<code>backup</code>，所以是否为<code>master</code>是要根据目录而定的。在这边我们在创建目录、删除目录、创建<code>vip</code>和删除<code>vip</code>时，更新一个<code>vip</code>和目录之间的映射关系。这个<code>map</code>我是存在<code>ceph</code>的<code>leveldb</code>中，至于为什么不存在节点本地，是因为这份数据必须要保证所有节点强一致，放在本地节点，可能会因为一些故障原因导致之后内容不一致的情况。</p><p>这边我们要求在创建目录前，必须要存在空闲<code>vip</code>可以提供目录绑定。所以当创建一个<code>vip</code>时，此时应该没有目录需要绑定，我们建立一个<code>key</code>和<code>value</code>都是<code>vip</code>的字典；当创建一个目录的时候，随机找到一个空闲<code>vip</code>进行绑定，建立一个<code>key</code>为<code>vip</code>，<code>value</code>为目录名的字典；当删除<code>vip</code>时，肯定是存在其他空闲<code>vip</code>的，所以在删除原来对应<code>map</code>后，我们要找到其他一个空闲<code>vip</code>与之前删除<code>vip</code>对应的目录进行绑定；当删除目录时，只要将对应关系中的<code>value</code>换成<code>key</code>，也就是对应的<code>vip</code>了。</p><p>有了这个<code>map</code>，我们就可以实时获取目录和<code>vip</code>的信息和之间的对应关系。</p><p><code>vip.py</code></p><p>负责当<code>vip</code>发生变化时，更新<code>ip_folder_map</code>，以及<code>ip_folder_map</code>的读写<code>API</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_ip_folder_map</span><span class="params">()</span>:</span></div><div class="line">    result = &#123;&#125;</div><div class="line">    ip_folder_map = LevelDB(<span class="string">"ip_folder_map"</span>)</div><div class="line">    result = json.loads(ip_folder_map)[<span class="string">"ip_folder_map"</span>]</div><div class="line">    <span class="keyword">return</span> result</div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_ip_folder_map</span><span class="params">(ip_folder_map)</span>:</span></div><div class="line">    ip_folder_map = LevelDB(<span class="string">"ip_folder_map"</span>)</div><div class="line">    ip_folder_map.set(json.dumps(&#123;<span class="string">"ip_folder_map"</span>: ip_folder_map&#125;))</div><div class="line">    ip_folder_map.save()</div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_ip_folder_map_by_ip</span><span class="params">(ips)</span>:</span></div><div class="line">    ip_folder_map = get_ip_folder_map()</div><div class="line">    old_ips = ip_folder_map.keys()</div><div class="line">    <span class="keyword">if</span> len(ips) &gt; len(old_ips):</div><div class="line">        new_ip = list(set(ips) - set(old_ips))[<span class="number">0</span>]</div><div class="line">        ip_folder_map[new_ip] = new_ip</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        del_ip = list(set(old_ips) - set(ips))[<span class="number">0</span>]</div><div class="line">        folder = ip_folder_map[del_ip]</div><div class="line">        <span class="keyword">del</span> ip_folder_map[del_ip]</div><div class="line">        <span class="keyword">if</span> folder != del_ip:</div><div class="line">            <span class="keyword">for</span> k, v <span class="keyword">in</span> ip_folder_map.iteritems():</div><div class="line">                <span class="keyword">if</span> k == v:</div><div class="line">                    ip_folder_map[k] = folder</div><div class="line">                    <span class="keyword">break</span></div><div class="line">    set_ip_folder_map(ip_folder_map)</div></pre></td></tr></table></figure><p><code>folder.py</code></p><p>负责当<code>folder</code>发生变化时，更新<code>ip_folder_map</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> vip</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_ip_folder_map_by_folder</span><span class="params">(folder, type)</span>:</span></div><div class="line">    ip_folder_map = vip.get_ip_folder_map()</div><div class="line">    folder = get_folder_path(folder)</div><div class="line">    <span class="keyword">if</span> type == <span class="string">"add"</span>:</div><div class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> ip_folder_map.iteritems():</div><div class="line">            <span class="keyword">if</span> k == v:</div><div class="line">                ip_folder_map[k] = folder</div><div class="line">                <span class="keyword">break</span></div><div class="line">    <span class="keyword">elif</span> type == <span class="string">"delete"</span>:</div><div class="line">        <span class="keyword">for</span> k,v <span class="keyword">in</span> ip_folder_map.iteritems():</div><div class="line">            <span class="keyword">if</span> v == folder:</div><div class="line">                ip_folder_map[k] = k</div><div class="line">                <span class="keyword">break</span></div><div class="line">    vip.set_ip_folder_map(ip_folder_map)</div></pre></td></tr></table></figure><p>上面说了在切换节点的时候，需要传递目录参数，保证只操作对应目录。而脚本是静态的，目录确是动态的，所以我们需要在目录或者<code>vip</code>发生变化的时候对原来的<code>keepalived.conf</code>进行更新，添加目录参数。也就是说当<code>vip</code>发生变化时，我们根据当前<code>vip</code>选择添加或者减少<code>ins</code>，并且更新每个<code>ins</code>调用脚本后面追加的参数；而<code>folder</code>发生变化时，<code>vip</code>调用脚本后面追加的参数也需要更新，要么是<code>vip</code>，要么是<code>folder</code>。这边也需要用到上面的<code>ip_folder_map</code>，因为每个<code>ins</code>就是一个<code>vip</code>，而每个<code>vip</code>对应一个<code>folder</code>。所以我们这边当目录或者<code>vip</code>发生变化时，会根据<code>ip_folder_map</code>更新<code>keepalived.conf</code>，具体实现代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_keepalived_conf</span><span class="params">(self)</span>:</span></div><div class="line">        kconf = <span class="string">"""global_defs &#123;</span></div><div class="line"><span class="string">    notification_email &#123;</span></div><div class="line"><span class="string">    &#125;</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    router_id NFS_HA_112</span></div><div class="line"><span class="string">&#125;</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">vrrp_script chk_nfs &#123;</span></div><div class="line"><span class="string">    script "/etc/keepalived/check_nfs.sh"</span></div><div class="line"><span class="string">    interval 2</span></div><div class="line"><span class="string">&#125;</span></div><div class="line"><span class="string">"""</span></div><div class="line">        vips = self.ip_folder_map.keys()</div><div class="line">        vips.sort()</div><div class="line">        <span class="keyword">for</span> vip, folder <span class="keyword">in</span> self.ip_folder_map.items():</div><div class="line">            vip_idx = vips.index(vip)</div><div class="line">            state = self.get_my_state(vip_idx)</div><div class="line">            <span class="keyword">if</span> state <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">                kconf += self.add_keepalived_ins(vip, folder, state)</div><div class="line">        <span class="keyword">with</span> open(KEEPALIVED_CONF_PATH, <span class="string">'w'</span>) <span class="keyword">as</span> f:</div><div class="line">            f.writelines(kconf)</div><div class="line">        do_shell(<span class="string">'service keepalived reload'</span>)</div></pre></td></tr></table></figure><p>下面是添加一个<code>ins</code>的模板，上面也贴过代码，至于这边再次贴一遍的目的是想侧重展示一下脚本后面参数的动态变化的实现方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_keepalived_ins</span><span class="params">(self, vip, folder, state)</span>:</span></div><div class="line">        vrrp_ins = <span class="string">"""</span></div><div class="line"><span class="string">vrrp_instance VI_&#123;ins_name&#125; &#123;&#123;</span></div><div class="line"><span class="string">    state &#123;state&#125;</span></div><div class="line"><span class="string">    interface &#123;pubif&#125;</span></div><div class="line"><span class="string">    priority &#123;priority&#125;</span></div><div class="line"><span class="string">    virtual_router_id &#123;router_id&#125;</span></div><div class="line"><span class="string">    advert_int 1</span></div><div class="line"><span class="string">    authentication &#123;&#123;</span></div><div class="line"><span class="string">        auth_type PASS</span></div><div class="line"><span class="string">        auth_pass 1111</span></div><div class="line"><span class="string">    &#125;&#125;</span></div><div class="line"><span class="string">    track_script &#123;&#123;</span></div><div class="line"><span class="string">        chk_nfs</span></div><div class="line"><span class="string">    &#125;&#125;</span></div><div class="line"><span class="string">    notify_master "/etc/keepalived/ChangeToMaster.sh &#123;folder&#125;"</span></div><div class="line"><span class="string">    notify_backup "/etc/keepalived/ChangeToBackup.sh &#123;folder&#125;"</span></div><div class="line"><span class="string">    virtual_ipaddress &#123;&#123;</span></div><div class="line"><span class="string">        &#123;vip&#125;</span></div><div class="line"><span class="string">    &#125;&#125;</span></div><div class="line"><span class="string">&#125;&#125;</span></div><div class="line"><span class="string">"""</span>.format(ins_name = vip.replace(<span class="string">'.'</span>, <span class="string">'_'</span>).replace(<span class="string">'/'</span>, <span class="string">'_'</span>),</div><div class="line">           state = state,</div><div class="line">           priority =  <span class="number">200</span> <span class="keyword">if</span> state == <span class="string">"MASTER"</span> <span class="keyword">else</span> <span class="number">100</span>,</div><div class="line">           router_id = self.get_router_id(vip),</div><div class="line">           pubif = get_public_interface(),</div><div class="line">           folder = folder,</div><div class="line">           vip = vip)</div><div class="line">        <span class="keyword">return</span> vrrp_ins</div></pre></td></tr></table></figure><p>触发脚本：</p><p><code>ChangetoMaster.sh</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/bin/bash</span></div><div class="line"></div><div class="line">folder=<span class="string">"<span class="variable">$(dirname $1)</span>/<span class="variable">$(basename $1)</span>"</span></div><div class="line">fname=$(basename <span class="variable">$folder</span>)</div><div class="line"></div><div class="line"><span class="keyword">if</span> [ -d <span class="variable">$folder</span> ]; <span class="keyword">then</span></div><div class="line">    <span class="keyword">if</span> $(mount | grep -q <span class="string">"<span class="variable">$folder</span> "</span>); <span class="keyword">then</span></div><div class="line">        umount -f <span class="variable">$folder</span> &gt; /dev/null</div><div class="line">    <span class="keyword">fi</span></div><div class="line">    device=$(rbd showmapped | awk <span class="string">'/image_'</span><span class="variable">$fname</span><span class="string">' / &#123;print $5&#125;'</span>)</div><div class="line">    <span class="keyword">if</span> [ -b <span class="string">"<span class="variable">$device</span>"</span> ]; <span class="keyword">then</span></div><div class="line">        mount <span class="variable">$device</span> <span class="variable">$folder</span></div><div class="line">    <span class="keyword">fi</span></div><div class="line"><span class="keyword">fi</span></div><div class="line">service nfs-kernel-server restart</div></pre></td></tr></table></figure><p><code>ChangetoBackup.sh</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/bin/bash</span></div><div class="line"></div><div class="line">folder=<span class="variable">$1</span></div><div class="line">service nfs-kernel-server stop</div><div class="line"><span class="keyword">if</span> [ -d <span class="variable">$folder</span> ]; <span class="keyword">then</span></div><div class="line">    <span class="keyword">if</span> $(mount | grep -q <span class="string">"<span class="variable">$folder</span> "</span>); <span class="keyword">then</span></div><div class="line">        umount -f <span class="variable">$folder</span> &gt; /dev/null</div><div class="line">    <span class="keyword">fi</span></div><div class="line"><span class="keyword">fi</span></div><div class="line">service nfs-kernel-server start</div></pre></td></tr></table></figure><h3 id="大容量RBD-image的创建和删除-1"><a href="#大容量RBD-image的创建和删除-1" class="headerlink" title="大容量RBD image的创建和删除"></a>大容量RBD image的创建和删除</h3><p>在另外一个端口另起一个线程，通过异步的方式实现，主要利用<code>python</code>的<code>rpyc</code>模块实现，忧郁项目保密性等原因，只贴上部分关键代码，给大家提供一些思路。</p><p>以删除<code>RBD image</code>为例，调用<code>remove_image</code>方法，进入装饰器，从而在新现成做删除操作，不再阻塞之前进程的流程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">rbd_background</span><span class="params">()</span>:</span></div><div class="line">    conn = connect(<span class="string">'localhost'</span>, RBD_PORT)</div><div class="line">    module = conn.modules[<span class="string">'rbd_utils'</span>]</div><div class="line">    async_func = rpyc.<span class="keyword">async</span>(getattr(module, func_name))</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> async_func</div><div class="line">    </div><div class="line"><span class="meta">@rbd_utils.rbd_background</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_image</span><span class="params">(pool, image)</span>:</span></div><div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            logger.info(<span class="string">'rbd &#123;&#125; delete start'</span>.format(image))</div><div class="line">            do_shell(<span class="string">'rbd rm &#123;&#125;/&#123;&#125; &gt;&gt; /var/log/rbd_rm.log'</span>.format(pool, image))</div><div class="line">            logger.info(<span class="string">'rbd &#123;&#125; delete finish'</span>.format(image))</div><div class="line">            <span class="keyword">break</span></div><div class="line">        <span class="keyword">except</span> Exception:</div><div class="line">            logger.error(<span class="string">'rbd &#123;&#125; delete error'</span>.format(image))</div><div class="line">            time.sleep(<span class="number">30</span>)</div></pre></td></tr></table></figure><h3 id="快照保证扩容的安全性-1"><a href="#快照保证扩容的安全性-1" class="headerlink" title="快照保证扩容的安全性"></a>快照保证扩容的安全性</h3><p>首先介绍一下定时扩容的脚本：</p><p><code>monitor_rbd.sh</code>：当<code>RBD image</code>可利用空间小于<code>50%</code>或者小于<code>50T</code>时，扩容<code>50T</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/bin/bash</span></div><div class="line"></div><div class="line"><span class="keyword">function</span> convert_to_MB()</div><div class="line">&#123;</div><div class="line">    size=<span class="variable">$1</span></div><div class="line">    unit=<span class="variable">$&#123;size:(-1):1&#125;</span></div><div class="line">    nr=<span class="variable">$&#123;size/$unit/&#125;</span></div><div class="line">    <span class="keyword">case</span> <span class="variable">$unit</span> <span class="keyword">in</span></div><div class="line">        (k|K|\)) <span class="built_in">echo</span> <span class="string">"<span class="variable">$nr</span> / 1024"</span> | bc;;</div><div class="line">        (m|M|\)) <span class="built_in">echo</span> <span class="string">"<span class="variable">$nr</span>"</span>;;</div><div class="line">        (g|G|\)) <span class="built_in">echo</span> <span class="string">"<span class="variable">$nr</span> * 1024"</span> | bc;;</div><div class="line">        (t|T|\)) <span class="built_in">echo</span> <span class="string">"<span class="variable">$nr</span> * 1024 * 1024"</span> | bc;;</div><div class="line">        (p|P|\)) <span class="built_in">echo</span> <span class="string">"<span class="variable">$nr</span> * 1024 * 1024 * 1024"</span> | bc;;</div><div class="line">        *) <span class="built_in">echo</span> <span class="string">"Error: cannot convert to MB: <span class="variable">$size</span>"</span>;;</div><div class="line">    <span class="keyword">esac</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">function</span> get_available_size()</div><div class="line">&#123;</div><div class="line">    disk=<span class="variable">$1</span></div><div class="line">    unit_size=$(convert_to_MB <span class="string">'50T'</span>)</div><div class="line">    </div><div class="line">    disk_size=$(df -h | grep <span class="variable">$disk</span> | awk <span class="string">'&#123;print $2&#125;'</span>)</div><div class="line">    disk_size=$(convert_to_MB <span class="variable">$disk_size</span>)</div><div class="line">    pool=$(rbd showmapped | grep <span class="variable">$disk</span> | awk <span class="string">'&#123;print $2&#125;'</span>)</div><div class="line">    available_pool_size=$(ceph df | grep <span class="variable">$pool</span> | awk <span class="string">'&#123;print $5&#125;'</span>)</div><div class="line">    available_pool_size=$(convert_to_MB <span class="variable">$available_pool_size</span>)</div><div class="line">    <span class="keyword">if</span> [ $(<span class="built_in">echo</span> <span class="string">"<span class="variable">$available_pool_size</span> &lt; <span class="variable">$unit_size</span>"</span> | bc) -eq 1 ]; <span class="keyword">then</span></div><div class="line">        new_size=$(<span class="built_in">echo</span> <span class="string">"<span class="variable">$disk_size</span> + <span class="variable">$available_pool_size</span>"</span> | bc)</div><div class="line">    <span class="keyword">else</span></div><div class="line">        new_size=$(<span class="built_in">echo</span> <span class="string">"<span class="variable">$disk_size</span> + <span class="variable">$unit_size</span>"</span> | bc)</div><div class="line">    <span class="keyword">fi</span></div><div class="line">    <span class="built_in">echo</span> <span class="variable">$&#123;new_size%.*&#125;</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">function</span> check_and_enlarge_disk()</div><div class="line">&#123;</div><div class="line">    disk=<span class="string">"<span class="variable">$1</span>"</span></div><div class="line">    <span class="keyword">if</span> [ <span class="string">"<span class="variable">$disk</span>"</span> = <span class="string">""</span> ]; <span class="keyword">then</span></div><div class="line">        <span class="built_in">echo</span> <span class="string">"Error: You must specify the disk name"</span></div><div class="line">        <span class="built_in">return</span> 1</div><div class="line">    <span class="keyword">fi</span></div><div class="line">    <span class="built_in">echo</span> <span class="string">"Checking the disk [/dev/<span class="variable">$disk</span>] ..."</span></div><div class="line">    <span class="keyword">if</span> ! rbd showmapped | grep -q <span class="variable">$disk</span>; <span class="keyword">then</span></div><div class="line">        <span class="built_in">echo</span> <span class="string">"Error: Cannot find the disk [<span class="variable">$disk</span>]"</span></div><div class="line">        <span class="built_in">return</span> 2</div><div class="line">    <span class="keyword">fi</span></div><div class="line">    disk_usage=$(df | grep <span class="variable">$disk</span> | awk <span class="string">'&#123;print $5&#125;'</span>)</div><div class="line">    available_disk_size=$(df | grep <span class="variable">$disk</span> | awk <span class="string">'&#123;print $4&#125;'</span>)</div><div class="line">    available_disk_size=$(convert_to_MB <span class="string">"<span class="variable">$&#123;available_disk_size&#125;</span>k"</span>)</div><div class="line">    <span class="built_in">echo</span> <span class="string">"  The disk use% is <span class="variable">$&#123;disk_usage&#125;</span>"</span></div><div class="line">    disk_usage=<span class="variable">$&#123;disk_usage/\%/&#125;</span></div><div class="line">    <span class="keyword">if</span> [ <span class="variable">$disk_usage</span> -lt 50 -a <span class="variable">$available_disk_size</span> -gt 1024 * 1024 * 50 ]; <span class="keyword">then</span></div><div class="line">        <span class="built_in">echo</span> <span class="string">'Less then 50% use and more then 50TB available space left, just quit'</span></div><div class="line">        <span class="built_in">return</span> 0</div><div class="line">    <span class="keyword">fi</span></div><div class="line">    <span class="built_in">echo</span> <span class="string">'Enlarging the disk ...'</span></div><div class="line">    new_size=$(get_available_size <span class="variable">$disk</span>)</div><div class="line">    <span class="built_in">echo</span> <span class="string">"  the new size is <span class="variable">$&#123;new_size&#125;</span>MB"</span></div><div class="line">    pool=$(rbd showmapped | grep <span class="variable">$disk</span> | awk <span class="string">'&#123;print $2&#125;'</span>)</div><div class="line">    image=$(rbd showmapped | grep <span class="variable">$disk</span> | awk <span class="string">'&#123;print $3&#125;'</span>)</div><div class="line">    rbd resize --size <span class="variable">$new_size</span> -p <span class="variable">$pool</span> <span class="variable">$image</span></div><div class="line">    sleep 3</div><div class="line">    resize2fs /dev/<span class="variable">$&#123;disk&#125;</span> <span class="string">"<span class="variable">$&#123;new_size&#125;</span>M"</span></div><div class="line">    <span class="built_in">echo</span> <span class="string">"Done"</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">disks=$(lsblk | grep rbd | awk <span class="string">'&#123;print $1&#125;'</span>)</div><div class="line"><span class="keyword">for</span> disk <span class="keyword">in</span> <span class="variable">$disks</span></div><div class="line"><span class="keyword">do</span></div><div class="line"><span class="built_in">echo</span> <span class="string">"=============================================="</span></div><div class="line">check_and_enlarge_disk <span class="string">"<span class="variable">$disk</span>"</span></div><div class="line"><span class="built_in">echo</span> <span class="string">"=============================================="</span></div><div class="line"><span class="keyword">done</span></div></pre></td></tr></table></figure><p>这边我们采用<code>ceph</code>提供的原生<code>python</code>的接口，完成<code>RBD</code>的定时快照的创建和删除</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/python</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> rados</div><div class="line"><span class="keyword">import</span> rbd</div><div class="line"><span class="keyword">from</span> folder <span class="keyword">import</span> get_all_folder_info</div><div class="line"><span class="keyword">from</span> vip <span class="keyword">import</span> get_ip_folder_map</div><div class="line"></div><div class="line">CEPH_CONF = <span class="string">'/etc/ceph/ceph.conf'</span></div><div class="line">MAX_SNAP_COUNT = <span class="number">5</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_snap</span><span class="params">(pool, rbd_image)</span>:</span></div><div class="line">    now = time.localtime()</div><div class="line">    snap = time.strftime(<span class="string">"%Y_%m_%d_%H_%M_%S"</span>, now)</div><div class="line">    <span class="keyword">with</span> rados.Rados(conffile=CEPH_CONF) <span class="keyword">as</span> cluster:</div><div class="line">        <span class="keyword">with</span> cluster.open_ioctx(str(pool)) <span class="keyword">as</span> ioctx:</div><div class="line">            <span class="keyword">with</span> rbd.Image(ioctx, rbd_image) <span class="keyword">as</span> image:</div><div class="line">                image.create_snap(snap)</div><div class="line">                </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_images</span><span class="params">()</span>:</span></div><div class="line">    pubif = get_public_interface()</div><div class="line">    pub_ips = do_cmd(<span class="string">"ip addr show &#123;&#125; | awk '/inet/ &#123;&#123;print $2&#125;&#125;'"</span>.format(pubif)).split()</div><div class="line">    vip_folders = get_ip_folder_map(gwgroup)</div><div class="line">    my_folders = []</div><div class="line">    <span class="keyword">for</span> pip <span class="keyword">in</span> pub_ips:</div><div class="line">        <span class="keyword">if</span> pip <span class="keyword">in</span> vip_folders <span class="keyword">and</span> pip != vip_folders[pip]:</div><div class="line">            my_folders.append(os.path.basename(vip_folders[pip]))</div><div class="line">    folders = get_all_folder_info()</div><div class="line">    images = []</div><div class="line">    <span class="keyword">for</span> folder <span class="keyword">in</span> folders:</div><div class="line">        <span class="keyword">if</span> folder <span class="keyword">in</span> my_folders:</div><div class="line">            images.append(&#123;</div><div class="line">                <span class="string">'image'</span>: <span class="string">'image_&#123;&#125;'</span>.format(folder),</div><div class="line">                <span class="string">'pool'</span>: folders[folder][<span class="string">'pool'</span>]</div><div class="line">            &#125;)</div><div class="line">    <span class="keyword">return</span> images</div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_old_snap</span><span class="params">(pool, rbd_image)</span>:</span></div><div class="line">    <span class="keyword">with</span> rados.Rados(conffile=CEPH_CONF) <span class="keyword">as</span> cluster:</div><div class="line">        <span class="keyword">with</span> cluster.open_ioctx(str(pool)) <span class="keyword">as</span> ioctx:</div><div class="line">            <span class="keyword">with</span> rbd.Image(ioctx, rbd_image) <span class="keyword">as</span> image:</div><div class="line">                snaps = sorted(image.list_snaps(), key=<span class="keyword">lambda</span> snap: snap[<span class="string">'name'</span>])</div><div class="line">                <span class="keyword">if</span> len(snaps) &gt; MAX_SNAP_COUNT:</div><div class="line">                    <span class="keyword">for</span> snap <span class="keyword">in</span> snaps[<span class="number">0</span>:len(snaps)-MAX_SNAP_COUNT]:</div><div class="line">                        image.remove_snap(snap[<span class="string">'name'</span>])</div><div class="line">                        </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line">    images = get_images()</div><div class="line">    <span class="keyword">for</span> image <span class="keyword">in</span> images:</div><div class="line">        create_snap(image[<span class="string">'pool'</span>], image[<span class="string">'image'</span>])</div><div class="line">        remove_old_snap(image[<span class="string">'pool'</span>], image[<span class="string">'image'</span>])</div><div class="line">        device = do_shell(<span class="string">"rbd showmapped | awk '/&#123;&#125;[ \t]*&#123;&#125;/ &#123;&#123;print $5&#125;&#125;'"</span>.format(image[<span class="string">'pool'</span>], image[<span class="string">'image'</span>]))</div><div class="line">        do_shell(<span class="string">'/usr/local/bin/monitor_rbd.sh &#123;&#125;'</span>.format(os.path.basename(device)))</div><div class="line">        </div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    main()</div></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>内容和代码都比较多，其实每一个技术点都可以单独拿出来写一篇，但是我觉得这是一个完整<code>feature</code>，想让大家能够代入，了解到完成这样一个<code>feature</code>周边需要支持的各种技术点和注意点，一个<code>feature</code>往往是经过不断迭代和维护，很多实现方法也随着时间和应用场景不断发生变化。</p><p>完成这样一个<code>feature</code>，我也是反复修改，就比如异步实现<code>RBD image</code>的创建和删除，很多场景在生产环境和测试环境中的 情况是完全不一样的，比如我开发的时候创建的<code>image</code>都是<code>1G</code>的，当然很快，也不能存在什么阻塞的问题，也遇到很多问题和想不通的地方，感谢我的同事和前辈提供的帮助和启发。</p><p>最后，衷心希望<code>ceph</code>能够早日将<code>CephFS</code>完善，保证其在生产环境中的稳定性和性能。这样我们也就不用绞尽脑汁这般曲线救国了，哈哈。</p><p>最后的最后，贴上部分代码地址，由于项目保密性等原因，我只能贴出比较关键的代码，大家请见谅，我觉得这些代码应该足够了，足够给大家提供一个思路了，其实往往思路比代码更重要，相信很多人的实现方式要比我更加优秀呢！</p><blockquote><p>代码地址：<a href="https://github.com/tony-yin/Multi_RBD_HA" target="_blank" rel="external">https://github.com/tony-yin/Multi_RBD_HA</a></p></blockquote><p>如果大家觉得有帮助的话，欢迎<code>Star</code>哦 ~(≧▽≦)/~</p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/rbd2-600x450.jpg&quot; alt=&quot;RBD-HA-2&quot;&gt;&lt;/center&gt;

&lt;p&gt;之前分享过一篇&lt;a href=&quot;http://www.tony-yin.top/2017/12/07/RBD-HA/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;【通过 Keepalived 实现 Ceph RBD 的高可用】&lt;/a&gt;，主要讲解了将&lt;code&gt;RBD&lt;/code&gt;导出为&lt;code&gt;NFS&lt;/code&gt;，然后通过&lt;code&gt;keepalived&lt;/code&gt;实现高可用，保证当提供虚拟&lt;code&gt;IP&lt;/code&gt;节点发生故障时，可以自动切换节点，使得业务不发生中断。&lt;/p&gt;
&lt;p&gt;这样可以基本使用&lt;code&gt;RBD&lt;/code&gt;代替&lt;code&gt;CephFS&lt;/code&gt;对外提供&lt;code&gt;Ceph&lt;/code&gt;服务，至于为什么不用&lt;code&gt;CephFS&lt;/code&gt;就不多说了，不清楚的可以去看上一篇。虽然说这样可以保证无单点故障，但是有一点还是不如&lt;code&gt;CephFS&lt;/code&gt;，那就是&lt;code&gt;CephFS&lt;/code&gt;可以实现多节点同时提供服务，而&lt;code&gt;RBD&lt;/code&gt;说白了其实同时只有一个节点能提供服务，当客户端流量高的时候，&lt;code&gt;RBD&lt;/code&gt;方式的带宽并不能满足需求。就比如都是三个节点，&lt;code&gt;CephFS&lt;/code&gt;可以将客户端流量分流到三个节点，而&lt;code&gt;RBD&lt;/code&gt;只能用一个节点，而带宽上限又取决与网卡、磁盘和&lt;code&gt;IO&lt;/code&gt;等等原因，所以同样的硬件设施&lt;code&gt;RBD&lt;/code&gt;的带宽性能是跟不上的，本文就多虚拟&lt;code&gt;IP&lt;/code&gt;暴露访问方式进行分享。&lt;/p&gt;
    
    </summary>
    
      <category term="tech" scheme="https://tony-yin.github.io/categories/tech/"/>
    
    
      <category term="Ceph" scheme="https://tony-yin.github.io/tags/Ceph/"/>
    
      <category term="NFS" scheme="https://tony-yin.github.io/tags/NFS/"/>
    
      <category term="RBD" scheme="https://tony-yin.github.io/tags/RBD/"/>
    
      <category term="HA" scheme="https://tony-yin.github.io/tags/HA/"/>
    
      <category term="Keepalived" scheme="https://tony-yin.github.io/tags/Keepalived/"/>
    
  </entry>
  
  <entry>
    <title>scp 免交互式和 ssh 免交互式脚本</title>
    <link href="https://tony-yin.github.io/2018/01/10/scp-and-ssh/"/>
    <id>https://tony-yin.github.io/2018/01/10/scp-and-ssh/</id>
    <published>2018-01-10T15:40:46.000Z</published>
    <updated>2018-01-30T12:51:35.223Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/open_ssh-600x450.png" alt="Scp-And-Ssh"></center><p>简单实现了<code>scp</code>的免交互式脚本和<code>ssh</code>免交互式脚本。</p><a id="more"></a><h2 id="scp"><a href="#scp" class="headerlink" title="scp"></a>scp</h2><p>场景：</p><p>需要将以下源主机上的三个文件拷贝到以下目的主机的对应目录下</p><blockquote><p><code>src host</code>: 192.168.1.1<br><code>dist host</code>: 192.168.1.2<br><code>files</code>: <code>/root/1/1.txt</code>, <code>/root/2/2.txt</code>, <code>/root/3/3.txt</code></p></blockquote><p>这时候如果手动做的话，将会很繁琐，所以这时候需要一个脚本能够实现文件的自动复制，并且脚本需要自动把密码验证的步骤也覆盖。</p><p>这里的关键就是如何实现<code>shell</code>交互式命令行的自动化，这边可以用分界符<code>EOF</code>，<code>EOF</code>范围中的字符将会被作为命令输入到交互式命令行中，具体脚本如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">SOURCEHOST=192.168.1.1</div><div class="line">DISTHOST=$1</div><div class="line">FILE1=/root/1/1.txt</div><div class="line">FILE2=/root/2/2.txt</div><div class="line">FILE3=/root/3/3.txt</div><div class="line">FOLDER1=/root/1/</div><div class="line">FOLDER2=/root/2/</div><div class="line">FOLDER3=/root/3/</div><div class="line">PASSWORD=123456</div><div class="line">scp FILE1 $&#123;DISTHOST&#125;$&#123;Folder1&#125; &lt;&lt; EOF</div><div class="line">$PASSWORD</div><div class="line">EOF</div><div class="line">scp FILE2 $&#123;DISTHOST&#125;$&#123;Folder2&#125; &lt;&lt; EOF</div><div class="line">$PASSWORD</div><div class="line">EOF</div><div class="line">scp FILE3 $&#123;DISTHOST&#125;$&#123;Folder3&#125; &lt;&lt; EOF</div><div class="line">$PASSWORD</div><div class="line">EOF</div></pre></td></tr></table></figure><p>调用方式：<code>sh scp.sh 192.168.1.2</code></p><h2 id="ssh"><a href="#ssh" class="headerlink" title="ssh"></a>ssh</h2><p>场景：</p><p>上面的场景是建立在登陆<code>192.168.1</code>主机的基础上，现在我想我在任意主机上都可以实现上面将<code>192.168.1.1</code>的上述文件拷贝到<code>192.168.1.2</code>的对应目录下</p><p>这里的关键是实现<code>ssh</code>的免密登陆，这时我们需要用到<code>sshpass</code>，具体介绍可以自行搜索下，用法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">#! /bin/bash</div><div class="line"></div><div class="line">SOURCEHOST=192.168.1.1</div><div class="line">DISTHOST=$1</div><div class="line">FILE1=/root/1/1.txt</div><div class="line">FILE2=/root/2/2.txt</div><div class="line">FILE3=/root/3/3.txt</div><div class="line">FOLDER1=/root/1/</div><div class="line">FOLDER2=/root/2/</div><div class="line">FOLDER3=/root/3/</div><div class="line">PASSWORD=123456</div><div class="line"></div><div class="line">sshpass -p $PASSWORD ssh $SOURCEHOST \</div><div class="line">    sshpass -p $PASSWORD scp $&#123;FILE1&#125; $&#123;DISTHOST&#125;$&#123;FOLDER1&#125; &amp;&amp; \</div><div class="line">    sshpass -p $PASSWORD scp $&#123;FILE2&#125; $&#123;DISTHOST&#125;$&#123;FOLDER2&#125; &amp;&amp; \</div><div class="line">    sshpass -p $PASSWORD scp $&#123;FILE3&#125; $&#123;DISTHOST&#125;$&#123;FOLDER3&#125;</div></pre></td></tr></table></figure><p>调用方式：<code>sh scp.sh 192.168.1.2</code></p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/open_ssh-600x450.png&quot; alt=&quot;Scp-And-Ssh&quot;&gt;&lt;/center&gt;

&lt;p&gt;简单实现了&lt;code&gt;scp&lt;/code&gt;的免交互式脚本和&lt;code&gt;ssh&lt;/code&gt;免交互式脚本。&lt;/p&gt;
    
    </summary>
    
      <category term="tech" scheme="https://tony-yin.github.io/categories/tech/"/>
    
    
      <category term="Script" scheme="https://tony-yin.github.io/tags/Script/"/>
    
      <category term="Linux" scheme="https://tony-yin.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>利用Raid卡工具获取逻辑盘是否为SSD</title>
    <link href="https://tony-yin.github.io/2018/01/05/RaidCardToolUtils/"/>
    <id>https://tony-yin.github.io/2018/01/05/RaidCardToolUtils/</id>
    <published>2018-01-05T05:07:06.000Z</published>
    <updated>2018-01-30T12:50:22.464Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/raid-600x450.png" alt="RaidCardToolUtils"></center><p>网上很多获取一块盘是否为<code>SSD</code>的方式都是不靠谱的，不能覆盖到所有情况。一般我们在操作系统上的硬盘都是虚拟出来的逻辑盘，比如<code>/dev/sda</code>这种，它可能对应一块单独的物理硬盘，也有可能对应的是几块盘组成的<code>raid</code>。我们有时候想获取一块盘的具体信息，比如磁盘类型、插槽号、序列号等等，这时候我们就得借助对应的<code>raid</code>卡工具了，最常见的如<code>Megacli</code>，通过逻辑盘找到对应的物理盘，然后读取信息。</p><a id="more"></a><h2 id="Raid卡简介"><a href="#Raid卡简介" class="headerlink" title="Raid卡简介"></a>Raid卡简介</h2><p>所谓<code>raid</code>卡，就是为了更好的统一管理物理硬盘而存在的，在出现单独的<code>raid</code>卡之前，对硬盘做<code>raid</code>操作，需要<code>cpu</code>完成其中的计算操作，这个会很影响其他依赖<code>cpu</code>的应用或进程的性能，后来就将<code>raid</code>卡单独提取出来，并且在其之上存在一个小型<code>cpu</code>供来完成<code>raid</code>相关操作的计算，这其中最常见的<code>raid</code>工具应该非<code>Megacli</code>莫属了。</p><p>为什么说最常见的呢？因为<code>raid</code>卡工具对应不同型号的<code>raid</code>卡是不一样，<code>LSI</code>只是一个半导体厂商，负责提供<code>raid</code>芯片，最后还需要集成到服务器厂商的机器上，所以最后的工具还是由厂商决定和提供，也可以理解为特定型号的<code>raid</code>对应各自的工具。</p><h2 id="HBA卡简介"><a href="#HBA卡简介" class="headerlink" title="HBA卡简介"></a>HBA卡简介</h2><p>近来，又出现了一种<code>HBA</code>卡，只从<code>HBA</code>的英文解释<code>HOST BUS ADAPTER</code>（主机总线适配器）就能看出来，他肯定是给主机用的，一般<code>HBA</code>就是给主机插上后，给主机扩展出更多的接口，来连接外部的设备。大多数讲到<code>HBA</code>卡都是指光纤的<code>HBA</code>卡，给主机提供光纤接口的。也有<code>ISCSI</code>的<code>HBA</code>卡，链接<code>ISCSI</code>设备的，从这种功能上说，我们也可以把独立网卡称为<code>HBA</code>卡，通过独立网卡扩展出网口来连接外部网络设备或主机。不过习惯上大部分<code>HBA</code>只是称光纤卡或者<code>iscsi</code>卡。</p><p>简而言之，这种<code>HBA</code>卡本身是为了扩展外部连接设备而存在的，但是它具有部分<code>raid</code>功能，与<code>raid</code>卡相比它的优势在于它价格便宜，性价比高；劣势在于虽然具有<code>raid</code>功能，但是都是基础的功能，没有<code>raid</code>卡那么完善。</p><blockquote><p>这篇文章讲<code>raid</code>卡和<code>HBA</code>卡讲的挺好的：<a href="http://www.cnblogs.com/weikunzz/p/6707395.html" target="_blank" rel="external">HBA卡 和 RAID卡</a></p></blockquote><h2 id="需求和背景"><a href="#需求和背景" class="headerlink" title="需求和背景"></a>需求和背景</h2><p>据我所知，这类工具往往是运维人员用的居多，但是往往开发中也会需要用到。本文通过获取逻辑盘对应盘的类型展开描述，并借此讲解获取逻辑盘的一类信息或通过逻辑盘操作对应物理盘。因为这其中的关键就是找到逻辑盘和物理盘之间的对应关系。无论是<code>raid</code>卡工具还是<code>HBA</code>卡工具都是罗列所有硬盘的信息，所以你要从中找到你选择的逻辑盘所对应的便是重中之重。</p><p>逻辑盘对应的物理盘可能为单独的硬盘，也可能是<code>raid</code>，单独的可以直接读取硬盘类型，<code>raid</code>的话我们认为只会将同样类型的盘做<code>raid</code>，混合的情况不考虑。</p><p><code>raid</code>卡工具的话，我只对<code>Megacli</code>和<code>Sas3ircu</code>进行讲解，所以阅读本文前最好有使用以上两个工具的相关经验。首先我会根据目前存在的<code>raid</code>卡类型建立一个<code>map</code>关系，然后通过<code>raid</code>卡类型自动获取对应<code>raid</code>卡工具，每个<code>raid</code>卡都是一个类，然后里面的方法都是为该工具定制化的操作。</p><h2 id="获取raid卡工具"><a href="#获取raid卡工具" class="headerlink" title="获取raid卡工具"></a>获取raid卡工具</h2><p>目前就考虑两种型号的<code>raid</code>卡，以后有新的再往<code>map</code>里面填充就好了。<code>NotSupport</code>指的是其他不支持型号的<code>raid</code>卡和虚拟机。</p><blockquote><p><code>do_shell</code>是本人封装的一个在<code>python</code>中执行<code>shell</code>命令的方法，大家可以根据自己的情况对该方法进行转换</p></blockquote><p>通过获取的<code>card mode</code>，根据<code>map</code>找到对应的<code>tool</code>，然后实例化对应的工具类</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">RaidCardToolFactory</span><span class="params">()</span>:</span></div><div class="line">    RaidCardMap = &#123;</div><div class="line">        <span class="string">'SAS2208'</span>: MegaraidTool,</div><div class="line">        <span class="string">'SAS3008'</span>: HBATool,</div><div class="line">        <span class="string">'NotSupport'</span>: NotSupport</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getTool</span><span class="params">(self)</span>:</span></div><div class="line">        card_model = self.get_raidcard_model()</div><div class="line">        tool = self.RaidCardMap[card_model]()</div><div class="line">        <span class="keyword">return</span> tool</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_raidcard_model</span><span class="params">(self)</span>:</span></div><div class="line">        card_model = <span class="string">'NotSupport'</span></div><div class="line">        card_info = do_shell(<span class="string">"lspci | grep 'LSI Logic'"</span>)</div><div class="line">        <span class="keyword">if</span> card_info == <span class="string">''</span>:</div><div class="line">            <span class="keyword">return</span> card_model</div><div class="line">        card = card_info.strip().splitlines()[<span class="number">0</span>].split()</div><div class="line">        <span class="keyword">if</span> <span class="string">'RAID bus controller'</span> <span class="keyword">in</span> card_info:</div><div class="line">            card_model = card[<span class="number">10</span>] + card[<span class="number">11</span>]</div><div class="line">        <span class="keyword">elif</span> <span class="string">'Attached SCSI controller'</span> <span class="keyword">in</span> card_info:</div><div class="line">            card_model = card[<span class="number">10</span>]</div><div class="line">        <span class="keyword">return</span> card_model</div></pre></td></tr></table></figure><h2 id="Megaraid工具类"><a href="#Megaraid工具类" class="headerlink" title="Megaraid工具类"></a>Megaraid工具类</h2><ol><li>先通过<code>lsscsi</code>命令获取逻辑盘是否为<code>raid</code>；</li><li>如果是<code>raid</code>，那么直接根据<code>lsscsi</code>获取当前逻辑盘的<code>target id</code>，也就是第三个号，然后通过<code>megacli cfgdsply -aALL</code>获取所有<code>raid</code>信息，根据逻辑盘的<code>target id</code>对应物理盘中的<code>Target Id</code>找到对应<code>raid</code>，然后只要获取<code>raid</code>中第一块物理盘的硬盘类型即可，也就是<code>Media Type</code>，具体参见下方<code>API</code>: <code>get_ld_type</code></li><li>如果不是<code>raid</code>，那么直接根据<code>lsscsi</code>获取当前逻辑盘的<code>target id</code>，也就是第三个号，这边的<code>target id</code>直接对应<code>megacli</code>中每一块单盘中的<code>Device Id</code>字段，所以根据<code>target id</code>匹配<code>megacli pdlist aAll</code>获取磁盘列表的每一项的<code>Device Id</code>便可以找到对应的物理盘，具体参见下方<code>API</code>: <code>get_pd_type</code>。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MegaraidTool</span><span class="params">()</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_disk_type</span><span class="params">(self, disk_name)</span>:</span></div><div class="line">        scsi_info = do_shell(<span class="string">"lsscsi | grep &#123;&#125; -w"</span>.format(disk_name))</div><div class="line">        target_id = scsi_info.split()[<span class="number">0</span>].split(<span class="string">":"</span>)[<span class="number">2</span>]</div><div class="line">        serial_nu = scsi_info.split()[<span class="number">3</span>].strip()[<span class="number">2</span>:]</div><div class="line">        <span class="keyword">if</span> <span class="string">"LSI"</span> <span class="keyword">in</span> scsi_info:</div><div class="line">            disk_type = self.get_ld_type(target_id, serial_nu)</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            disk_type = self.get_pd_type(target_id)</div><div class="line">        <span class="keyword">return</span> disk_type</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_ld_type</span><span class="params">(self, target_id, serial_nu)</span>:</span></div><div class="line">        disk_type = <span class="string">''</span></div><div class="line">        cmd = MEGACLI + <span class="string">' cfgdsply -aALL -NoLog|grep -E "Product Name|Target Id|Media Type"'</span></div><div class="line">        output = do_shell(cmd)</div><div class="line">        adapters = output.split(<span class="string">'Product Name'</span>)</div><div class="line">        <span class="keyword">for</span> adapter <span class="keyword">in</span> adapters:</div><div class="line">            <span class="keyword">if</span> serial_nu <span class="keyword">not</span> <span class="keyword">in</span> adapter:</div><div class="line">                <span class="keyword">continue</span></div><div class="line">            lines = adapter.split(<span class="string">'\n'</span>)</div><div class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> lines:</div><div class="line">                <span class="keyword">if</span> <span class="string">"Target Id: &#123;&#125;"</span>.format(target_id) <span class="keyword">in</span> line:</div><div class="line">                    index = lines.index(line)</div><div class="line">                    <span class="keyword">if</span> <span class="string">'Solid State Device'</span> <span class="keyword">in</span> lines[index + <span class="number">1</span>]:</div><div class="line">                        disk_type = <span class="string">"SSD"</span></div><div class="line">                    <span class="keyword">else</span>:</div><div class="line">                        disk_type = <span class="string">"HDD"</span></div><div class="line">                    <span class="keyword">break</span></div><div class="line">            <span class="keyword">if</span> disk_type != <span class="string">''</span>:</div><div class="line">                <span class="keyword">break</span></div><div class="line">        <span class="keyword">return</span> disk_type</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_pd_type</span><span class="params">(self, target_id)</span>:</span></div><div class="line">        disk_type = <span class="string">''</span></div><div class="line">        cmd = MEGACLI + <span class="string">' pdlist aAll | grep -E "Device Id|Media Type"'</span></div><div class="line">        output = do_shell(cmd)</div><div class="line">        lines = output.split(<span class="string">'\n'</span>)</div><div class="line">        <span class="keyword">if</span> <span class="string">'Device Id: &#123;&#125;'</span>.format(target_id) <span class="keyword">not</span> <span class="keyword">in</span> lines:</div><div class="line">            <span class="keyword">return</span> <span class="string">''</span></div><div class="line">        index = lines.index(<span class="string">'Device Id: &#123;&#125;'</span>.format(target_id))</div><div class="line">        <span class="keyword">if</span> <span class="string">'Solid State Device'</span> <span class="keyword">in</span> lines[index + <span class="number">1</span>]:</div><div class="line">            disk_type = <span class="string">"SSD"</span></div><div class="line">        <span class="keyword">else</span> :</div><div class="line">            disk_type = <span class="string">"HDD"</span></div><div class="line">        <span class="keyword">return</span> disk_type</div></pre></td></tr></table></figure><h2 id="HBA工具类"><a href="#HBA工具类" class="headerlink" title="HBA工具类"></a>HBA工具类</h2><ol><li><code>HBA</code>类用的工具是<code>sas3ircu</code>，首先我们需要根据命令<code>sas3ircu list</code>获取所有的<code>controller</code>，然后每次获取信息都需要遍历所有<code>controller</code>；</li><li>第一步依旧是判断逻辑盘是否为<code>raid</code>；</li><li>如果是<code>raid</code>，获取逻辑盘的<code>target id</code>，与之匹配的是<code>sas3ircu</code>中的<code>Initiator at ID</code>字段，找到对应的<code>raid</code>，然后通过获取其下第一个物理盘的类型，这边类型字段变成了<code>Drive Type</code>，具体参考下方<code>API</code>: <code>get_ld_type</code>；</li><li>如果非<code>raid</code>，我匹配的是<code>sas3ircu</code>中的<code>Sas Address</code>字段，那么逻辑盘的<code>Sas Address</code>如何获取呢？这边我用的方式是通过<code>udev</code>获取逻辑盘的<code>symlink</code>，这里面有很多<code>address</code>，而我们需要的是<code>by-path</code>，我这边就简单做了，看<code>sas3ircu</code>每个盘的<code>Sas Address</code>是否被<code>udev</code>获取的<code>symlink</code>包含，如果包含了，那么也就匹配到了，然后直接获取<code>Drive Type</code>字段就可以得到磁盘类型类；具体参考下方<code>API</code>: <code>get_pd_type</code></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HBATool</span><span class="params">()</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_disk_type</span><span class="params">(self, disk_name)</span>:</span></div><div class="line">        scsi_info = do_shell(<span class="string">"lsscsi | grep &#123;&#125; -w"</span>.format(disk_name))</div><div class="line">        <span class="keyword">if</span> <span class="string">"LSI"</span> <span class="keyword">in</span> scsi_info:</div><div class="line">            target_id = scsi_info.split()[<span class="number">0</span>].split(<span class="string">":"</span>)[<span class="number">2</span>]</div><div class="line">            disk_type = self.get_ld_type(target_id)</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            sas_address = do_cmd(<span class="string">'udevadm info --query=symlink --name=&#123;&#125;'</span>.format(disk_name))</div><div class="line">            disk_type = self.get_pd_type(sas_address)</div><div class="line">        <span class="keyword">return</span> disk_type</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_ld_type</span><span class="params">(self, target_id)</span>:</span></div><div class="line">        disk_type = <span class="string">''</span></div><div class="line">        controllers = self.get_controllers()</div><div class="line">        <span class="keyword">for</span> controller <span class="keyword">in</span> controllers:</div><div class="line">            cmd = <span class="string">'sas3ircu &#123;&#125; display|grep -E "Initiator at ID|Drive Type"'</span>.format(controller)</div><div class="line">            output = do_shell(cmd)</div><div class="line">            <span class="keyword">if</span> <span class="string">'Initiator at ID #&#123;&#125;'</span>.format(target_id) <span class="keyword">in</span> output:</div><div class="line">                lines = output.splitlines()</div><div class="line">                index = lines.index(<span class="string">'Initiator at ID #&#123;&#125;'</span>.format(target_id))</div><div class="line">                <span class="keyword">if</span> <span class="string">'HDD'</span> <span class="keyword">in</span> lines[index + <span class="number">1</span>]:</div><div class="line">                    disk_type = <span class="string">'HDD'</span></div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    disk_type = <span class="string">'SSD'</span></div><div class="line">                <span class="keyword">break</span></div><div class="line">        <span class="keyword">return</span> disk_type</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_pd_type</span><span class="params">(self, sas_address)</span>:</span></div><div class="line">        disk_type = <span class="string">''</span></div><div class="line">        controllers = self.get_controllers()</div><div class="line">        <span class="keyword">for</span> controller <span class="keyword">in</span> controllers:</div><div class="line">            cmd = <span class="string">'sas3ircu &#123;&#125; display|grep -E "SAS Address|Drive Type"'</span>.format(controller)</div><div class="line">            output = do_shell(cmd)</div><div class="line">            lines = output.splitlines()</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">0</span>, len(lines), <span class="number">2</span>):</div><div class="line">                address = lines[i].split()[<span class="number">-1</span>].replace(<span class="string">'-'</span>, <span class="string">''</span>)</div><div class="line">                <span class="keyword">if</span> address <span class="keyword">in</span> sas_address:</div><div class="line">                    <span class="keyword">if</span> <span class="string">'HDD'</span> <span class="keyword">in</span> lines[i + <span class="number">1</span>]:</div><div class="line">                        disk_type = <span class="string">'HDD'</span></div><div class="line">                    <span class="keyword">else</span>:</div><div class="line">                        disk_type = <span class="string">'SSD'</span></div><div class="line">                    <span class="keyword">break</span></div><div class="line">            <span class="keyword">if</span> disk_type != <span class="string">''</span>:</div><div class="line">                <span class="keyword">break</span></div><div class="line">        <span class="keyword">return</span> disk_type</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_controllers</span><span class="params">(self)</span>:</span></div><div class="line">        cmd = <span class="string">'sas3ircu list | awk \'&#123;print $1&#125;\''</span></div><div class="line">        list = do_shell(cmd).splitlines()</div><div class="line">        index = list.index(<span class="string">'Index'</span>) + <span class="number">2</span></div><div class="line">        controllers = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(index, len(list) - <span class="number">1</span>):</div><div class="line">            controllers.append(list[i])</div><div class="line">        <span class="keyword">return</span> controllers</div></pre></td></tr></table></figure><h2 id="调用方式"><a href="#调用方式" class="headerlink" title="调用方式"></a>调用方式</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> mcs3.raidcardutils <span class="keyword">import</span> RaidCardToolFactory</div><div class="line"></div><div class="line">tool = RaidCardToolFactory().getTool()</div><div class="line">disk_type = tool.get_disk_type(disk_name)</div></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>其实这其中的关键就是先找到每一块物理盘的唯一标识，然后我们根据工具获取列表中的唯一标识字段，获取逻辑盘对应的信息，就比如上面的<code>Device Id</code>，对应的是逻辑盘的<code>target id</code>。</p><blockquote><p>完整代码地址：<a href="https://github.com/tony-yin/RaidCardTool/" target="_blank" rel="external">https://github.com/tony-yin/RaidCardTool/</a><br>如果有所帮助的话，帮忙<code>star</code>一下哦 ^_^</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/raid-600x450.png&quot; alt=&quot;RaidCardToolUtils&quot;&gt;&lt;/center&gt;

&lt;p&gt;网上很多获取一块盘是否为&lt;code&gt;SSD&lt;/code&gt;的方式都是不靠谱的，不能覆盖到所有情况。一般我们在操作系统上的硬盘都是虚拟出来的逻辑盘，比如&lt;code&gt;/dev/sda&lt;/code&gt;这种，它可能对应一块单独的物理硬盘，也有可能对应的是几块盘组成的&lt;code&gt;raid&lt;/code&gt;。我们有时候想获取一块盘的具体信息，比如磁盘类型、插槽号、序列号等等，这时候我们就得借助对应的&lt;code&gt;raid&lt;/code&gt;卡工具了，最常见的如&lt;code&gt;Megacli&lt;/code&gt;，通过逻辑盘找到对应的物理盘，然后读取信息。&lt;/p&gt;
    
    </summary>
    
      <category term="tech" scheme="https://tony-yin.github.io/categories/tech/"/>
    
    
      <category term="Ceph" scheme="https://tony-yin.github.io/tags/Ceph/"/>
    
      <category term="Raidcard" scheme="https://tony-yin.github.io/tags/Raidcard/"/>
    
  </entry>
  
  <entry>
    <title>Daily Article Vol 1 - (2017/11/1 ~ 2017/12/31)</title>
    <link href="https://tony-yin.github.io/2018/01/01/Daily-Article-2017/"/>
    <id>https://tony-yin.github.io/2018/01/01/Daily-Article-2017/</id>
    <published>2018-01-01T02:13:25.000Z</published>
    <updated>2018-01-08T06:00:28.779Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/2018-1b.png" alt="Daily Article"></center><p>书籍可以系统的学习一些知识，并且需要比较长的时间集中注意力学习。而现在网络越来越发达，各种社区的流行，还有开源分享精神的传播，导致现在互联网上很多优秀文章、博客、微信公众号等出现，这些文章贴近热点，往往都很新，并且篇幅有长有短，我们可以利用一些碎片时间来吸收这些知识。优秀文章很多，所以每天读个一两篇文章可以作为一个习惯养成，这样日积月累相信会获益良多。</p><p><code>Daily Article</code>系列就是为了记录我每天的阅读历程，以月为单位，每个月出一篇大的总结，一是为了约束自己每天按时按量阅读，也给自己打气，二是给自己每个月的阅读内容做一个总结，用于回头阅读，三是将其中有质量的内容分享给有需要的人。由于我是从<code>2017</code>九月才可以记录，所以趁着年底索性把十一和十二月的记录一次性发出来。</p><p>目前我采取星星的方式给文章评级，最高三颗星，最低没有星星，一般我放上来的都不会是太水的文章，所以如果是一般的工具类或者没有很大特色的文章我不会进行标记。一颗星表示<code>good</code>，即这篇文章有特色，对自己有帮助；两颗星表示<code>verygood</code>，说明这篇文章内容很好，有深度有广度，是一篇很有质量的文章；三颗星表示<code>excellent</code>，说明这篇文章不仅内容技术讲的很到位，文章文笔也很出色，实践结合理论，让人很容易理解，看完后收获很大或者是顿悟，总而言之是一片很优秀的文章。当然我还会在这三个等级中结合半个星星进行调节，反正就是对文章的一个个人看法而已，仁者见仁，智者见智吧。</p><a id="more"></a><h2 id="十一月"><a href="#十一月" class="headerlink" title="十一月"></a>十一月</h2><ol><li><a href="http://www.xuxiaopang.com/08/23/easy-ceph-CephX/" target="_blank" rel="external">大话 Ceph – CephX 那点事儿</a>(11/15-11/17) <i class="fa fa-star"></i><i class="fa fa-star"></i></li><li><a href="http://mp.weixin.qq.com/s/UiDd-1zwrqIsk3-KEcAQaA" target="_blank" rel="external">互联网架构为什么要做服务化？</a>(11/18) <i class="fa fa-star"></i></li><li><a href="http://blog.csdn.net/liuaigui/article/details/7163482" target="_blank" rel="external">基于开源软件构建高性能集群NAS系统</a>(11/20)</li><li><a href="http://blog.csdn.net/whycold/article/details/11898249" target="_blank" rel="external">虚拟IP原理</a>(11/21)</li><li><a href="http://mp.weixin.qq.com/s/8aI9jS0SXJl5NdcM3TPYuQ" target="_blank" rel="external">究竟为什么要引入数据库中间件</a>(11/27) <i class="fa fa-star"></i><i class="fa fa-star-half-full"></i></li><li><a href="https://time.geekbang.org/column/article/183" target="_blank" rel="external">程序员如何用技术变现（上）</a>(11/28)</li><li><a href="https://time.geekbang.org/column/article/294" target="_blank" rel="external">Go语言，Docker和新技术</a>(11/28)</li><li><a href="https://h5.ele.me/hongbao/#hardware_id=&amp;is_lucky_group=True&amp;lucky_number=10&amp;track_id=&amp;platform=0&amp;sn=29dad164ef30a0c9&amp;theme_id=1745&amp;device_id=" target="_blank" rel="external">秒杀系统架构优化思路</a>(11/29) <i class="fa fa-star"></i></li></ol><h2 id="十二月"><a href="#十二月" class="headerlink" title="十二月"></a>十二月</h2><ol><li><a href="https://time.geekbang.org/column/article/294" target="_blank" rel="external">Ceph开发每周谈首发</a>(12/1)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-1/" target="_blank" rel="external">Ceph开发每周谈Vol2</a>(12/4)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-1/" target="_blank" rel="external">Ceph开发每周谈Vol3</a>(12/5)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-1/" target="_blank" rel="external">Ceph开发每周谈Vol4</a>(12/5)</li><li><a href="https://www.thomas-krenn.com/en/wiki/Ext4_Filesystem" target="_blank" rel="external">Ext4 Filesystem</a>(12/11)</li><li><a href="https://www.hecticgeek.com/2015/01/ext4-external-hard-disk-busy-at-idle-fix/" target="_blank" rel="external">Formatted ‘Ext4’ External Hard Disk is Busy</a>(12/12)</li><li><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=bfff68738f1cb5c93dab1114634cea02aae9e7ba" target="_blank" rel="external">Ext4lazyinit detail</a>(12/12)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-5/" target="_blank" rel="external">Ceph开发每周谈Vol5</a>(12/13)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-6/" target="_blank" rel="external">Ceph开发每周谈Vol6</a>(12/13)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-7/" target="_blank" rel="external">Ceph开发每周谈Vol7</a>(12/13)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-8/" target="_blank" rel="external">Ceph开发每周谈Vol8—社区加快开发节奏, CDS 变更为 CDM, Firefly 结束版本支持</a>(12/13)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-9/" target="_blank" rel="external">Ceph开发每周谈Vol9—Ceph开发每周谈 Vol 9—加密、压缩、EC 全场景支持</a>(12/13)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-10/" target="_blank" rel="external">Ceph开发每周谈 Vol 10—NFS 已经被 RadosGW 支持|用户态</a>(12/13)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-11/" target="_blank" rel="external">Ceph开发每周谈 Vol 11—RadosGW 支持 KeyStone V3, AWS v4, 多站点多活</a>(12/13)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-12/" target="_blank" rel="external">Ceph开发每周谈 Vol 12—Scrub 增强，Jewel 小结</a>(12/13)</li><li><a href="http://link.zhihu.com/?target=https%3A//opensource.com/life/16/10/introduction-linux-filesystems" target="_blank" rel="external">An introduction to Linux filesystems</a>(12/15 ~ 12/17) <i class="fa fa-star"></i><i class="fa fa-star"></i></li><li><a href="http://www.cnblogs.com/ggjucheng/archive/2012/01/08/2316599.html" target="_blank" rel="external">linux lsof命令详解</a>(12/18)</li><li><a href="http://blog.csdn.net/stpeace/article/details/47069215" target="_blank" rel="external">linux中的ldd命令简介</a>(12/18)</li><li><a href="http://blog.csdn.net/qq_26819733/article/details/50610129" target="_blank" rel="external">linux–&gt;ldd命令的介绍</a>(12/18)</li><li><a href="http://www.cnblogs.com/lyongde/p/4190588.html" target="_blank" rel="external">【Linux笔记】ldconfig、ldd</a>(12/18)</li><li><a href="https://zhuanlan.zhihu.com/p/27875337" target="_blank" rel="external">Linux 的 EXT4 文件系统的历史、特性以及最佳实践</a>(12/18) <i class="fa fa-star"></i><i class="fa fa-star"></i> </li><li><a href="http://www.ruanyifeng.com/blog/2011/12/inode.html" target="_blank" rel="external">理解inode</a>(12/18)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-13/" target="_blank" rel="external">Ceph开发每周谈 Vol 13 — Cache on SPDK / bufferlist</a>(12/19)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-14/" target="_blank" rel="external">Ceph开发每周谈 Vol 14 — LDAP/ BlueStore SMR</a>(12/19)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-15/" target="_blank" rel="external">Ceph开发每周谈 Vol 15—Unix Socket / BlueStore 压缩和 Checksum</a>(12/19)</li><li><a href="https://opensource.com/life/15/9/everything-is-a-file" target="_blank" rel="external">Everything is a file</a>(12/21) <i class="fa fa-star"></i><i class="fa fa-star"></i></li><li><a href="http://www.tldp.org/LDP/sag/html/dev-fs.html" target="_blank" rel="external">Overview of the Directory Tree</a>(12/21)</li><li><a href="https://www.xsky.com/news/20171218/" target="_blank" rel="external">没错，它就是存储界的“大胃王”</a>(12/22)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-16/" target="_blank" rel="external">Ceph开发每周谈 Vol 16—Jewel RC Release!</a>(12/22)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-17/" target="_blank" rel="external">Ceph开发每周谈 Vol 17 — ARM Status | RBD 一致性组合 | 内核模块 转至元数据结尾</a>(12/22)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-18/" target="_blank" rel="external">Ceph开发每周谈 Vol 18 — EXT4 废弃论战? | 去重支持</a>(12/22)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-19/" target="_blank" rel="external">Ceph开发每周谈Vol19 | Ceph Next 2016 闭门会议资讯独家大放送</a>(12/26)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-20/" target="_blank" rel="external">Ceph开发每周谈Vol 20 | NVMe Over Fabric/Kernel Multi Queue</a>(12/26)</li><li><a href="http://mp.weixin.qq.com/s/h9mz5gWN8tKRz8by2-Sn6w" target="_blank" rel="external">Ceph开发每周谈Vol 104 | NFS Ganesha VS Kernel Client</a>(12/27)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-21/" target="_blank" rel="external">Ceph开发每周谈Vol 21 | ZetaScale | CMP/WriteSame</a>(12/27)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-22/" target="_blank" rel="external">Ceph开发每周谈Vol 22 | 全球最大Ceph集群到底有多大？</a>(12/28)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-23/" target="_blank" rel="external">Ceph开发每周谈vol23｜BlueStore新动向</a>(12/28)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-24/" target="_blank" rel="external">Ceph开发每周谈 Vol 24｜Jewel 10.2.1 第一个 Bug 修复版本释出</a>(12/28)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-24-2/" target="_blank" rel="external">Ceph开发每周谈 Vol 25 | Ceph &amp; DPDK 网络插件开源</a>(12/29)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-27/" target="_blank" rel="external">Ceph开发每周谈Vol 27｜主线分支默认启用 AsyncMessenger</a>(12/29)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-28/" target="_blank" rel="external">Ceph开发每周谈 Vol 28 | OSD 心跳 | Jewel RBD 测试</a>(12/30)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-29/" target="_blank" rel="external">Ceph开发每周谈 Vol 29 — RBD Cache 警告: 数据不一致风险</a>(12/30)</li><li><a href="https://www.xsky.com/tec/ceph-weekly-vol-30/" target="_blank" rel="external">Ceph开发每周谈 Vol 30 — ISA-L 和 BlueStore 性能有哪些进展？</a>(12/30)</li><li><a href="http://blog.csdn.net/haoel/article/details/2879" target="_blank" rel="external">用GDB调试程序（一）</a>(12/31) <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i></li><li><a href="http://blog.csdn.net/haoel/article/details/2880" target="_blank" rel="external">用GDB调试程序（二）</a>(12/31) <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i></li><li><a href="http://blog.csdn.net/haoel/article/details/2881" target="_blank" rel="external">用GDB调试程序（三）</a>(12/31) <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i></li><li><a href="http://blog.csdn.net/haoel/article/details/2882" target="_blank" rel="external">用GDB调试程序（四）</a>(12/31) <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i></li><li><a href="http://blog.csdn.net/haoel/article/details/2883" target="_blank" rel="external">用GDB调试程序（五）</a>(12/31) <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i></li><li><a href="http://blog.csdn.net/haoel/article/details/2884" target="_blank" rel="external">用GDB调试程序（六）</a>(12/31) <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i></li><li><a href="http://blog.csdn.net/haoel/article/details/2885" target="_blank" rel="external">用GDB调试程序（七）</a>(12/31) <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i></li><li><a href="http://www.zphj1987.com/2017/04/26/rados-put-strip-debug/" target="_blank" rel="external">rados put striper功能的调试</a>(12/31) <i class="fa fa-star"></i></li><li><a href="https://ivanjobs.github.io/2016/05/11/prepare-ceph-dev-env.html" target="_blank" rel="external">准备Ceph开发环境</a>(12/31) <i class="fa fa-star"></i></li><li><a href="https://my.oschina.net/u/2460844/blog/515353" target="_blank" rel="external">ceph编译源码、单机搭建调试环境</a>(12/31) <i class="fa fa-star"></i></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/2018-1b.png&quot; alt=&quot;Daily Article&quot;&gt;&lt;/center&gt;

&lt;p&gt;书籍可以系统的学习一些知识，并且需要比较长的时间集中注意力学习。而现在网络越来越发达，各种社区的流行，还有开源分享精神的传播，导致现在互联网上很多优秀文章、博客、微信公众号等出现，这些文章贴近热点，往往都很新，并且篇幅有长有短，我们可以利用一些碎片时间来吸收这些知识。优秀文章很多，所以每天读个一两篇文章可以作为一个习惯养成，这样日积月累相信会获益良多。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Daily Article&lt;/code&gt;系列就是为了记录我每天的阅读历程，以月为单位，每个月出一篇大的总结，一是为了约束自己每天按时按量阅读，也给自己打气，二是给自己每个月的阅读内容做一个总结，用于回头阅读，三是将其中有质量的内容分享给有需要的人。由于我是从&lt;code&gt;2017&lt;/code&gt;九月才可以记录，所以趁着年底索性把十一和十二月的记录一次性发出来。&lt;/p&gt;
&lt;p&gt;目前我采取星星的方式给文章评级，最高三颗星，最低没有星星，一般我放上来的都不会是太水的文章，所以如果是一般的工具类或者没有很大特色的文章我不会进行标记。一颗星表示&lt;code&gt;good&lt;/code&gt;，即这篇文章有特色，对自己有帮助；两颗星表示&lt;code&gt;very
good&lt;/code&gt;，说明这篇文章内容很好，有深度有广度，是一篇很有质量的文章；三颗星表示&lt;code&gt;excellent&lt;/code&gt;，说明这篇文章不仅内容技术讲的很到位，文章文笔也很出色，实践结合理论，让人很容易理解，看完后收获很大或者是顿悟，总而言之是一片很优秀的文章。当然我还会在这三个等级中结合半个星星进行调节，反正就是对文章的一个个人看法而已，仁者见仁，智者见智吧。&lt;/p&gt;
    
    </summary>
    
      <category term="read" scheme="https://tony-yin.github.io/categories/read/"/>
    
    
      <category term="Read" scheme="https://tony-yin.github.io/tags/Read/"/>
    
      <category term="Daily-Article" scheme="https://tony-yin.github.io/tags/Daily-Article/"/>
    
  </entry>
  
  <entry>
    <title>译：一切皆文件</title>
    <link href="https://tony-yin.github.io/2017/12/21/Everything-is-a-file/"/>
    <id>https://tony-yin.github.io/2017/12/21/Everything-is-a-file/</id>
    <published>2017-12-21T07:34:32.000Z</published>
    <updated>2017-12-21T07:36:22.516Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/file-600x450.png" alt="Everything is a file"></center><p>这里先提一个技巧性的问题:以下哪一个是文件?</p><ul><li>目录</li><li><code>Shell</code>脚本</li><li><code>Office</code>文档</li><li>串行端口（<code>Serial ports</code>）</li><li>内核数据结构</li><li>内核调优参数</li><li>硬盘驱动器</li><li>分区</li><li>逻辑卷（<code>LVM</code>）</li><li>打印机</li><li>套接字（<code>Sockets</code>）</li></ul><p>也许你不会相信，但是对于<code>Unix</code>和<code>Linux</code>，它们都是文件。这是最令人惊奇的概念之一——这样做使得许多管理任务可以被一些非常简单但功能强大的方法执行，否则这些任务实现起来可能非常困难甚至不可能。</p><a id="more"></a><h2 id="备份主引导记录"><a href="#备份主引导记录" class="headerlink" title="备份主引导记录"></a>备份主引导记录</h2><p>举个简单任务的例子，考虑一下为你的硬盘驱动器地主引导记录（<code>MBR</code>）做一个备份工作。有时候我需要恢复或重新创建我的<code>MBR</code>，尤其是分区表。从头开始重新创建它是非常困难的。但是从保存好的文件中恢复出来这是非常容易的。<code>Linux</code>有一个很强大的<code>GNU</code>工具 — <code>dd</code>，它可以实现这个和其他很多功能。</p><p><code>dd</code>表示<code>disk dump</code>的缩写，意为“磁盘转储”，但是我们很多资深管理员一直认为它是<code>disk destroyer</code>的缩写，因为如果你不是很小心的话，这个工具会准确无误地执行你告诉它要做的事情，包括将硬盘上或者分区上所有的数据都破坏掉。</p><p>以下命令将会备份你的<code>MBR</code>，它必须要是<code>root</code>用户执行，因为非<code>root</code>用户没有访问<code>/dev</code>目录下硬盘驱动器<a href="https://en.wikipedia.org/wiki/Device_file" target="_blank" rel="external">设备文件</a>的权限。<code>BS</code>是<code>Block Size</code>缩写，表示块大小，<code>count</code>表示从源文件读取的块的个数。这个命令将在<code>/tmp</code>目录创建一个<code>myMBR.bak</code>的文件。这个文件的大小将为<code>512</code>字节，包含了<code>MBR</code>的内容，包括引导代码和分区表等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dd if=/dev/sda of=/tmp/myMBR.bak bs=512 count=1</div></pre></td></tr></table></figure><p>如果<code>MBR</code>被损坏了，就需要引导到一个修复盘并执行下面的命令，这个命令本质上就是上面的反向操作。值得注意的是这条命令没有必要指定块大小和块个数这两个参数，因为<code>dd</code>命令将会把备份文件简单地拷贝到硬盘的第一个扇区，并且当它执行到源文件末尾后停止。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dd if=/tmp/myMBR.bak of=/dev/sda</div></pre></td></tr></table></figure><h2 id="都是文件系统的一部分"><a href="#都是文件系统的一部分" class="headerlink" title="都是文件系统的一部分"></a>都是文件系统的一部分</h2><p><code>Linux</code>计算机上的所有内容都可以作为文件系统空间的文件被访问。这是非常重要的，这使得我们 可以<a href="http://yarchive.net/comp/linux/everything_is_file.html" target="_blank" rel="external">使用通用的工具访问不同的东西</a>。</p><p><code>dd</code>命令可用于将硬盘的整个分区拷贝到一个文件或者如下所示的其他硬盘。在这里<code>dd</code>命令再次将数据拷贝到输入设备的末尾并停止。请确保输出设备的容量要大于输入设备。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">dd if=/dev/sdf2 of=/dev/sdg3</div><div class="line"></div><div class="line">dd if=/dev/sda of=/dev/sdg</div></pre></td></tr></table></figure><p>此外文件系统还有其他工具可以达到此作用。比如，<code>cat</code>命令可以用来将任意文件的内容发送到标准输出，这包括分区和整个硬盘。然后，输出还可以被重定向到一个文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat /dev/sda1 &gt; partition1.backup</div></pre></td></tr></table></figure><p>但是，<code>cat</code>命令没有<code>dd</code>命令的控制功能。例如，不能指定从源设备或者源文件读取的数据量。</p><p>下面是一个有趣的实验，它将正面一切皆文件的事实。大多数<code>Linux</code>发行版都有多个虚拟控制台，其中<code>1</code>到<code>7</code>可以用来登录到一个带有<code>shell</code>接口的本地控制台会话。可以通过一些组合键访问它们，比如<code>Ctrl-Alt-F1</code>是控制台<code>1</code>，<code>Ctrl-Alt-F2</code>是控制台2，以此类推。</p><p>按<code>Ctrl-Alt-F2</code>切换到控制台2。在一些发行版中，登录信息包括与此控制台相关的<code>tty</code>（<code>Teletype</code>）设备，但是也有很多发行版不包括。页面应该显示<code>tty2</code>的信息，因为你当前在控制台<code>2</code>。</p><p>用一个非<code>root</code>登录，你可以通过<code>who am i</code>这个命令来确定哪一个<code>tty</code>设备连接到当前控制台。</p><p>在我们实际执行这个实验之前，请看一下<code>/dev</code>目录下的<code>tty2</code>和<code>tty3</code>设备的列表清单。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ls -l /dev tty[23]</div></pre></td></tr></table></figure><p>有大量的定义过的<code>tty</code>设备，但是它们其中的大多数我们并不关心，我们只关系<code>tty2</code>和<code>tty3</code>设备。作为设备文件，它们没有什么特殊之处；它们只是简单的字符类型的设备。我们将用这些设备做这个实验。<code>tty2</code>设备连接到虚拟控制台<code>2</code>，<code>tty3</code>设备连接到虚拟控制台<code>3</code>。</p><p>按<code>Ctrl-Alt-F3</code>组合键切换到控制台<code>3</code>，再次以同样的非<code>root</code>用户登录。</p><p>现在在控制台<code>3</code>输入以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">echo &quot;Hello world&quot; &gt; /dev/tty2</div></pre></td></tr></table></figure><p>按<code>Ctrl-Alt-F2</code>组合键返回控制台<code>2</code>。字符串“Hello world”（没有引号）将显示在控制台<code>2</code>上。</p><p>这个实验也可以在<code>GUI</code>桌面的终端模拟器上进行。桌面上的终端会话在<code>/dev</code>树中使用伪终端设备，比如<code>/dev/pts/1</code>。通过<code>Konsole</code>或者<code>Xterm</code>开启两个终端会话，确定它们连接到哪个伪终端后，使用其中一个发送消息给另一个。</p><p>现在继续试验，使用<code>cat</code>命令在不同的终端显示<code>/etc/fstab</code>文件。</p><p>另一个有趣的实验是使用<code>cat</code>命令直接将文件打印到打印机上。假设你的打印机设备是<code>/dev/usb/lp0</code>，并且你的打印机可以直接打印<code>PDF</code>文件，下面的命令将会在你的打印机上打印一个<code>PDF</code>文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat test.pdf &gt; /dev/usb/lp0</div></pre></td></tr></table></figure><p><code>dd</code>命令也可以用来打印一个准备打印的文件。不过，我认为<code>cat</code>命令实际上更适合这个任务。</p><h2 id="“一切皆文件”的含义"><a href="#“一切皆文件”的含义" class="headerlink" title="“一切皆文件”的含义"></a>“一切皆文件”的含义</h2><p>“一切都是文件”的含义是深远的，远远超过了像这篇文章所列举的那样。你们已经在前面的实验中看到过一些例子，但这里有一个包含这些和更多的简短列表。</p><ol><li>克隆硬盘。</li><li>备份分区。</li><li>备份主引导记录(<code>MBR</code>)。</li><li>在<code>u</code>盘上安装<code>ISO</code>镜像。</li><li>与其他终端用户沟通。</li><li>将文件打印到打印机。</li><li>更改<code>/proc pseudo</code>文件系统中的某些文件的内容，以修改运行内核的配置参数。</li><li>用随机数据或零覆盖文件、分区或整个硬盘驱动器。</li><li>将不需要的输出重定向到<code>/dev/null</code>设备，它将永远不会显示。</li><li>等等，等等，等等。。。</li></ol><p>这里有太多的例子，任何一个列表都只是表面的一部分。我相信，你肯定会想出或指出许多比我这里提到更有创造性的方式，来使用<code>Linux</code>的这个特性。我很乐意看到你对如何使用“一切都是文件”的评论。</p><h2 id="附加信息"><a href="#附加信息" class="headerlink" title="附加信息"></a>附加信息</h2><p>有关<code>/dev/</code>目录和你可能在那里找到的设备的更多信息，请参阅<code>Linux Journal</code>上的<a href="http://www.linuxjournal.com/article/2597" target="_blank" rel="external">这篇文章</a>。有关单个设备的更详细信息，<a href="http://www.tldp.org/" target="_blank" rel="external">Linux文档项目</a>中的<a href="http://www.tldp.org/LDP/sag/html/dev-fs.html" target="_blank" rel="external">这篇文章</a>和<a href="http://www.tldp.org/LDP/Linux-Filesystem-Hierarchy/html/dev.html" target="_blank" rel="external">这篇文章</a>会有所帮助。</p><blockquote><p>原文地址：<a href="https://opensource.com/life/15/9/everything-is-a-file" target="_blank" rel="external">https://opensource.com/life/15/9/everything-is-a-file</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/file-600x450.png&quot; alt=&quot;Everything is a file&quot;&gt;&lt;/center&gt;

&lt;p&gt;这里先提一个技巧性的问题:以下哪一个是文件?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目录&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Shell&lt;/code&gt;脚本&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Office&lt;/code&gt;文档&lt;/li&gt;
&lt;li&gt;串行端口（&lt;code&gt;Serial ports&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;内核数据结构&lt;/li&gt;
&lt;li&gt;内核调优参数&lt;/li&gt;
&lt;li&gt;硬盘驱动器&lt;/li&gt;
&lt;li&gt;分区&lt;/li&gt;
&lt;li&gt;逻辑卷（&lt;code&gt;LVM&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;打印机&lt;/li&gt;
&lt;li&gt;套接字（&lt;code&gt;Sockets&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也许你不会相信，但是对于&lt;code&gt;Unix&lt;/code&gt;和&lt;code&gt;Linux&lt;/code&gt;，它们都是文件。这是最令人惊奇的概念之一——这样做使得许多管理任务可以被一些非常简单但功能强大的方法执行，否则这些任务实现起来可能非常困难甚至不可能。&lt;/p&gt;
    
    </summary>
    
      <category term="read" scheme="https://tony-yin.github.io/categories/read/"/>
    
    
      <category term="Linux" scheme="https://tony-yin.github.io/tags/Linux/"/>
    
      <category term="Filesystem" scheme="https://tony-yin.github.io/tags/Filesystem/"/>
    
  </entry>
  
  <entry>
    <title>译：Linux 文件系统介绍</title>
    <link href="https://tony-yin.github.io/2017/12/17/Linux-Filesystem/"/>
    <id>https://tony-yin.github.io/2017/12/17/Linux-Filesystem/</id>
    <published>2017-12-17T14:01:15.000Z</published>
    <updated>2017-12-21T07:42:57.680Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/filesystem-600x450.png" alt="Linux Filesystem"></center><p>本文旨在对<code>Linux</code>文件系统概念进行深层次的讨论。本文既不准备对某个特定类型的文件系统（比如<code>ext4</code>）进行基础性的描述，也不打算作为一个讲解文件系统命令的教程。</p><a id="more"></a><p>每台通用的计算机都需要把各种类型的数据存储在硬盘驱动器(<code>HDD</code>)或者一些同样功能的设备上，比如<code>USB</code>。存储在这些设备上有几个原因，首先,<code>RAM</code>会在计算机电源关闭时丢失内容，虽然也有非易失性类型的内存，可以在电源关闭后维持数据存储不丢失(如<code>flash</code>内存也就是闪存使用的<code>USB</code>和固态硬盘)，但<code>flash</code>内存要比一些标准的、挥发性的内存比如<code>DDR3</code>和其他类似的类型昂贵的多。</p><p>数据需要存储在硬盘驱动器上的第二个原因是，即使是标准的<code>RAM</code>也要比磁盘空间更昂贵。<code>RAM</code>和磁盘成本都在迅速下降，但如果按每字节的成本来算的话还是<code>RAM</code>更高。我们就基于<code>16GB RAM</code>和<code>2TB</code>硬盘的成本，快速计算其每个字节的成本，结果显示  <code>RAM</code>比硬盘驱动器的价格高约<code>71</code>倍。目前，<code>RAM</code>的典型成本大约每字节<code>0.0000000043743750</code>。</p><p>更加直截了当说的话，在计算机的早期，一种内存是基于<code>CRT</code>屏幕上的点的，每一比特大约<code>1</code>美元，这是非常非常昂贵的!</p><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>你也许会听到人们经常以不同的或者混淆的方式谈论文件系统这个词。这个词本身可能有多重含义，你可能需要从讨论或文档的语境中辨别真正的意思。</p><p>我将尝试根据我在不同情况下使用它的方式来定义“文件系统”的各种含义。注意，在试图遵循标准的“official”含义时，我的意图是根据它的各种用法定义术语。在本文后面的小节中，将更详细地讨论这些含义。</p><ol><li>整个<code>Linux</code>目录结构从顶部(/)根目录开始。</li><li>各种特定类型的数据存储格式，如<code>EXT3</code>、<code>EXT4</code>、<code>BTRFS</code>、<code>XFS</code>等。<code>Linux</code>支持近<code>100</code>种类型的文件系统，包括一些非常古老的文件系统，以及一些最新的文件系统。每个文件系统类型都使用自己的元数据结构来定义如何存储和访问数据。</li><li>一个分区或被格式化为特定类型文件系统的逻辑卷，可以被挂载到<code>Linux</code>文件系统上的指定挂载点上。</li></ol><h2 id="基本的文件系统功能"><a href="#基本的文件系统功能" class="headerlink" title="基本的文件系统功能"></a>基本的文件系统功能</h2><p>磁盘存储是必需的，它带来了一些有趣且不可避免的细节。显然，文件系统的设计目的是为数据的非易失性存储提供空间，这是它的最根本的功能。但是它还有许多其他重要的功能满足不同的需求。</p><p>所有文件系统都需要提供一个命名空间（<code>namespace</code>）——即一个命名和组织的方法。它定义了如何命名文件，具体来说是文件名的长度和可用于文件名的字符的子集，这些字符可以从全部字符集中获取。它还定义了磁盘上数据的逻辑结构，例如使用目录来组织文件，而不是将它们集中在一个单一的、巨大的文件集中。</p><p>一旦定义了名称空间，就需要一个元数据结构来为该名称空间提供逻辑基础。其中元数据包括支持分层目录结构所需的数据结构；用于确定磁盘上哪些块空间已经被使用和哪些可用的结构；允许维护文件和目录名称的结构；文件相关的信息，比如它们的大小和时间，比如创建时间、修改时间或最后访问时间等等；以及属于文件的数据在磁盘上面的位置。还有一些其他元数据用于存储关于磁盘划分的高级信息，如逻辑卷和分区。这个更高级别的元数据和它所代表的结构包含了描述存储在驱动器或分区上的文件系统的信息，这些元数据独立于上面提到的一般文件系统元数据。</p><p>文件系统还需要<code>API</code>接口为系统函数调用提供访问，这些系统函数调用操作文件和目录等文件系统对象。<code>APIs</code>提供诸如创建、移动和删除文件之类的接口。它还提供了一些算法来确定文件放置在文件系统上的位置。这些算法还有确定速度或最小化磁盘碎片等作用。</p><p>现代文件系统还提供了一个安全模式，它是一个为文件和目录定义访问权限的方案。<code>Linux</code>文件系统安全模式有助于确保用户只能访问他们自己的文件，而不是其他人或操作系统本身的文件。</p><p>最后的构建块是实现所有这些功能所需的软件。为了改提高系统和程序员效率，<code>Linux</code>使用了一种<code>two-part</code>的软件实现方式。</p><center><img src="http://ow0mgad6r.bkt.clouddn.com/filesystem_diagram.png" alt="filesystem diagram"></center><br><center>图1：Linux two-part 文件系统软件实现方式</center><p>这两部分实现的第一部分是<code>Linux</code>虚拟文件系统。这个虚拟文件系统为内核和开发人员提供了访问<strong>所有类型</strong>文件系统的一组命令。虚拟文件系统软件调用特定的设备驱动程序来连接到各种类型的文件系统。文件系统特定的设备驱动程序是实现的第二部分。设备驱动程序将文件系统命令的标准集根据特定分区或逻辑卷上的文件系统类型做转换和解释。</p><h2 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h2><p>作为一个通常很有条理的处女座，我喜欢把东西放在那些小而有组织的地方，而不是一个大的桶。使用目录可以帮助我存储和定位我想找的文件。目录也被称为文件夹，因为它们可以被看作实际生活中办公桌上保存文件的文件夹。</p><p>在<code>Linux</code>和许多其他操作系统中，目录可以以树状的层次结构来构造。<code>Linux</code>目录结构在<a href="http://www.pathname.com/fhs/" target="_blank" rel="external">Linux文件系统层次标准(FHS)</a>中得到了很好的定义和记录。在访问它们时引用这些目录是通过使用由前斜杠(<code>/</code>)连接的顺序较深的目录名称(<code>/</code>)来实现的，例如<code>/var/log</code>和<code>/var/spool/mail</code>。这些被称为路径。</p><p>下表提供了一个非常简短的标准、众所周知的和定义在顶层上的<code>Linux</code>目录及其用途的列表。</p><center><img src="http://ow0mgad6r.bkt.clouddn.com/linux-filesystaem.png" alt="top level directory"></center><br><center>表1：Linux文件系统层次结构的顶层</center><p>表<code>1</code>中显示的目录及其子目录及其子目录的子目录，其中背景色为蓝色的目录被认为是根文件系统中不能缺少的组成部分。也就是说，它们不能作为单独的文件系统创建，并且在启动时安装。这是因为它们(特别是它们的内容)必须在引导时出现，以便系统正确引导。</p><p><code>/media</code>和<code>/mnt</code>目录是根文件系统的一部分，但它们不应该包含任何数据。相反，它们只是临时的挂载点。<br>其余的目录，在表<code>1</code>中没有背景颜色的目录不需要在引导序列中出现，但是会在以后安装，在启动序列中准备主机来执行有用的工作。</p><p>可以通过参考官方的<a href="http://www.pathname.com/fhs/" target="_blank" rel="external">Linux文件系统层次标准</a><code>(FHS)web</code>页面，以了解这些目录及其许多子目录的详细信息。维基百科对<code>FHS</code>的描述也很好。应尽可能密切地遵循这一标准，以确保业务和职能的一致性。不管主机上使用的文件系统类型是什么，这个分层目录结构都是相同的。</p><h2 id="Linux-统一目录结构"><a href="#Linux-统一目录结构" class="headerlink" title="Linux 统一目录结构"></a>Linux 统一目录结构</h2><p>在一些非<code>linux PC</code>操作系统中，如果有多个物理硬盘或多个分区，每个磁盘或分区都被分配一个驱动器号。想定位到文件或程序所在的硬盘的位置，驱动器号是必需的，比如<code>C:</code>或<code>D:</code>。然后，以命令的形式发出驱动器字母<code>D:</code>例如，要更改到<code>D:</code>驱动器，然后使用<code>cd</code>命令更改到正确的目录来定位所需的文件。每个硬盘都有自己独立的和完整的目录树。</p><p><code>Linux</code>文件系统将所有物理硬盘和分区统一到一个目录结构中。这一切都是从顶部(<code>/</code>)目录开始的。所有其他目录及其子目录都位于<code>Linux</code>根目录下。这意味着只有一个单独的目录树来搜索文件和程序。</p><p>它们之所以能工作,都是因为文件系统,如<code>/home</code>、<code>/tmp</code>、<code>/var</code>、<code>/opt</code>、<code>/usr</code>可以被创建在单独的物理硬盘上一个不同的分区,或一个不同的逻辑卷<code>/</code>(根)文件系统,然后安装在一个挂载点(目录)作为根文件系统树的一部分。即使是可移动的驱动器，如闪存盘或外部<code>USB</code>或<code>ESATA</code>硬盘驱动器也将安装到根文件系统中，并成为该目录树的一个不可分割的部分。</p><p>在从一个版本的<code>Linux</code>发行版升级到另一个版本，或者从一个发行版切换成到另一个发行版时，文件系统有一个很好的理由可以做到这一点。一般来说，除了<code>Fedora</code>的<code>dnf</code>升级之类的升级工具之外，偶尔重新格式化包含操作系统的硬盘驱动器是明智的，因为在升级过程中，硬盘驱动器会清除任何随时间积累的东西。如果<code>/home</code>是根文件系统的一部分，它将被重新格式化，然后必须从备份中恢复。通过将<code>/home</code>格式化为一个单独的文件系统，那么在根文件系统格式化时它将识别成一个单独的文件系统，并且可以跳过当前步骤。这也适用于数据库、电子邮件收件箱、网站和其他可变用户和系统数据存储的目录<code>/var</code>。</p><p>维护<code>Linux</code>目录树的某些部分作为单独的文件系统还有其他原因。例如，很久以前，当我还没有意识到围绕着所有需要的<code>Linux</code>目录都作为<code>/(root)</code>文件系统的一部分的潜在问题时，我曾用大量非常大的文件填充了我的主目录。由于<code>/home</code>目录和<code>/tmp</code>目录都不是独立的文件系统，而只是根文件系统的子目录，所以整个根文件系统都被填满了。操作系统没有空间创建临时文件或扩展现有的数据文件。起初，应用程序开始抱怨没有空间保存文件，然后操作系统本身开始变得非常奇怪。引导到单用户模式，并清除我的主目录中的问题文件，这让我可以重新开始。然后，我使用一个相当标准的多文件系统设置重新安装了<code>Linux</code>，并能够防止完全的系统崩溃再次发生。</p><p>我曾经还遇到过一个情况，<code>Linux</code>主机继续运行，但是阻止用户使用<code>GUI</code>桌面登录。我能够使用一个<a href="https://en.wikipedia.org/wiki/Virtual_console" target="_blank" rel="external">虚拟控制台</a>本地使用命令行接口(<code>CLI</code>)，并远程使用<code>SSH</code>。问题是，<code>/tmp</code>文件系统已经填满了，而<code>GUI</code>桌面所需的一些临时文件在登录时无法创建。由于<code>CLI</code>登录不需要在<code>/tmp</code>中创建文件，因此缺少空间并没有阻止我使用<code>CLI</code>进行登录。在这种情况下，<code>/tmp</code>目录是一个单独的文件系统，在卷组中有大量可用的空间，<code>/tmp</code>逻辑卷是其中的一部分。我只是将<code>/tmp</code><a href="https://opensource.com/business/16/9/linux-users-guide-lvm" target="_blank" rel="external">逻辑卷扩展</a>到一个够大的容量（其实就是<code>LVM</code>扩容），以适应我对该主机所需要的临时文件空间数量的新需求，并解决了问题。请注意，此解决方案不需要重新启动，并且当<code>/tmp</code>文件系统被放大后，用户可以登录到桌面。</p><blockquote><p>逻辑卷扩展也可以参考我之前总结的一篇文章，简洁明了：<a href="http://www.tony-yin.top/2017/11/14/LVM-Space-Expansion/" target="_blank" rel="external">LVM动态扩展</a></p></blockquote><p>另一种情况发生在我在一家大型科技公司做实验室管理员的时候。我们的一个开发人员在错误的位置（<code>/var</code>）安装了应用程序（我个人认为不能说是装在错误的位置，只能说装的位置的可用空间不合适）。应用程序崩溃是因为<code>/var</code>文件系统已经满了，而存储在<code>/var/log/</code>上的日志文件由于缺少空间，不能添加新的消息。但是，由于关键的<code>/(root)</code>和<code>/tmp</code>文件系统没有填充，系统仍然保持运行。删除违规应用程序并将其重新安装到<code>/opt</code>文件系统中解决了这个问题。（其实通过<code>LVM</code>动态扩容也是可以解决这个问题，要么扩展空间大小，要么换大空间的文件系统）</p><h2 id="文件系统类型"><a href="#文件系统类型" class="headerlink" title="文件系统类型"></a>文件系统类型</h2><p><code>Linux</code>支持读取大约<code>100</code>个分区类型，它只可以在其中的几个而不是所有的分区上创建或写文件。但是，在同一个根文件系统上的不同类型的挂载文件系统是可以做到的，也是非常常见的。在此上下文中，我们讨论的是在硬盘或逻辑卷的分区上存储和管理用户数据所需的结构和元数据。这里提供了<code>Linux fdisk</code>命令识别的文件系统分区类型的完整列表，这样您就可以了解<code>Linux</code>与许多类型的系统之间的高度兼容性。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">0 Empty 24 NEC DOS 81 Minix / old Lin bf Solaris 1 FAT12 27 Hidden NTFS Win 82 Linux swap / So c1 DRDOS/sec (FAT- 2 XENIX root 39 Plan 9 83 Linux c4 DRDOS/sec (FAT- 3 XENIX usr 3c PartitionMagic 84 OS/2 hidden or c6 DRDOS/sec (FAT- 4 FAT16 &lt;32M 40 Venix 80286 85 Linux extended c7 Syrinx 5 Extended 41 PPC PReP Boot 86 NTFS volume set da Non-FS data 6 FAT16 42 SFS 87 NTFS volume set db CP/M / CTOS / . 7 HPFS/NTFS/exFAT 4d QNX4.x 88 Linux plaintext de Dell Utility 8 AIX 4e QNX4.x 2nd part 8e Linux LVM df BootIt 9 AIX bootable 4f QNX4.x 3rd part 93 Amoeba e1 DOS access a OS/2 Boot Manag 50 OnTrack DM 94 Amoeba BBT e3 DOS R/O b W95 FAT32 51 OnTrack DM6 Aux 9f BSD/OS e4 SpeedStor c W95 FAT32 (LBA) 52 CP/M a0 IBM Thinkpad hi ea Rufus alignment e W95 FAT16 (LBA) 53 OnTrack DM6 Aux a5 FreeBSD eb BeOS fs f W95 Ext&apos;d (LBA) 54 OnTrackDM6 a6 OpenBSD ee GPT 10 OPUS 55 EZ-Drive a7 NeXTSTEP ef EFI (FAT-12/16/ 11 Hidden FAT12 56 Golden Bow a8 Darwin UFS f0 Linux/PA-RISC b 12 Compaq diagnost 5c Priam Edisk a9 NetBSD f1 SpeedStor 14 Hidden FAT16 &lt;3 61 SpeedStor ab Darwin boot f4 SpeedStor 16 Hidden FAT16 63 GNU HURD or Sys af HFS / HFS+ f2 DOS secondary 17 Hidden HPFS/NTF 64 Novell Netware b7 BSDI fs fb VMware VMFS 18 AST SmartSleep 65 Novell Netware b8 BSDI swap fc VMware VMKCORE 1b Hidden W95 FAT3 70 DiskSecure Mult bb Boot Wizard hid fd Linux raid auto 1c Hidden W95 FAT3 75 PC/IX bc Acronis FAT32 L fe LANstep 1e Hidden W95 FAT1 80 Old Minix be Solaris boot ff BBT</div></pre></td></tr></table></figure><p>拥有支持读取这么多分区类型的能力的主要目的是允许兼容性和与其他计算机系统的文件系统的某些互操作性。使用<code>Fedora</code>创建新文件系统时可用的选项如下所示。</p><ul><li>btrfs</li><li><strong>cramfs</strong></li><li><strong>ext2</strong></li><li><strong>ext3</strong></li><li><strong>ext4</strong></li><li>fat</li><li>gfs2</li><li>hfsplus</li><li>minix</li><li><strong>msdos</strong></li><li>ntfs</li><li>reiserfs</li><li><strong>vfat</strong></li><li>xfs</li></ul><p>其他发行版支持创建不同的文件系统类型。例如，<code>CentOS 6</code>只支持创建上面列表中粗体显示的文件系统。</p><h2 id="挂载"><a href="#挂载" class="headerlink" title="挂载"></a>挂载</h2><p>在<code>Linux</code>中，<code>to mount</code>一词指的是早期的计算机中，当一个磁带或可移动的磁盘包需要在适当的驱动器上进行物理安装时。在物理上放置磁盘之后，磁盘包上的文件系统将由操作系统逻辑上挂载，以使操作系统、应用程序和用户能够访问这些内容。</p><p>挂载点仅仅是一个目录，就像任何其他的目录一样，它是作为根文件系统的一部分创建的。例如，<code>home</code>文件系统安装在目录<code>/home</code>上。文件系统可以安装在其他非根文件系统上的挂载点上，但这并不常见。<br><code>Linux</code>根文件系统安装在根目录上(<code>/</code>)非常早的引导序列。其他文件系统会被安装在后面，由<code>Linux</code>启动程序，无论是在<code>SystemV</code>下的<code>rc</code>，还是在新的<code>Linux</code>版本中的<code>systemd</code>，在启动过程中挂载文件系统是由<code>/ etc/fstab</code>配置文件管理的。一个容易记住的方法是<code>fstab</code>表示“文件系统表”，它是要挂载的文件系统的列表，还有它们指定的挂载点，以及特定文件系统可能需要的任何选项。</p><p>文件系统安装在现有的目录（挂载点）上，使用<code>mount</code>命令。一般来说，任何被用作挂载点的目录都应该是空的，并且没有包含其中的任何其他文件。<code>Linux</code>不会阻止用户将一个文件系统安装到一个已经存在的文件系统上，或者在一个包含文件的目录上。如果你在现有的目录或文件系统上安装了一个文件系统，那么原始的内容将会被隐藏，只有新挂载的文件系统的内容才会可见。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>我希望本文能够把围绕“文件系统”这个术语的一些可能的混淆给理清楚。我花了很长时间才真正理解并理解<code>Linux</code>文件系统的复杂性、优雅和功能。</p><p>如果你有问题，请把它们加到下面的评论中，我会尽量回答。</p><h2 id="下个月"><a href="#下个月" class="headerlink" title="下个月"></a>下个月</h2><p>另一个重要的概念是，对于<code>Linux</code>，一切都是文件。这个概念为用户和系统管理员提供了一些有趣且重要的实际应用程序。我之所以提到这一点，是因为您可能想在我下个月的<code>/dev</code>目录下的文章前阅读我的<a href="https://opensource.com/life/15/9/everything-is-a-file" target="_blank" rel="external">一切皆文件</a>的文章。</p><blockquote><p>原文地址：<a href="https://opensource.com/life/16/10/introduction-linux-filesystems" target="_blank" rel="external">https://opensource.com/life/16/10/introduction-linux-filesystems</a></p></blockquote><p>“一切皆文件”这篇文章我也进行了翻译</p><blockquote><p>翻译地址：<a href="http://www.tony-yin.top/2017/12/21/Everything-is-a-file" target="_blank" rel="external">http://www.tony-yin.top/2017/12/21/Everything-is-a-file</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/filesystem-600x450.png&quot; alt=&quot;Linux Filesystem&quot;&gt;&lt;/center&gt;

&lt;p&gt;本文旨在对&lt;code&gt;Linux&lt;/code&gt;文件系统概念进行深层次的讨论。本文既不准备对某个特定类型的文件系统（比如&lt;code&gt;ext4&lt;/code&gt;）进行基础性的描述，也不打算作为一个讲解文件系统命令的教程。&lt;/p&gt;
    
    </summary>
    
      <category term="read" scheme="https://tony-yin.github.io/categories/read/"/>
    
    
      <category term="Ceph" scheme="https://tony-yin.github.io/tags/Ceph/"/>
    
      <category term="Linux" scheme="https://tony-yin.github.io/tags/Linux/"/>
    
      <category term="Filesystem" scheme="https://tony-yin.github.io/tags/Filesystem/"/>
    
  </entry>
  
  <entry>
    <title>阅读感悟：《白夜行》</title>
    <link href="https://tony-yin.github.io/2017/12/10/Into-Withe-Night/"/>
    <id>https://tony-yin.github.io/2017/12/10/Into-Withe-Night/</id>
    <published>2017-12-10T11:57:34.000Z</published>
    <updated>2017-12-11T11:59:53.743Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/white_night.jpg" alt="Into White Night"></center><p>阅读周期：2017/12/08 ~ 2017/12/10<br>阅读评分：4.9<br>阅读人群：还是成年的人看着好一点，不大适合未成年人</p><blockquote><p>我的天空里没有太阳，总是黑夜，但并不暗，因为有东西代替了太阳。虽然没有太阳那么明亮，但对我来说已经足够。凭借着这份光，我便能把黑夜当成白天。我从来就没有太阳，所以不怕失去。</p></blockquote><a id="more"></a><p>之前一直在看技术书，这周末想稍微放松一下自己，翻了翻买了许久却没阅读的《白夜行》，之前听身边很多人称赞过这本书，果然看了就没停的下来，花了两天直接拉满读完。。。</p><p>坊间传言这是东野圭吾写的最好的一本书，我只看过《嫌疑人x的献身》，对比那个的话我觉得这一本更加细腻和深远。</p><p>看完了这本书，我去看了很多的书评，各有各的见解，并且都很有道理，我想这就是东野圭吾的厉害支持了，真正厉害的推理小说，不是作者在推理，而是最后是读者在推理。</p><p>对我个人而言，这本书最大的亮眼之处，就是作者重来不主动把某件事情说明，而是留下种种线索，相关关联，埋下伏笔，这样就导致永远没有一个确定性的答案，作者在意的也许不是具体的场景和手段，他着重刻画的是人性的本质、作恶的动机和灵魂的交融。</p><p>回过头一看，全书亮司与雪穗的生活宛如两条平行线，男女主角之间竟然没有任何对白，也没有交待任何他们见面的情节。书最后亮司突然死了，故事也很突然就这样结束了。让人反应不过来，因为她的太阳失去了。亮司承担了所有的罪恶，为了想让她生活在阳光下。</p><p>很多人都在讨论桐源和雪穗之间的关系，大多数人都认为他们是深爱着的。我个人觉得他们或许有爱，但是更多的是相互依靠和相互依附，也就是双方都是彼此的灵魂，活下去的羁绊，我觉得这是和单单的爱情是不一样的，否则他们大可以在一起，他们有的是钱，完全可以隐性瞒名的私奔。</p><p>我觉得桐源应该更爱雪穗一些，比如一直在他身边守护着她，最后关头为了保住她选择自杀，还有就是只有和她ML的时候才不会迟泄（这个在夕子那个宾馆的章节可以看出），但是桐源尊重雪穗，他只是一直在她身边守护着，永远不会过分打扰她的生活，即使她和别的男人恋爱，即使结婚，即使离婚再结婚，在他心里，雪穗永远是最重要的，满足她想要的和想做的是他一生的追求。桐源一直是作恶的执行者，雪穗背后的指使者，很多读者都为桐源不值，觉得他为了雪穗付出了那么多，最后得到确是冷漠的不回头，其实他并不后悔，看到《嫌疑人x的献身》的同学都知道最后时刻男主多希望女主也能像这边的女主雪穗一样头也不回地离开，这样他的付出才是值得的。桐源对典子应该也是有感情的，从他愿意带她去大阪，跟她讲童年时光，不过这种感情是建立在先利用之后感情培养出来的，但是在桐源心中雪穗永远是最重要的，即使典子获取桐源所有的爱情，当要做出选择的时候，我相信桐源还是选择雪穗吧，因为我觉得在他心中爱情远没有他和雪穗之间的羁绊重要，他们之间的关系关乎到灵魂和生死，他们是对方相互的太阳。</p><blockquote><p>曾经拥有的东西被夺走，并不代表就会回到原来没有那种东西的时候。                    —典子</p></blockquote><p>而雪穗难道对桐源没感情吗？我想肯定有，但是他们俩成为互相羁绊的时间太小了，才十一二岁，在太早的时间双方互相守护秘密，更像是相互保护，少了爱情的起源，所以她们也不知道双方之间是不是爱，雪穗说过她不知道如何去爱一个人，这个人说的可能是高工城，可能是一成，也有可能是桐源，桐源和雪穗经常就是在实行某个行动需要对方配合帮忙的时候才会聚头，比如夕子的那件事，雪穗肯定是通过手或者嘴帮助桐源完成了SJ，但是雪穗从来没有为高工城做过这样的事情，桐源在雪穗的心目中的位置可见一斑。但是也许她自己都不确定这是不是爱情，就像高工城内心的疑问一样，总感觉这份感情里面掺杂了很多其他东西。而雪穗对一诚或许在感情上面和别的人有一些不同，但是这也仅仅是有一点点不同，除了感情我觉得还有一个原因，雪穗不喜欢被别人无视，当大学社团一诚喜欢江利子忽略雪穗时，这让她感觉到嫉妒了，她一直认为自己是完美的，是所有人的焦点所在。</p><p>很多人都在愤怒雪穗最后的冷漠，上面我也说了，除了桐源希望用自己的生命保全雪穗之外，雪穗的行为是头也不回的离去，要知道雪穗在此之前无论是生母、养母、前夫等等，都表现出自己的伤心，唯独这次雪穗没有表现正常，也算是她的失误了，我想她不仅因为是失去了她的太阳觉得无助，最重要的是他也不敢面对这个现实，她面对谁都可以表演的很好，但是除了桐源，她做不到，也许她过不了多久也会选择离开这个世界，要么就永远在白夜中度过。。。</p><p>店已打烊女主确上楼而不是离开，是否会意味着要与亮一同结束在梦魇开始的地方？</p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/white_night.jpg&quot; alt=&quot;Into White Night&quot;&gt;&lt;/center&gt;

&lt;p&gt;阅读周期：2017/12/08 ~ 2017/12/10&lt;br&gt;阅读评分：4.9&lt;br&gt;阅读人群：还是成年的人看着好一点，不大适合未成年人&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我的天空里没有太阳，总是黑夜，但并不暗，因为有东西代替了太阳。虽然没有太阳那么明亮，但对我来说已经足够。凭借着这份光，我便能把黑夜当成白天。我从来就没有太阳，所以不怕失去。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="read" scheme="https://tony-yin.github.io/categories/read/"/>
    
    
      <category term="Read" scheme="https://tony-yin.github.io/tags/Read/"/>
    
  </entry>
  
  <entry>
    <title>故障修复：文件系统导致OSD启动失败</title>
    <link href="https://tony-yin.github.io/2017/12/08/Filesystem-Bug-Fix/"/>
    <id>https://tony-yin.github.io/2017/12/08/Filesystem-Bug-Fix/</id>
    <published>2017-12-08T12:54:16.000Z</published>
    <updated>2017-12-10T12:59:19.652Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/bugfix.png" alt="Bug fix"></center><p>记一次因为文件系统导致<code>OSD</code>无法启动的故障修复。</p><a id="more"></a><h2 id="集群状况："><a href="#集群状况：" class="headerlink" title="集群状况："></a>集群状况：</h2><p><code>Cluster</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">root@gigabyte:~# ceph -s</div><div class="line">    cluster de3627bb-c748-4623-8cb1-b88c646ff5d5</div><div class="line">     health HEALTH_WARN 42 pgs degraded; 1 pgs down; 1 pgs peering; 17 pgs recovering; 25 pgs recovery_wait; 359 pgs stale; 42 pgs stuck degraded; 1 pgs stuck inactive; 359 pgs stuck stale; 244 pgs stuck unclean; recovery 6665/163785 objects degraded (4.069%); 6665/163785 unfound (4.069%); 2/23 in osds are down</div><div class="line">     monmap e1: 1 mons at &#123;erxdl=10.16.180.28:6789/0&#125;, election epoch 2, quorum 0 erxdl</div><div class="line">     mdsmap e654: 1/1/1 up &#123;0=irlhy=up:active&#125;</div><div class="line">     osdmap e218: 23 osds: 21 up, 23 in</div><div class="line">      pgmap v8943: 7936 pgs, 16 pools, 639 GB data, 159 kobjects</div><div class="line">            105 GB used, 76827 GB / 76933 GB avail</div><div class="line">            6665/163785 objects degraded (4.069%); 6665/163785 unfound (4.069%)</div><div class="line">                 359 stale+active+clean</div><div class="line">                 201 active+remapped</div><div class="line">                7333 active+clean</div><div class="line">                  25 active+recovery_wait+degraded</div><div class="line">                  17 active+recovering+degraded</div><div class="line">                   1 down+peering</div></pre></td></tr></table></figure><p><code>OSD</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">root@test:/data# ceph osd tree</div><div class="line"># idweighttype nameup/downreweight</div><div class="line">-382.29pool 4T</div><div class="line">-482.29host test1</div><div class="line">00osd.0up    1</div><div class="line">83.578osd.8up    1</div><div class="line">173.578osd.17up    1</div><div class="line">53.578osd.5up    1    </div><div class="line">...</div><div class="line">...</div><div class="line">163.578osd.16up    1</div><div class="line">103.578osd.10up    1</div><div class="line">153.578osd.15up    1</div><div class="line">130osd.13down1</div></pre></td></tr></table></figure><p>由上可知：<code>osd.0</code>和<code>osd.13</code>已经被集群剔除，并且权重变为了<code>0</code></p><h2 id="报错日志："><a href="#报错日志：" class="headerlink" title="报错日志："></a>报错日志：</h2><h3 id="报错1："><a href="#报错1：" class="headerlink" title="报错1："></a>报错1：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">2017-12-06 10:18:05.180802 7f4809ae07c0 -1 osd.13 234 set_disk_tp_priority(22) Invalid argument: osd_disk_thread_ioprio_class is  but only the following values are allowed: idle, be or rt</div><div class="line"></div><div class="line">2017-12-06 10:10:44.974634 7f4cbcfff700 -1 os/FileStore.cc: In function &apos;virtual int FileStore::read(coll_t, const ghobject_t&amp;, uint64_t, size_t, ceph::bufferlist&amp;, bool)&apos; thread 7f4cbcfff700</div><div class="line"></div><div class="line">2017-12-06 10:10:44.972299 os/FileStore.cc: 2851: FAILED assert(allow_eio || !m_filestore_fail_eio || got != -5)</div></pre></td></tr></table></figure><h3 id="报错2"><a href="#报错2" class="headerlink" title="报错2:"></a>报错2:</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">2017-12-06 10:32:56.602065 7f576071b7c0  0 genericfilestorebackend(/ceph/osd.13) detect_features: FIEMAP ioctl is supported and appears to work</div><div class="line"></div><div class="line">2017-12-06 10:32:56.602095 7f576071b7c0  0 genericfilestorebackend(/ceph/osd.13) detect_features: FIEMAP ioctl is disabled via &apos;filestore fiemap&apos; config option</div><div class="line"> </div><div class="line">2017-12-06 10:32:56.620337 7f576071b7c0  0 genericfilestorebackend(/ceph/osd.13) detect_features: syncfs(2) syscall fully supported (by glibc and kernel)</div><div class="line"></div><div class="line">2017-12-06 10:32:56.739219 7f576071b7c0  0 filestore(/ceph/osd.13) limited size xattrs</div></pre></td></tr></table></figure><h3 id="报错3："><a href="#报错3：" class="headerlink" title="报错3："></a>报错3：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">2017-12-06 10:16:32.442815 7f06cddf2700 -1 journal aio to 1398235136~434176 got (5) Input/output error</div><div class="line"></div><div class="line">2017-12-06 10:16:32.443787 7f06cddf2700 -1 os/FileJournal.cc: In function &apos;void FileJournal::write_finish_thread_entry()&apos; thread 7f06cddf2700</div><div class="line"></div><div class="line">2017-12-06 10:16:32.442867 os/FileJournal.cc: 1383: FAILED assert(0 == &quot;unexpected aio error&quot;)</div></pre></td></tr></table></figure><h3 id="报错4："><a href="#报错4：" class="headerlink" title="报错4："></a>报错4：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">2017-12-06 00:52:33.814785 7fb24be877c0 -1 filestore(/ceph/osd.13) FileStore::mount: unable to access basedir &apos;/ceph/osd.0&apos;: (30) Read-only file system</div><div class="line"></div><div class="line">2017-12-06 00:52:33.814801 7fb24be877c0 -1 osd.13 0 OSD:init: unable to mount object store</div><div class="line"></div><div class="line">2017-12-06 00:52:33.814806 7fb24be877c0 -1 ^[[0;31m ** ERROR: osd init failed: (30) Read-only file system</div></pre></td></tr></table></figure><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>首先我们肯定是要尝试把<code>OSD</code>起来嘛，所以要做的就是先给<code>osd</code>加权重，接着加入集群，最后再启动。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">ceph osd crush add osd.0 3.578 host=test1</div><div class="line">ceph osd in osd.0</div><div class="line">service ceph start osd.0</div><div class="line"></div><div class="line">ceph osd crush add osd.13 3.578 host=test1</div><div class="line">ceph osd in osd.13</div><div class="line">service ceph start osd.13</div></pre></td></tr></table></figure><p>这时候发现<code>OSD</code>还是起不来，我们就去看<code>osd.0</code>和<code>osd.13</code>的<code>log</code>，也就会发现以上一系列的报错日志，错误较多；</p><p><code>filesystem</code>出现较多<code>limited size xattrs</code>这一行引起了我的注意，由于此环境<code>osd</code>用的文件系统是<code>ext4</code>，而<code>ext4</code>对存储<code>xattr</code>的大小有限制，使得OSD信息不能安全的保存。</p><p>所以在<code>ceph</code>中如果<code>osd</code>采用<code>ext4</code>文件系统时，需要在配置项里面加入相关配置实现用<code>omap</code>来存储<code>xattr</code>，而<code>xfs</code>文件系统由于对<code>xattr</code>的存储是足够的，所以不存在这个问题。</p><p>所以解决这个问题有三个方案：</p><h3 id="方案1"><a href="#方案1" class="headerlink" title="方案1"></a>方案1</h3><p>更改文件系统，将<code>ext4</code>改成<code>xfs</code></p><h3 id="方案2"><a href="#方案2" class="headerlink" title="方案2"></a>方案2</h3><p>文件系统还是采用<code>ext4</code>，配置让<code>Ceph filestore</code>中的<code>omap</code>存储<code>xattr</code>，在<code>/etc/ceph/ceph.conf</code>中<code>global section</code>或<code>osd section</code>中插入一行以下配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">filestore xattr use omap = true</div></pre></td></tr></table></figure><h3 id="方案3"><a href="#方案3" class="headerlink" title="方案3"></a>方案3</h3><p>限制对象的长度大小，同样是修改<code>ceph.conf</code>，在<code>global section</code>或者<code>osd section</code>中加入以下配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">osd max object name len = 256 </div><div class="line">osd max object namespace len = 64</div></pre></td></tr></table></figure><p>然后再次重启以下对应的<code>osd</code>服务就OK了！</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在<code>Ceph</code>中如果用<code>ext4</code>文件系统的话，一定要注意配置将<code>xattr</code>存在<code>omap</code>中。</p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/bugfix.png&quot; alt=&quot;Bug fix&quot;&gt;&lt;/center&gt;

&lt;p&gt;记一次因为文件系统导致&lt;code&gt;OSD&lt;/code&gt;无法启动的故障修复。&lt;/p&gt;
    
    </summary>
    
      <category term="tech" scheme="https://tony-yin.github.io/categories/tech/"/>
    
    
      <category term="Ceph" scheme="https://tony-yin.github.io/tags/Ceph/"/>
    
      <category term="Bugfix" scheme="https://tony-yin.github.io/tags/Bugfix/"/>
    
  </entry>
  
  <entry>
    <title>通过 Keepalived 实现 Ceph RBD 的高可用</title>
    <link href="https://tony-yin.github.io/2017/12/07/RBD-HA/"/>
    <id>https://tony-yin.github.io/2017/12/07/RBD-HA/</id>
    <published>2017-12-06T16:25:31.000Z</published>
    <updated>2017-12-07T06:47:35.572Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/HA.jpg" alt="HA"></center><p>由于<code>Cephfs</code>很不稳定，并且性能差，很难达到用户在性能上的需求，所以<code>Cephfs</code>也难以应用于生产环境之上。而<code>RBD</code>可以说是一直非常稳定的存储接口方案，用户可以将<code>image</code>挂载到客户端进行访问读写，然而很多用户不愿意在本地安装<code>Ceph</code>客户端，所以我们常常需要自己封装一层，给客户端暴露出一个通用的接口进行访问，现在一般都是默认用<code>NFS</code>，所以本文就<code>Ceph RBD</code>如何实现高可用暴露<code>NFS</code>给客户端访问进行分享。</p><a id="more"></a><h2 id="环境："><a href="#环境：" class="headerlink" title="环境："></a>环境：</h2><blockquote><p><code>Linux Distribution</code> : <code>ubuntu</code><br><code>Ceph</code> : <code>Giant</code><br><code>Keepalived</code> : <code>v1.2.2</code><br>集群信息 ：三节点，<code>IP</code>分别为<code>192.168.1.111</code>，<code>192.168.1.112</code>，<code>192.168.1.113</code></p></blockquote><h2 id="Keepalived-简介"><a href="#Keepalived-简介" class="headerlink" title="Keepalived 简介"></a>Keepalived 简介</h2><p>建议先简单了解一些<code>keepalived</code>的机制再看下面的内容~</p><blockquote><p><code>Keepalived</code>的作用是检测集群中服务器的状态，如果有一台服务器死机，或工作出现故障，<code>Keepalived</code>将检测到，并将有故障的服务器从集群中剔除，当服务器工作正常后<code>Keepalived</code>自动将服务器加入到服务器群中，这些工作全部自动完成，不需要人工干涉，需要人工做的只是修复故障的服务器。</p></blockquote><p>下面从网上找了几张图片，方便大家理解一下其原理和机制：</p><h3 id="Keepalived-内部结构："><a href="#Keepalived-内部结构：" class="headerlink" title="Keepalived 内部结构："></a>Keepalived 内部结构：</h3><center><img src="http://ow0mgad6r.bkt.clouddn.com/keepalived_space.png" alt="keepalive layer"></center><h3 id="双机热备："><a href="#双机热备：" class="headerlink" title="双机热备："></a>双机热备：</h3><center><img src="http://ow0mgad6r.bkt.clouddn.com/keepalived_two_host.png" alt="keepalive two host master and backup"></center><h3 id="负载均衡、应用分层："><a href="#负载均衡、应用分层：" class="headerlink" title="负载均衡、应用分层："></a>负载均衡、应用分层：</h3><center><img src="http://ow0mgad6r.bkt.clouddn.com/keepalived_layer.png" alt="keepalive layer"></center><h3 id="配置文件解析"><a href="#配置文件解析" class="headerlink" title="配置文件解析"></a>配置文件解析</h3><p>已下摘录自：<a href="http://blog.csdn.net/love_is_simple/article/details/47903527" target="_blank" rel="external">http://blog.csdn.net/love_is_simple/article/details/47903527</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">global_defs &#123;</div><div class="line">   notification_email &#123;</div><div class="line">     sai@localhost # 报警邮件接收人的地址</div><div class="line">   &#125;</div><div class="line">   notification_email_from root@localhost # 发送报警邮件发件人地址</div><div class="line">   smtp_server 127.0.0.1# 发送邮件的服务器地址</div><div class="line">   smtp_connect_timeout 30# 邮件超时时间(可以根据自己的需求进行设定)</div><div class="line">   router_id LVS_DEVEL# 一个实例的标识地址(可以有多个实例但不能相同)</div><div class="line">&#125;</div><div class="line">vrrp_script monitor_nginx &#123;</div><div class="line">  script “/root/scripts/monitor_nginx.sh”#根据自己的实际路径放置脚本文件</div><div class="line">  interval 1# 脚本执行间隔</div><div class="line">Weight -5#脚本结果导致的优先级变更:5表示优先级加5；-5表示优先级减5</div><div class="line">&#125;</div><div class="line">vrrp_instance VI_1 &#123;# 虚拟路由器自己的名字</div><div class="line">    state MASTER# 设置服务器模式，当前为主节点,master端</div><div class="line">    interface eth0# 实例网卡,也就是提供服务的网卡，来发送vrrp通告</div><div class="line">    virtual_router_id 51# 设置vrid,这里非常重要,相同的vrid为一个组,他决定,它将决定多播的MAC地址.（建议不要使用默认地址,以免发生冲突）</div><div class="line">    priority 100#  设置本节点的优先级,优先级高的为master</div><div class="line">    advert_int 1# 检查间隔,默认为1秒</div><div class="line">    authentication &#123;</div><div class="line">        auth_type PASS# 认证方式,可以是pass或者AH两种认证方式</div><div class="line">        auth_pass 1111# 认证密码</div><div class="line">    &#125;</div><div class="line">    virtual_ipaddress &#123;# 设置vip,虚拟ip地址(实现高可用,转移的vip地址)</div><div class="line">        10.0.1.230# 此地址并不存在,当成为主节点时,此ip地址将会自动生成</div><div class="line">&#125;</div><div class="line">script_track &#123;</div><div class="line">monitor_nginx  #跟踪这个monitor_nginx脚本;就是不断去检查这个脚本</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h2><h3 id="RBD-导出-NFS"><a href="#RBD-导出-NFS" class="headerlink" title="RBD 导出 NFS"></a>RBD 导出 NFS</h3><p>首先我们要实现<code>RBD</code>导出<code>NFS</code>功能，毕竟只有先能让客户端通过<code>NFS</code>访问后端存储，然后才有必要谈后端存储集群的高可用方案。</p><p>我们需要在<code>Ceph Server</code>集群创建<code>RBD image</code>；然后在三个节点上都建立<code>RBD Map</code>关系，最终只会有一个块设备被<code>mount</code>，其余两个既用于占位（防止多<code>image</code>的情况下造成节点间块设备名称不一致），又是为了作为备机在主机发生故障时转换角色，挂载当前节点的块设备。</p><p>接着在三个节点上分别在指定目录下创建目录，本文是在<code>/vol/</code>目录下创建目录，比如创建目录<code>/vol/ec</code>，这个目录就是块设备对应的挂载目录。</p><p>如果有童鞋对<code>rbd</code>导出<code>nfs</code>过程有兴趣的话，具体请参考：<a href="http://www.tony-yin.top/2017/10/31/RBD-Mount-NFS/" target="_blank" rel="external">使用NFS挂载RBD</a>。</p><h3 id="Keepalived-实现-HA"><a href="#Keepalived-实现-HA" class="headerlink" title="Keepalived 实现 HA"></a>Keepalived 实现 HA</h3><p>我们后端存储集群最终只会暴露出一个接口或者说是一个<code>IP</code>，<code>keepalived</code>中有<code>VIP</code>这种配置可以支持，所以我们需要在三个节点上配置<code>keepalived.conf</code>文件，然后启动<code>keepalived</code>所有节点会选举一个<code>master</code>节点并暴露虚拟<code>IP</code>。</p><p>然后我们在<code>master</code>节点上将块设备挂载到之前创建的目录<code>/vol/ec</code>，同步信息至<code>/ect/exports</code>，可以通过<code>showmount -e vip</code>可以发现<code>/vol/ec</code>已经暴露到了<code>vip</code>上，客户端便可以通过<code>NFS</code>将上一步创建的目录<code>/vol/ec</code>挂载到本地目录，比如<code>/client_ec</code>；</p><p>这时候客户端已经可以通过虚拟<code>IP</code>对<code>RBD image</code>进行读写了，但是如果这时候<code>master</code>节点<code>down</code>了咋办呢？</p><p>为了防止集群中主节点不能给<code>client</code>提供访问，我们需要实现高可用，也就是当主节点<code>down</code>了后，集群自动切换主机，并且针对<code>RBD</code>做自动相应挂载操作，让用户无感知访问存储后端。</p><p>我们需要配置<code>keepalived.conf</code>，当节点角色转为<code>backup</code>时，触发停止<code>NFS</code>并卸载暴露目录等操作；当节点角色转为<code>master</code>时，触发挂载<code>RBD image</code>并启动<code>NFS</code>等操作；定时检查当前<code>NFS</code>，一旦<code>NFS</code>服务停止了，尝试重启，如果重启失败，停止<code>keepalived</code>服务触发节点角色切换等等。</p><p>这些操作对用户来说是无感知的，我们还可以针对<code>keepalived</code>做相关邮件配置提醒服务器发生故障等等。</p><h2 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a>具体步骤</h2><h3 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h3><h4 id="搭建-Ceph-集群"><a href="#搭建-Ceph-集群" class="headerlink" title="搭建 Ceph 集群"></a>搭建 Ceph 集群</h4><p>这个就不多说了，基本操作。</p><h4 id="安装-Keepalived"><a href="#安装-Keepalived" class="headerlink" title="安装 Keepalived"></a>安装 Keepalived</h4><p>本位基于<code>ubuntu</code>，<code>redhat</code>派可以转换成对应的命令再操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">apt-get install libpopt-dev     // 安装依赖</div><div class="line">apt-get install keepalived</div></pre></td></tr></table></figure><h3 id="RBD-导出"><a href="#RBD-导出" class="headerlink" title="RBD 导出"></a>RBD 导出</h3><h4 id="创建-image"><a href="#创建-image" class="headerlink" title="创建 image"></a>创建 image</h4><p>这里默认在<code>test1 pool</code>中创建<code>1G</code>的<code>image</code>，请根据自己的场景转换大小，生产环境一般都要几十<code>T</code>，甚至上百<code>T</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rbd create --size 1024 -p test1 image_ec</div></pre></td></tr></table></figure><h4 id="建立-map-关系"><a href="#建立-map-关系" class="headerlink" title="建立 map 关系"></a>建立 map 关系</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">rbd map -p test1 image_ec</div><div class="line"># 输出块设备名称： /dev/rbd0</div></pre></td></tr></table></figure><h4 id="为块设备格式化文件系统"><a href="#为块设备格式化文件系统" class="headerlink" title="为块设备格式化文件系统"></a>为块设备格式化文件系统</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mkfs.ext4 -i 400000 /dev/rbd0</div></pre></td></tr></table></figure><h4 id="将块设备挂载到本地目录"><a href="#将块设备挂载到本地目录" class="headerlink" title="将块设备挂载到本地目录"></a>将块设备挂载到本地目录</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount -o noatime,user_xattr /dev/rbd0 /vol/ec</div></pre></td></tr></table></figure><h3 id="配置-Keepalived"><a href="#配置-Keepalived" class="headerlink" title="配置 Keepalived"></a>配置 Keepalived</h3><h4 id="配置-VIP"><a href="#配置-VIP" class="headerlink" title="配置 VIP"></a>配置 VIP</h4><p><code>VIP</code>必须是当前集群不存在的<code>ip</code>，通过将配置个节点上<code>keepalived.conf</code>，为<code>virtual_ipaddress</code>选项添加<code>IP</code>，我这边用的是<code>192.168.1.13/24</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">virtual_ipaddress &#123;</div><div class="line">    192.168.1.13/24</div><div class="line">&#125;</div></pre></td></tr></table></figure><h4 id="配置优先级和网卡"><a href="#配置优先级和网卡" class="headerlink" title="配置优先级和网卡"></a>配置优先级和网卡</h4><p>三个节点的角色都配置为<code>BACKUP</code>，并且配置<code>nopreempt</code>，这样就可以实现不抢占模式，当主节点<code>down</code>恢复后不会抢占成为主节点，对我而言哪个是主节点并不重要，频繁切换反而会造成客户端延时。我这边的对外网卡是<code>eth0</code>，<code>priority</code>是真正决定一开始初始化选举<code>master</code>的因素，最大值的节点是<code>master</code>节点，一旦切换角色，这个值并不会改变。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">vrrp_instance VI_1 &#123;</div><div class="line">    state BACKUP</div><div class="line">    interface eth0</div><div class="line">    priority 100</div><div class="line">    nopreempt</div><div class="line">&#125;</div></pre></td></tr></table></figure><h4 id="配置角色切换后触发相关操作"><a href="#配置角色切换后触发相关操作" class="headerlink" title="配置角色切换后触发相关操作"></a>配置角色切换后触发相关操作</h4><p>当主机<code>down</code>之后，如果没有关机，角色转换为<code>backup</code>后需要做卸载相关操作；而之前的备机如今成为了主机，也要做挂载等相关操作，这些需求我们可以通过配置<code>keepalived</code>，当角色转换时触发相关脚本，这里的配置就表示当节点角色切换为了<code>master</code>时则需要执行<code>/etc/keepalived/ChangeToMaster.sh</code>，角色切换为<code>backup</code>则会执行<code>/etc/keepalived/ChangeToBackup.sh</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">vrrp_instance VI_1 &#123;</div><div class="line">    notify_master &quot;/etc/keepalived/ChangeToMaster.sh&quot; </div><div class="line">    notify_backup &quot;/etc/keepalived/ChangeToBackup.sh&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h4 id="配置定时检测-NFS-状态"><a href="#配置定时检测-NFS-状态" class="headerlink" title="配置定时检测 NFS 状态"></a>配置定时检测 NFS 状态</h4><p>如果一旦<code>NFS</code>服务断了，我们不及时处理的话，客户端就可以明显地感知到无法读写了。所以我们需要定时不断检测<code>NFS</code>的状态，这个也可以通过配置<code>track_script</code>选项执行某个脚本并指定间隔时间：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">vrrp_script chk_nfs &#123;</div><div class="line">    script &quot;/etc/keepalived/check_nfs.sh&quot;       # 调用脚本</div><div class="line">    interval 2      # 设置间隔时间为 2s</div><div class="line">&#125;</div><div class="line">vrrp_instance VI_1 &#123;</div><div class="line">    track_script &#123;</div><div class="line">        chk_nfs     # 调用上面的chk_nfs函数</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h4 id="整个配置文件内容"><a href="#整个配置文件内容" class="headerlink" title="整个配置文件内容"></a>整个配置文件内容</h4><p>暂时还是比较精简的，邮件什么的都没配置，<code>keepalived</code>还是可以做很多事情的，有兴趣的童鞋可以深入研究</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">global_defs &#123;</div><div class="line">    notification_email &#123;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    router_id NFS_HA_222</div><div class="line">&#125;</div><div class="line"></div><div class="line">vrrp_script chk_nfs &#123;</div><div class="line">    script &quot;/etc/keepalived/check_nfs.sh&quot;</div><div class="line">    interval 2</div><div class="line">&#125;</div><div class="line"></div><div class="line">vrrp_instance VI_1 &#123;</div><div class="line">    #state MASTER</div><div class="line">    state BACKUP</div><div class="line">    interface eth0</div><div class="line">    priority 100</div><div class="line">    virtual_router_id 100</div><div class="line">    advert_int 1</div><div class="line">    authentication &#123;</div><div class="line">        auth_type PASS</div><div class="line">        auth_pass 1111</div><div class="line">    &#125;</div><div class="line">    track_script &#123;</div><div class="line">        chk_nfs</div><div class="line">    &#125;</div><div class="line">    nopreempt</div><div class="line">    notify_master &quot;/etc/keepalived/ChangeToMaster.sh&quot;</div><div class="line">    notify_backup &quot;/etc/keepalived/ChangeToBackup.sh&quot;</div><div class="line">    virtual_ipaddress &#123;</div><div class="line">        192.168.1.13/24</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h4 id="相关脚本"><a href="#相关脚本" class="headerlink" title="相关脚本"></a>相关脚本</h4><blockquote><p>大家可以手动从下面复制，也可以去我的<code>github</code>上面获取，欢迎点赞！</p><p>地址： <a href="https://github.com/tony-yin/ceph_scripts#keepalived" target="_blank" rel="external">https://github.com/tony-yin/ceph_scripts#keepalived</a></p></blockquote><p>这些脚本都是针对我当前环境的，需要针对自己的环境和需求进行相应更改</p><p><code>ChangeToBackup.sh</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">#!/bin/bash</div><div class="line"></div><div class="line">service nfs-kernel-server stop</div><div class="line">for folder in $(ls /vol)</div><div class="line">do</div><div class="line">    if $(mount | grep $folder -q); then</div><div class="line">        umount -f /vol/$folder</div><div class="line">    fi</div><div class="line">done</div></pre></td></tr></table></figure><p><code>ChangeToMaster.sh</code>：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/bin/bash</span></div><div class="line"><span class="keyword">for</span> folder <span class="keyword">in</span> $(ls /vol)</div><div class="line"><span class="keyword">do</span></div><div class="line">    <span class="keyword">if</span> $(mount | grep <span class="variable">$folder</span> -q); <span class="keyword">then</span></div><div class="line">        umount /vol/<span class="variable">$folder</span> &gt; /dev/null</div><div class="line">    <span class="keyword">fi</span></div><div class="line">    device=$(grep <span class="variable">$folder</span> /etc/block_map -w | awk <span class="string">'&#123;print $1&#125;'</span>)</div><div class="line">    mount <span class="variable">$device</span> /vol/<span class="variable">$folder</span></div><div class="line"><span class="keyword">done</span></div><div class="line">service nfs-kernel-server start</div></pre></td></tr></table></figure><p><code>check_nfs.sh</code>：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/bin/sh</span></div><div class="line">vip=$(grep -A 1 virtual_ipaddress /etc/keepalived/keepalived.conf | grep -v virtual_ipaddress | tr -d [:blank:] | cut -d <span class="string">'/'</span> -f 1)</div><div class="line"><span class="keyword">if</span> ! /sbin/ip addr | grep -q <span class="variable">$vip</span>; <span class="keyword">then</span></div><div class="line">    <span class="built_in">exit</span></div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"><span class="comment"># check nfs service</span></div><div class="line">/sbin/service nfs-kernel-server status &gt;/dev/null</div><div class="line"><span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></div><div class="line">    <span class="comment"># abnormal, try to restart the nfs service</span></div><div class="line">    /sbin/service nfs-kernel-server restart</div><div class="line">    /sbin/service nfs-kernel-server status &gt;/dev/null</div><div class="line">    <span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></div><div class="line">        <span class="comment"># still abnormal</span></div><div class="line">        <span class="keyword">for</span> folder <span class="keyword">in</span> $(ls /vol)</div><div class="line">        <span class="keyword">do</span></div><div class="line">            <span class="keyword">if</span> $(mount | grep <span class="variable">$folder</span> -q); <span class="keyword">then</span></div><div class="line">                umount -f /vol/<span class="variable">$folder</span></div><div class="line">            <span class="keyword">fi</span></div><div class="line">        <span class="keyword">done</span></div><div class="line">        <span class="comment"># stop keepalived service</span></div><div class="line">        /sbin/service keepalived stop</div><div class="line">    <span class="keyword">fi</span></div><div class="line"><span class="keyword">fi</span></div></pre></td></tr></table></figure><p>配置完后，分别在三个节点上执行<code>service keepalived restart</code>重启服务，然后分别在三个节点上执行<code>ip addr</code>查看<code>IP</code>情况，可以发现<code>VIP</code>暴露在了<code>node2</code>上，说明我这里<code>node2</code>在<code>keepalived.conf</code>里面配置<code>priority</code>的值是最大的</p><p><code>node1</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">root@node1:/etc/keepalived# ip addr</div><div class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN </div><div class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</div><div class="line">    inet 127.0.0.1/8 scope host lo</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP qlen 1000</div><div class="line">    link/ether 00:50:56:aa:70:4e brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.1.111/24 brd 192.168.1.255 scope global eth0</div><div class="line">       valid_lft forever preferred_lft forever</div></pre></td></tr></table></figure><p><code>node2</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">root@node2:/etc# ip addr</div><div class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN </div><div class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</div><div class="line">    inet 127.0.0.1/8 scope host lo</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP qlen 1000</div><div class="line">    link/ether 00:50:56:aa:61:26 brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.1.112/24 brd 192.168.1.255 scope global eth0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">    inet 192.168.1.13/24 scope global secondary eth0</div><div class="line">       valid_lft forever preferred_lft forever</div></pre></td></tr></table></figure><p><code>node3</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">root@node3:~# ip addr</div><div class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN </div><div class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</div><div class="line">    inet 127.0.0.1/8 scope host lo</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP qlen 1000</div><div class="line">    link/ether 00:50:56:aa:a9:13 brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.1.113/24 brd 192.168.1.255 scope global eth0</div><div class="line">       valid_lft forever preferred_lft forever</div></pre></td></tr></table></figure><h3 id="客户端通过-NFS-访问-RBD"><a href="#客户端通过-NFS-访问-RBD" class="headerlink" title="客户端通过 NFS 访问 RBD"></a>客户端通过 NFS 访问 RBD</h3><p>客户端检查<code>VIP</code>对外暴露接口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@tony /]# showmount -e 192.168.1.13</div><div class="line">Export list for 192.168.1.13:</div><div class="line">/vol/ec1 *</div></pre></td></tr></table></figure><p>将<code>server</code>端挂载块设备的目录<code>/vol/ec1</code>再次挂载到客户端上的<code>ec1</code>目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@tony /]# mkdir ec1</div><div class="line">[root@tony /]# mount -o rw,hard,intr -t nfs 192.168.1.13:/vol/ec1 /ec1</div><div class="line">[root@tony /]# cd ec1</div><div class="line">[root@tony ec1]# ls</div><div class="line">lost+found      # 此时是没有数据的</div></pre></td></tr></table></figure><p>我们可以测试一下读写，先看下读，比如我们在<code>node2</code>的<code>/vol/ec1</code>目录下写一个文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">root@node2:/vol/ec1# ls</div><div class="line">lost+found</div><div class="line">root@node2:/vol/ec1# echo &apos;hello&apos; &gt; hello.txt</div></pre></td></tr></table></figure><p>然后客户端查看<code>/ec1</code>目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@tony ec1]# ls</div><div class="line">hello.txt  lost+found</div><div class="line">[root@tony ec1]# cat hello.txt </div><div class="line">hello</div></pre></td></tr></table></figure><p>接下来测写，我们可以在客户端写一个文件，然后到服务端查看</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@tony ec1]# echo &apos;i am client&apos; &gt; client.txt</div><div class="line">[root@tony ec1]# ls</div><div class="line">client.txt  hello.txt  lost+found</div></pre></td></tr></table></figure><p>服务端查看：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">root@node2:/vol/ec1# ls</div><div class="line">client.txt  hello.txt  lost+found</div><div class="line">root@node2:/vol/ec1# cat client.txt </div><div class="line">i am client</div></pre></td></tr></table></figure><p>ok，读写正常，目前为止客户端访问后端存储集群一切顺利！</p><h3 id="测试高可用"><a href="#测试高可用" class="headerlink" title="测试高可用"></a>测试高可用</h3><p>分三个测试：</p><ul><li>手动停止主机<code>NFS</code></li><li>手动停止主机<code>Keepalived</code></li><li>手动关机主机</li></ul><h4 id="手动停止主机-NFS"><a href="#手动停止主机-NFS" class="headerlink" title="手动停止主机 NFS"></a>手动停止主机 NFS</h4><p>这个主要是测试<code>check_nfs.sh</code>这个脚本是否在实时监控<code>NFS</code>状态，可以看到刚<code>stop</code>再次查看状态已经是<code>running</code>了，本测试通过~</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">root@node2:/vol/ec1# service nfs-kernel-server stop</div><div class="line"> * Stopping NFS kernel daemon                                                                                                                                                         [ OK ] </div><div class="line"> * Unexporting directories for NFS kernel daemon...                                                                                                                                   [ OK ] </div><div class="line">root@node2:/vol/ec1# service nfs-kernel-server status</div><div class="line">nfsd running</div></pre></td></tr></table></figure><h4 id="手动停止主机-Keepalived"><a href="#手动停止主机-Keepalived" class="headerlink" title="手动停止主机 Keepalived"></a>手动停止主机 Keepalived</h4><p>手动停止主机<code>node2</code>的<code>keepalived</code>服务，发现<code>VIP</code>已经在<code>node2</code>上面消失不见</p><p><code>node2</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">root@node2:/vol/ec1# service keepalived stop</div><div class="line"> * Stopping keepalived keepalived                                                                                                                                                     [ OK ] </div><div class="line">root@node2:/vol/ec1# ip addr</div><div class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN </div><div class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</div><div class="line">    inet 127.0.0.1/8 scope host lo</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP qlen 1000</div><div class="line">    link/ether 00:50:56:aa:61:26 brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.1.112/24 brd 192.168.1.255 scope global eth0</div><div class="line">       valid_lft forever preferred_lft forever</div></pre></td></tr></table></figure><p>我们可以在<code>node1</code>发现了上面消失不见得<code>VIP</code>，可知如今角色发生了改变，<code>node1</code>已经成为了新的<code>master</code>节点</p><p><code>node1</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"># 出现了 VIP：192.168.1.13/24</div><div class="line">root@node1:/etc/keepalived# ip addr</div><div class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN </div><div class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</div><div class="line">    inet 127.0.0.1/8 scope host lo</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP qlen 1000</div><div class="line">    link/ether 00:50:56:aa:70:4e brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.1.111/24 brd 192.168.1.255 scope global eth0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">    inet 192.168.1.13/24 scope global secondary eth0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line"># 查看node1的/vol/ec1目录     </div><div class="line">root@node1:/etc/keepalived# ls /vol/ec1</div><div class="line">client.txt  hello.txt  lost+found</div><div class="line"># 查看mount信息</div><div class="line">root@node1:/etc/keepalived# mount</div><div class="line">/dev/sda3 on / type ext4 (rw,errors=remount-ro)</div><div class="line">/dev/sdb2 on /data/osd.0 type ext4 (rw,noatime,user_xattr)</div><div class="line">nfsd on /proc/fs/nfsd type nfsd (rw)</div><div class="line">...</div><div class="line">/dev/rbd0 on /vol/ec1 type ext4 (rw)</div></pre></td></tr></table></figure><p>此时我们可以再次测试一下读写：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"># 新的主机读</div><div class="line">root@node1:/etc/keepalived# ls /vol/ec1</div><div class="line">client.txt  hello.txt  lost+found</div><div class="line"></div><div class="line"># 新的主机写</div><div class="line">root@node1:/etc/keepalived# echo &apos;new service 111&apos; &gt; /vol/ec1/new_server.txt</div><div class="line">root@node1:/etc/keepalived# ls /vol/ec1</div><div class="line">client.txt  hello.txt  lost+found  new_server.txt</div><div class="line"></div><div class="line"># 客户端读</div><div class="line">[root@tony ec1]# ls</div><div class="line">client.txt  hello.txt  lost+found  new_server.txt</div><div class="line">[root@tony ec1]# cat new_server.txt</div><div class="line">new service 111</div><div class="line"></div><div class="line"># 客户端写</div><div class="line">[root@tony ec1]# echo &apos;hello new server&apos; &gt; hello_new_server.txt</div><div class="line"># 可以看到刚刚客户端写的文件</div><div class="line">root@node1:/vol/ec1# ls</div><div class="line">client.txt  hello_new_server.txt  hello.txt  lost+found  new_server.txt</div></pre></td></tr></table></figure><p>ok，本测试通过~</p><h4 id="手动关机主机"><a href="#手动关机主机" class="headerlink" title="手动关机主机"></a>手动关机主机</h4><p>关闭主机<code>node1</code>，稍等片刻，确定完全关闭再测试</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">root@node1:/vol# reboot</div><div class="line"></div><div class="line">Broadcast message from root@node1</div><div class="line">(/dev/pts/3) at 9:16 ...</div><div class="line"></div><div class="line">The system is going down for reboot NOW!</div></pre></td></tr></table></figure><p>等待完全关闭，我们在<code>node3</code>上看到了<code>VIP</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">root@node3:~# ip addr</div><div class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN </div><div class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</div><div class="line">    inet 127.0.0.1/8 scope host lo</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP qlen 1000</div><div class="line">    link/ether 00:50:56:aa:a9:13 brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 192.168.1.113/24 brd 192.168.1.255 scope global eth0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">    inet 192.168.1.13/24 scope global secondary eth0</div><div class="line">       valid_lft forever preferred_lft forever</div></pre></td></tr></table></figure><p>客户端读写测试：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># 客户端读</div><div class="line">[root@tony ec1]# ls</div><div class="line">client.txt  hello_new_server.txt  hello.txt  lost+found  new_server.txt</div><div class="line"># 客户端写</div><div class="line">[root@tony ec1]# echo &apos;reboot&apos; &gt;  reboot.txt</div><div class="line">[root@tony ec1]# ls</div><div class="line">client.txt  hello_new_server.txt  hello.txt  lost+found  new_server.txt  reboot.txt</div></pre></td></tr></table></figure><p><code>node3</code>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">root@node3:~# ls /vol/ec1</div><div class="line">client.txt  hello_new_server.txt  hello.txt  lost+found  new_server.txt  reboot.txt</div><div class="line">root@node3:~# cat /vol/ec1/reboot.txt </div><div class="line">reboot</div></pre></td></tr></table></figure><p>ok，本测试通过~</p><h3 id="测试小结"><a href="#测试小结" class="headerlink" title="测试小结"></a>测试小结</h3><p>通过上面三个测试，我们已经基本确保了<code>keepalived</code>会保证集群中主机发生异常时还是可以很好地对外提供服务，并且真正地做到了高可用，低延时，高可靠。</p><h2 id="QA-环节"><a href="#QA-环节" class="headerlink" title="QA 环节"></a>QA 环节</h2><p>因为我实现这个<code>RBD</code>高可用是在我们项目中做的，我们项目中<code>UI</code>上可以创建共享目录，但是之前都是用的<code>cephfs</code>实现的，而我做的就是将<code>cephfs</code>方式使用<code>RBD</code>替代，大家应该都清楚作为<code>POSIX</code>文件接口的<code>cephfs</code>内部已经做好了很多事情，它可以将所有节点挂载的目录做到真正的共享，也就是共享目录三个目录都有，改一个其他两个都会随之而改变，而不是像我们<code>RBD</code>同时只会针对某一个主机访问。</p><p>而<code>RBD</code>替换的话必然存在很多困难和问题，在这里我就以<code>QA</code>问答的方式分享一下我实现过程中遇到的种种问题和别人提出的需求。</p><h3 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h3><p>问：如何通过代码实现三个节点都做相关操作的，比如创建<code>image</code>和目录等等？</p><p>答：我们项目是这样实现的，将前端<code>UI</code>的增删改查（比如创建或删除目录等）和后端具体实现共享目录业务分离，也就是说前端只负责做这些信息的增删改查，对应的后端也只是负责这些信息的增删改查，所以用户会即时收到反馈。而真正做事的是在共享业务后端，这个和<code>UI</code>对应的后端做事有所区别，这边共享业务后端是做成了一个<code>Daemon</code>每隔几秒就会去扫描<code>UI</code>后端存储数据是否变化，发生了变化就会做相关操作，比如多了一个文件夹就要创建<code>image</code>等，删除一个文件夹也要做一系列的事情。</p><h3 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h3><p>问：如何判断哪个节点是<code>master</code>？</p><p>答：这个很简单，就通过<code>ip addr</code>命令查找<code>VIP</code>就好了，不能通过配置文件中的<code>priority</code>来判断，因为即使角色切换，那个值也不会变化的，也就是说即使<code>priority</code>是最大值也有可能当前节点不是主节点，这里要注意的是不能仅仅是包含<code>VIP</code>，而是要精确匹配才行，比如<code>VIP</code>是<code>192.168.1.12</code>，如果此时还有个<code>192.168.1.123</code>，如果只是字符串包含的话，那这个也会被匹配，所以要精确匹配。</p><h3 id="问题3"><a href="#问题3" class="headerlink" title="问题3"></a>问题3</h3><p>问：创建文件夹后端实现的逻辑是什么样的？</p><p>答：后端<code>Daemon</code>当扫描存储的目录信息相比于上一次扫描时新增的话，那么后端就会做事情了。首先我们要判断是否为主节点，如果是主节点，那么就创建<code>image</code>，然后做<code>Map</code>，接着就要<code>format</code>文件系统，创建目录，然后再做挂载。这时候要注意其他两个备节点也要做<code>rbd map</code>操作，这样做的原因，一是为了占位，比如当创建的项目多了之后，<code>backup</code>节点再<code>map</code>的时候顺序会乱掉，二是为了当主机<code>down</code>，备机转换为<code>master</code>后要找同样的块设备挂载，比如都是<code>/dev/rbd0</code></p><h3 id="问题4"><a href="#问题4" class="headerlink" title="问题4"></a>问题4</h3><p>问：删除文件夹后端实现的逻辑是什么样的？</p><p>答：扫描当前目录少于上一次扫描的目录，那么就针对这些目录，主节点要先<code>umount</code>，再<code>umap</code>，然后<code>rm image</code>，最后删除目录，对于备节点的话就<code>umap</code>，然后再删除目录就好</p><h3 id="问题5"><a href="#问题5" class="headerlink" title="问题5"></a>问题5</h3><p>问：三个节点的<code>Daemon</code>可能执行的顺序不一样，不一定是主节点先执行，那么这个时候备节点将无法<code>map</code>，同理很有可能在删除<code>image</code>的时候，别的节点的<code>image</code>都还没<code>unmap</code>，这样的话<code>image</code>是会删除失败的，这里怎么处理节点间的冲突呢？</p><p>答：</p><p>首先是创建目录，这时候主节点我们已经做得比较好了，主要担心备节点<code>map</code>的时候<code>image</code>还没有创建，那么我们这边就要判断一下，如果<code>image</code>还不在指定<code>pool</code>中，那么就要设置当前目录情况还为上一次的目录信息，这样下一次扫描代码就会又以为有新目录了，那么该段代码就会又执行一次，此时应该成功了，反正只要成功的时候才会把当前目录信息更改为最新的目录信息。</p><p>再来说删除目录，这个和创建<code>map</code>不同的地方在于，我要删除<code>image</code>的时候，我无法知道这个<code>image</code>还有没有和其他节点有<code>map</code>关系，所以我们只有尝试去删除，这边加一个异常捕获，因为<code>rm image</code>报错我们不处理的话会造成代码出错，所以外面包一层异常，这样就可以和上面类似的操作了。这边要注意的是一旦发生异常，我们还必须要在<code>map</code>回去，否则我们无法获取<code>pool</code>等信息了，因为我们是通过<code>rbd showmapped</code>来获取相关信息的。</p><h3 id="问题6"><a href="#问题6" class="headerlink" title="问题6"></a>问题6</h3><p>问：请问<code>keepalived</code>如何做自动化的？</p><p>答：由于<code>keepalived</code>也比较简单，三个配置文件相关配置信息都配一样的，我们要做的就是网卡和<code>VIP</code>，网卡的话我们就从项目中获取<code>public ip</code>，而<code>VIP</code>就是<code>UI</code>上面配置的，然后读写文件就好了。</p><h3 id="问题7"><a href="#问题7" class="headerlink" title="问题7"></a>问题7</h3><p>问：一旦节点关机的话，下次开机后块设备就会没了，我们该如何做呢？</p><p>答：这个问题的确存在，所以我们要提前将对应关系存在文件中，下次开机的时候根据文件然后对应做<code>map</code>工作</p><h3 id="问题8"><a href="#问题8" class="headerlink" title="问题8"></a>问题8</h3><p>问：多个块设备的时候，<code>keepalived</code>触发的脚本如何做？</p><p>答：其实这个的做法我已经暴露在上面我分享的三个脚本里面了，要做的就是遍历<code>/vol</code>目录下的所有目录或者所有<code>rbd*</code>，这边要注意的就是<code>/vol/</code>或者指定目录下存在的必须只有创建的共享目录。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文通过<code>keepalived</code>初步实现了<code>RBD</code>的高可用，简单地替代了<code>cephfs</code>导出<code>NFS</code>，针对<code>cephfs</code>性能不行的问题，应该有很多小伙伴有这种需求，希望这篇文章能给大家带来一些思路和帮助</p><p>之后，我会尝试研究<code>CTDB</code>做高可用，因为<code>keepalived</code>由于比较简单，所以功能也就比较局限了。然后本文只有<code>NFS</code>，后续应该还会有<code>smb</code>，<code>iscsi</code>等等</p><p>通过本文，我对<code>RBD</code>和高可用的认识又深入了一些，其实本文涉及到的技术还是比较简单的，还有很多更复杂、更牛逼的高可用方案，这里不禁要说一句，后端还是有意思呀！（相比于前端而言），起码对我来说是这样的，以后会不断精进这些技术，加油！</p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/HA.jpg&quot; alt=&quot;HA&quot;&gt;&lt;/center&gt;

&lt;p&gt;由于&lt;code&gt;Cephfs&lt;/code&gt;很不稳定，并且性能差，很难达到用户在性能上的需求，所以&lt;code&gt;Cephfs&lt;/code&gt;也难以应用于生产环境之上。而&lt;code&gt;RBD&lt;/code&gt;可以说是一直非常稳定的存储接口方案，用户可以将&lt;code&gt;image&lt;/code&gt;挂载到客户端进行访问读写，然而很多用户不愿意在本地安装&lt;code&gt;Ceph&lt;/code&gt;客户端，所以我们常常需要自己封装一层，给客户端暴露出一个通用的接口进行访问，现在一般都是默认用&lt;code&gt;NFS&lt;/code&gt;，所以本文就&lt;code&gt;Ceph RBD&lt;/code&gt;如何实现高可用暴露&lt;code&gt;NFS&lt;/code&gt;给客户端访问进行分享。&lt;/p&gt;
    
    </summary>
    
      <category term="tech" scheme="https://tony-yin.github.io/categories/tech/"/>
    
    
      <category term="Ceph" scheme="https://tony-yin.github.io/tags/Ceph/"/>
    
      <category term="RBD" scheme="https://tony-yin.github.io/tags/RBD/"/>
    
      <category term="HA" scheme="https://tony-yin.github.io/tags/HA/"/>
    
      <category term="Keepalived" scheme="https://tony-yin.github.io/tags/Keepalived/"/>
    
  </entry>
  
  <entry>
    <title>Cephx 实战演练</title>
    <link href="https://tony-yin.github.io/2017/11/30/Cephx-practice/"/>
    <id>https://tony-yin.github.io/2017/11/30/Cephx-practice/</id>
    <published>2017-11-30T03:04:04.000Z</published>
    <updated>2017-11-30T03:10:00.441Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/cephx-600x450.jpg" alt="cephx"></center><p>本文就阅读完<a href="http://www.xuxiaopang.com/2017/08/23/easy-ceph-CephX/" target="_blank" rel="external">徐小胖的大话Cephx</a>后，针对一些猜测和疑惑进行了实战演练，对原文的一些说法和结论进行了验证，并进行了一系列的扩展的思考猜想和总结。最后收获满满，不仅对原文的一些结论进行了验证，也发现了其中的一些问题，更多的是自己动手后一些奇妙的场景和发现。</p><a id="more"></a><p>本文实战任务和完成情况如下：</p><ul><li style="list-style: none"><input type="checkbox" checked> 删除<code>client.admin.keyring</code></li><li style="list-style: none"><input type="checkbox" checked> 修改<code>cephx</code>配置</li><li style="list-style: none"><input type="checkbox" checked> 修改<code>Monitor keyring</code></li><li style="list-style: none"><input type="checkbox" checked> 修改<code>OSD keyring</code></li><li style="list-style: none"><input type="checkbox" checked> 修改<code>client.admin.keyring</code>，通过<code>Mon</code>找回正确的<code>keyring</code></li><li style="list-style: none"><input type="checkbox" checked> <code>Mon Cap</code></li><li style="list-style: none"><input type="checkbox" checked> <code>OSD Cap</code></li><li style="list-style: none"><input type="checkbox" checked> 删除所有<code>keyring</code>文件再恢复</li><li style="list-style: none"><input type="checkbox" checked> 删除<code>ceph.conf</code>再恢复</li><li style="list-style: none"><input type="checkbox"> 关闭<code>CephX</code>后不重启<code>OSD</code></li><li style="list-style: none"><input type="checkbox" checked> 通过<code>osd.keyring</code>访问集群</li><li style="list-style: none"><input type="checkbox"> 配置只能访问一个<code>RBD</code>的用户权限</li></ul><h2 id="删除-client-admin-keyring"><a href="#删除-client-admin-keyring" class="headerlink" title="删除 client.admin.keyring"></a>删除 client.admin.keyring</h2><p>主节点开始存在<code>keyring</code>，可以正常访问集群</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">[root@node1 ceph]# ls</div><div class="line">ceph.bootstrap-mds.keyring  ceph.bootstrap-osd.keyring  ceph.client.admin.keyring  ceph-deploy-ceph.log  rbdmap</div><div class="line">ceph.bootstrap-mgr.keyring  ceph.bootstrap-rgw.keyring  ceph.conf                  ceph.mon.keyring</div><div class="line">[root@node1 ceph]# ceph -s</div><div class="line">  cluster:</div><div class="line">    id:     99480db2-f92f-481f-b958-c03c261918c6</div><div class="line">    health: HEALTH_WARN</div><div class="line">            no active mgr</div><div class="line">            Reduced data availability: 281 pgs inactive, 65 pgs down, 58 pgs incomplete</div><div class="line">            Degraded data redundancy: 311/771 objects degraded (40.337%), 439 pgs unclean, 316 pgs degraded, 316 pgs undersized</div><div class="line">            application not enabled on 3 pool(s)</div><div class="line">            clock skew detected on mon.node2, mon.node3</div><div class="line"> </div><div class="line">  services:</div><div class="line">    mon:     3 daemons, quorum node1,node2,node3</div><div class="line">    mgr:     no daemons active</div><div class="line">    osd:     6 osds: 5 up, 5 in</div><div class="line">    rgw:     1 daemon active</div><div class="line">    rgw-nfs: 1 daemon active</div><div class="line"> </div><div class="line">  data:</div><div class="line">    pools:   10 pools, 444 pgs</div><div class="line">    objects: 257 objects, 36140 kB</div><div class="line">    usage:   6256 MB used, 40645 MB / 46901 MB avail</div><div class="line">    pgs:     63.288% pgs not active</div><div class="line">             311/771 objects degraded (40.337%)</div><div class="line">             158 undersized+degraded+peered</div><div class="line">             158 active+undersized+degraded</div><div class="line">             65  down</div><div class="line">             58  incomplete</div><div class="line">             5   active+clean+remapped</div></pre></td></tr></table></figure><p>将<code>keyring</code>文件移动到其他地方，相当于删除了<code>keyring</code>，这时访问集群报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@node1 ceph]# mv ceph.client.admin.keyring /tmp/</div><div class="line">[root@node1 ceph]# ls</div><div class="line">ceph.bootstrap-mds.keyring  ceph.bootstrap-mgr.keyring  ceph.bootstrap-osd.keyring  ceph.bootstrap-rgw.keyring  ceph.conf  ceph-deploy-ceph.log  ceph.mon.keyring  rbdmap</div><div class="line">[root@node1 ceph]# ceph -s</div><div class="line">2017-11-23 18:07:48.685028 7f63f6935700 -1 auth: unable to find a keyring on /etc/ceph/ceph.client.admin.keyring,/etc/ceph/ceph.keyring,/etc/ceph/keyring,/etc/ceph/keyring.bin,: (2) No such file or directory</div><div class="line">2017-11-23 18:07:48.685094 7f63f6935700 -1 monclient: ERROR: missing keyring, cannot use cephx for authentication</div><div class="line">2017-11-23 18:07:48.685098 7f63f6935700  0 librados: client.admin initialization error (2) No such file or directory</div><div class="line">[errno 2] error connecting to the cluster</div></pre></td></tr></table></figure><p>再拷贝回来又可以访问集群了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[root@node1 ceph]# mv /tmp/ceph.client.admin.keyring ./</div><div class="line">[root@node1 ceph]# ceph -s</div><div class="line">  cluster:</div><div class="line">    id:     99480db2-f92f-481f-b958-c03c261918c6</div><div class="line">    health: HEALTH_WARN</div><div class="line">            no active mgr</div><div class="line">            Reduced data availability: 281 pgs inactive, 65 pgs down, 58 pgs incomplete</div><div class="line">            Degraded data redundancy: 311/771 objects degraded (40.337%), 439 pgs unclean, 316 pgs degraded, 316 pgs undersized</div><div class="line">            application not enabled on 3 pool(s)</div><div class="line">            clock skew detected on mon.node2, mon.node3</div></pre></td></tr></table></figure><p><code>node3</code>由于<code>/etc/ceph/</code>目录下没有<code>keyring</code>文件，所以也无法连接集群</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@node3 ceph]# ls</div><div class="line">ceph.conf  ceph-deploy-ceph.log  rbdmap</div><div class="line">[root@node3 ceph]# ceph -s</div><div class="line">2017-11-23 17:59:16.659034 7fbe34678700 -1 auth: unable to find a keyring on /etc/ceph/ceph.client.admin.keyring,/etc/ceph/ceph.keyring,/etc/ceph/keyring,/etc/ceph/keyring.bin,: (2) No such file or directory</div><div class="line">2017-11-23 17:59:16.659085 7fbe34678700 -1 monclient: ERROR: missing keyring, cannot use cephx for authentication</div><div class="line">2017-11-23 17:59:16.659089 7fbe34678700  0 librados: client.admin initialization error (2) No such file or directory</div><div class="line">[errno 2] error connecting to the cluster</div></pre></td></tr></table></figure><p><strong>结论：</strong></p><blockquote><p>当<code>ceph.conf</code>中的<code>auth</code>配置为<code>cephx</code>的时候，访问集群是需要秘钥文件的</p></blockquote><h2 id="修改-cephx-配置"><a href="#修改-cephx-配置" class="headerlink" title="修改 cephx 配置"></a>修改 cephx 配置</h2><p>在<code>node3</code>节点上的<code>/etc/ceph/</code>目录下操作，首先将<code>ceph.client.admin.keyring</code>文件删除，然后将<code>auth</code>配置从<code>cephx</code>改为<code>none</code>，然后先重启<code>monitor</code>，再重启<code>osd</code>，这时候依然不可以访问集群，因为<code>cephx</code>是面向整个集群的，而不是某个节点，接下来需要在其他节点做一样的操作，更改<code>cephx</code>为<code>none</code>，然后重启<code>monitor</code>和<code>osd</code>，这时候便可以在没有<code>keyring</code>文件的情况下访问集群了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"># 删除keyring文件</div><div class="line">[root@node3 ~]# cd /etc/ceph/</div><div class="line">[root@node3 ceph]# ls</div><div class="line">ceph.client.admin.keyring  ceph.conf  ceph-deploy-ceph.log  rbdmap</div><div class="line">[root@node3 ceph]# mv ceph.client.admin.keyring /tmp/</div><div class="line"># 更改cephx配置</div><div class="line">[root@node3 ceph]# cat ceph.conf </div><div class="line">[global]</div><div class="line">fsid = 99480db2-f92f-481f-b958-c03c261918c6</div><div class="line">mon_initial_members = node1, node2, node3</div><div class="line">mon_host = 192.168.1.58,192.168.1.61,192.168.1.62</div><div class="line">auth_cluster_required = cephx</div><div class="line">auth_service_required = cephx</div><div class="line">auth_client_required = cephx</div><div class="line"></div><div class="line">public network = 192.168.1.0/24</div><div class="line">mon clock drift allowed = 2</div><div class="line">mon clock drift warn backoff = 30</div><div class="line">[root@node3 ceph]# vim ceph.conf </div><div class="line">[root@node3 ceph]# cat ceph.conf </div><div class="line">[global]</div><div class="line">fsid = 99480db2-f92f-481f-b958-c03c261918c6</div><div class="line">mon_initial_members = node1, node2, node3</div><div class="line">mon_host = 192.168.1.58,192.168.1.61,192.168.1.62</div><div class="line">auth_cluster_required = none</div><div class="line">auth_service_required = none</div><div class="line">auth_client_required = none</div><div class="line"></div><div class="line">public network = 192.168.1.0/24</div><div class="line">mon clock drift allowed = 2</div><div class="line">mon clock drift warn backoff = 30</div><div class="line">[root@node3 ceph]# systemctl restart ceph-mon</div><div class="line">ceph-mon@               ceph-mon@node3.service  ceph-mon.target         </div><div class="line">[root@node3 ceph]# systemctl restart ceph-mon</div><div class="line">ceph-mon@               ceph-mon@node3.service  ceph-mon.target         </div><div class="line">[root@node3 ceph]# systemctl restart ceph-mon.target</div><div class="line">[root@node3 ceph]# systemctl restart ceph-osd.target</div><div class="line"># 更改单个节点配置后依然不可以访问集群</div><div class="line">[root@node3 ceph]# ceph -s</div><div class="line">2017-11-27 23:05:23.022571 7f5200c2f700  0 librados: client.admin authentication error (95) Operation not supported</div><div class="line">[errno 95] error connecting to the cluster</div><div class="line"># 相应的更改其他几个节点并重启，便又可以正常访问集群了</div><div class="line">[root@node3 ceph]# ceph -s</div><div class="line">  cluster:</div><div class="line">    id:     99480db2-f92f-481f-b958-c03c261918c6</div><div class="line">    health: HEALTH_WARN</div><div class="line">    ...</div></pre></td></tr></table></figure><p><strong>结论：</strong></p><blockquote><p>当<code>auth</code>配置为<code>cephx</code>的时候访问集群必须要借助秘钥文件，而当<code>auth</code>配置为<code>none</code>的时候，不再需要秘钥文件就可以访问集群了。（<strong>更改配置需要集群所有节点都做才可以生效，而不是单一节点</strong>）</p></blockquote><h2 id="删除monitor秘钥"><a href="#删除monitor秘钥" class="headerlink" title="删除monitor秘钥"></a>删除monitor秘钥</h2><p><code>/etc/ceph</code>和<code>/var/lib//ceph/mon/ceph-node1</code>各有一个<code>mon keyring</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@node1 ceph-node1]# cd /etc/ceph/</div><div class="line">[root@node1 ceph]# ls</div><div class="line">ceph.bootstrap-mds.keyring  ceph.bootstrap-osd.keyring  ceph.client.admin.keyring  ceph-deploy-ceph.log  rbdmap</div><div class="line">ceph.bootstrap-mgr.keyring  ceph.bootstrap-rgw.keyring  ceph.conf                  ceph.mon.keyring</div><div class="line">[root@node1 ceph]# cd /var/lib/ceph/mon/ceph-node1/</div><div class="line">[root@node1 ceph-node1]# ls</div><div class="line">done  keyring  kv_backend  store.db  systemd</div></pre></td></tr></table></figure></p><p>先删除<code>/etc/ceph/ceph-mon.keyring</code>，还是可以访问集群</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[root@node1 ceph]# rm ceph.mon.keyring </div><div class="line">rm: remove regular file ‘ceph.mon.keyring’? y</div><div class="line">[root@node1 ceph]# systemctl restart ceph-mon@node1.service </div><div class="line">[root@node1 ceph]# ceph -s</div><div class="line">  cluster:</div><div class="line">    id:     99480db2-f92f-481f-b958-c03c261918c6</div><div class="line">    health: HEALTH_WARN</div><div class="line">            no active mgr</div><div class="line">            Reduced data availability: 281 pgs inactive, 65 pgs down, 58 pgs incomplete</div><div class="line">            Degraded data redundancy: 311/771 objects degraded (40.337%), 439 pgs unclean, 316 pgs degraded, 316 pgs undersized</div><div class="line">            application not enabled on 3 pool(s)</div><div class="line">            clock skew detected on mon.node2</div><div class="line">...</div><div class="line">...</div></pre></td></tr></table></figure><p>再删除<code>/var/lib/ceph/mon/ceph-node1/keyring</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node1 ceph-node1]# rm keyring </div><div class="line">rm: remove regular file ‘keyring’? y</div><div class="line">[root@node1 ceph-node1]# systemctl restart ceph-mon@node1.service </div><div class="line">[root@node1 ceph-node1]# ceph -s</div></pre></td></tr></table></figure><p>访问集群一直<code>timeount</code>，查看<code>log</code>文件发现<code>Mon</code>初始化失败</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">2017-11-24 00:33:55.812955 7fa16f995e40 -1 auth: error reading file: /var/lib/ceph/mon/ceph-node1/keyring: can&apos;t open /var/lib/ceph/mon/ceph-node1/keyring: (2) No such file or directory</div><div class="line">2017-11-24 00:33:55.812991 7fa16f995e40 -1 mon.node1@-1(probing) e1 unable to load initial keyring /etc/ceph/ceph.mon.node1.keyring,/etc/ceph/ceph.keyring,/etc/ceph/keyring,/etc/ceph/keyring.bin,</div><div class="line">2017-11-24 00:33:55.812999 7fa16f995e40 -1 failed to initialize</div></pre></td></tr></table></figure><p>ok，那我们再试试将<code>/var/lib/ceph/mon/ceph-node1/keyring</code>删除，将<code>etc/ceph/ceph.mon.keyring</code>拷贝回来，这时候意外发生了，居然<code>mon</code>初始化失败</p><p><strong>结论：</strong></p><blockquote><p><code>Monitor</code>启动是需要<code>keyring</code>文件进行秘钥认证的，并且这个文件必须是<code>/var/lib/ceph/mon/ceph-node1/</code>目录下的，<code>/etc/ceph/</code>目录下的<code>ceph.mon.keyring</code>并不起作用</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@node1 ceph-node1]# rm keyring </div><div class="line">rm: remove regular file ‘keyring’? y</div><div class="line">[root@node1 ceph]# ls</div><div class="line">ceph.bootstrap-mds.keyring  ceph.bootstrap-osd.keyring  ceph.client.admin.keyring  ceph-deploy-ceph.log  rbdmap</div><div class="line">ceph.bootstrap-mgr.keyring  ceph.bootstrap-rgw.keyring  ceph.conf                  ceph.mon.keyring  </div><div class="line">[root@node1 ceph]# ceph -s</div><div class="line">// timeout</div><div class="line">...</div></pre></td></tr></table></figure><p><code>mon.log</code>中的现象：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">2017-11-24 00:44:26.534865 7ffaf5117e40 -1 auth: error reading file: /var/lib/ceph/mon/ceph-node1/keyring: can&apos;t open /var/lib/ceph/mon/ceph-node1/keyring: (2) No such file or directory</div><div class="line">2017-11-24 00:44:26.534901 7ffaf5117e40 -1 mon.node1@-1(probing) e1 unable to load initial keyring /etc/ceph/ceph.mon.node1.keyring,/etc/ceph/ceph.keyring,/etc/ceph/keyring,/etc/ceph/keyring.bin,</div><div class="line">2017-11-24 00:44:26.534916 7ffaf5117e40 -1 failed to initialize</div></pre></td></tr></table></figure><p>至此，我们可以得出结论<code>monitor</code>初始化的时候依赖的文件是<code>/var/lib/ceph/mon/ceph-node1/keyring</code>而不是<code>/etc/ceph/ceph.mon.keyring</code></p><h2 id="修改-Mon-keyring"><a href="#修改-Mon-keyring" class="headerlink" title="修改 Mon keyring"></a>修改 Mon keyring</h2><h3 id="原始的-keyring"><a href="#原始的-keyring" class="headerlink" title="原始的 keyring"></a>原始的 keyring</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">[root@node1 ceph-node1]# cat keyring </div><div class="line">[mon.]</div><div class="line">key = AQCo7fdZAAAAABAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div><div class="line">[root@node1 ceph-node1]# ceph auth get mon.</div><div class="line">exported keyring for mon.</div><div class="line">[mon.]</div><div class="line">key = AQCo7fdZAAAAABAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div></pre></td></tr></table></figure><h3 id="将中间的五个A替换成了五个C"><a href="#将中间的五个A替换成了五个C" class="headerlink" title="将中间的五个A替换成了五个C"></a>将中间的五个A替换成了五个C</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@node1 ceph-node1]# vim keyring </div><div class="line">[root@node1 ceph-node1]# cat keyring </div><div class="line">[mon.]</div><div class="line">key = AQCo7fdZCCCCCBAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div></pre></td></tr></table></figure><h3 id="重启查看-Mon-keyring"><a href="#重启查看-Mon-keyring" class="headerlink" title="重启查看 Mon keyring"></a>重启查看 Mon keyring</h3><p>理想结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@node1 ceph-node1]# systemctl restart ceph-mon.target</div><div class="line">[root@node1 ceph-node1]# ceph auth get mon.</div><div class="line">exported keyring for mon.</div><div class="line">[mon.]</div><div class="line">key = AQCo7fdZCCCCCBAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div></pre></td></tr></table></figure><p>令人疑惑的现实：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line">[root@node1 ceph]# ceph auth get mon.</div><div class="line">exported keyring for mon.</div><div class="line">[mon.]</div><div class="line">key = AQCo7fdZAAAAABAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div><div class="line">[root@node1 ceph]# ceph auth get mon.</div><div class="line">exported keyring for mon.</div><div class="line">[mon.]</div><div class="line">key = AQCo7fdZAAAAABAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div><div class="line">[root@node1 ceph]# ceph auth get mon.</div><div class="line">exported keyring for mon.</div><div class="line">[mon.]</div><div class="line">key = AQCo7fdZCCCCCBAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div><div class="line">[root@node1 ceph]# ceph auth get mon.</div><div class="line">exported keyring for mon.</div><div class="line">[mon.]</div><div class="line">key = AQCo7fdZCCCCCBAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div><div class="line">[root@node1 ceph]# ceph auth get mon.</div><div class="line">exported keyring for mon.</div><div class="line">[mon.]</div><div class="line">key = AQCo7fdZCCCCCBAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div><div class="line">[root@node1 ceph]# ceph auth get mon.</div><div class="line">exported keyring for mon.</div><div class="line">[mon.]</div><div class="line">key = AQCo7fdZCCCCCBAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div><div class="line">[root@node1 ceph]# ceph auth get mon.</div><div class="line">exported keyring for mon.</div><div class="line">[mon.]</div><div class="line">key = AQCo7fdZCCCCCBAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div><div class="line">[root@node1 ceph]# ceph auth get mon.</div><div class="line">exported keyring for mon.</div><div class="line">[mon.]</div><div class="line">key = AQCo7fdZCCCCCBAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div><div class="line">[root@node1 ceph]# ceph auth get mon.</div><div class="line">exported keyring for mon.</div><div class="line">[mon.]</div><div class="line">key = AQCo7fdZCCCCCBAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div><div class="line">[root@node1 ceph]# ceph auth get mon.</div><div class="line">exported keyring for mon.</div><div class="line">[mon.]</div><div class="line">key = AQCo7fdZAAAAABAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div></pre></td></tr></table></figure><p>可以看到一会是修改之前的<code>keyring</code>，一会是修改之后的<code>keyring</code>，那遇到这种问题，我们就通过<code>log</code>观察如何获取<code>keyring</code>的</p><p><code>node1</code>的<code>mon.log</code>中日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">2017-11-24 09:30:08.697047 7f9b73e09700  0 mon.node1@0(leader) e1 handle_command mon_command(&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125; v 0) v1</div><div class="line">2017-11-24 09:30:08.697106 7f9b73e09700  0 log_channel(audit) log [INF] : from=&apos;client.? 192.168.1.58:0/1169357136&apos; entity=&apos;client.admin&apos; cmd=[&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125;]: dispatch</div><div class="line">2017-11-24 09:30:10.020571 7f9b73e09700  0 mon.node1@0(leader) e1 handle_command mon_command(&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125; v 0) v1</div><div class="line">2017-11-24 09:30:10.020641 7f9b73e09700  0 log_channel(audit) log [INF] : from=&apos;client.? 192.168.1.58:0/2455152702&apos; entity=&apos;client.admin&apos; cmd=[&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125;]: dispatch</div><div class="line">2017-11-24 09:30:11.393391 7f9b73e09700  0 mon.node1@0(leader) e1 handle_command mon_command(&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125; v 0) v1</div><div class="line">2017-11-24 09:30:11.393452 7f9b73e09700  0 log_channel(audit) log [INF] : from=&apos;client.? 192.168.1.58:0/1704778092&apos; entity=&apos;client.admin&apos; cmd=[&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125;]: dispatch</div><div class="line">2017-11-24 09:30:12.669987 7f9b73e09700  0 mon.node1@0(leader) e1 handle_command mon_command(&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125; v 0) v1</div><div class="line">2017-11-24 09:30:12.670049 7f9b73e09700  0 log_channel(audit) log [INF] : from=&apos;client.? 192.168.1.58:0/275069695&apos; entity=&apos;client.admin&apos; cmd=[&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125;]: dispatch</div><div class="line">2017-11-24 09:30:14.113077 7f9b73e09700  0 mon.node1@0(leader) e1 handle_command mon_command(&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125; v 0) v1</div><div class="line">2017-11-24 09:30:14.113147 7f9b73e09700  0 log_channel(audit) log [INF] : from=&apos;client.? 192.168.1.58:0/3800873459&apos; entity=&apos;client.admin&apos; cmd=[&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125;]: dispatch</div><div class="line">2017-11-24 09:30:15.742038 7f9b73e09700  0 mon.node1@0(leader) e1 handle_command mon_command(&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125; v 0) v1</div><div class="line">2017-11-24 09:30:15.742106 7f9b73e09700  0 log_channel(audit) log [INF] : from=&apos;client.? 192.168.1.58:0/1908944728&apos; entity=&apos;client.admin&apos; cmd=[&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125;]: dispatch</div><div class="line">2017-11-24 09:30:17.629681 7f9b73e09700  0 mon.node1@0(leader) e1 handle_command mon_command(&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125; v 0) v1</div><div class="line">2017-11-24 09:30:17.629729 7f9b73e09700  0 log_channel(audit) log [INF] : from=&apos;client.? 192.168.1.58:0/2193002591&apos; entity=&apos;client.admin&apos; cmd=[&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125;]: dispatch</div></pre></td></tr></table></figure><p><code>node2</code>的<code>mon.log</code>中日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">2017-11-24 09:29:23.799402 7fdb3c0ae700  0 log_channel(audit) log [INF] : from=&apos;client.? 192.168.1.58:0/4284881078&apos; entity=&apos;client.admin&apos; cmd=[&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125;]: dispatch</div><div class="line">2017-11-24 09:29:26.030516 7fdb3c0ae700  0 mon.node2@1(peon) e1 handle_command mon_command(&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125; v 0) v1</div><div class="line">2017-11-24 09:29:26.030588 7fdb3c0ae700  0 log_channel(audit) log [INF] : from=&apos;client.? 192.168.1.58:0/4157525590&apos; entity=&apos;client.admin&apos; cmd=[&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125;]: dispatch</div><div class="line">2017-11-24 09:29:38.637677 7fdb3c0ae700  0 mon.node2@1(peon) e1 handle_command mon_command(&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125; v 0) v1</div><div class="line">2017-11-24 09:29:38.637748 7fdb3c0ae700  0 log_channel(audit) log [INF] : from=&apos;client.? 192.168.1.58:0/4028820259&apos; entity=&apos;client.admin&apos; cmd=[&#123;&quot;prefix&quot;: &quot;auth get&quot;, &quot;entity&quot;: &quot;mon.&quot;&#125;]: dispatch</div></pre></td></tr></table></figure><p><strong>结论：</strong></p><ul><li><code>Monitor</code>的秘钥哪怕被修改过了，也不会影响<code>Monitor</code>的启动，也就是说<code>Monitor</code>启动时只要存在秘钥文件就好，内容忽略并不重要</li><li><code>Monitor</code>启动的时候读取秘钥文件是随机的，并不一定是当前节点的，具体选择机制需要后期去看源代码了</li></ul><h2 id="修改OSD-keyring和修复"><a href="#修改OSD-keyring和修复" class="headerlink" title="修改OSD keyring和修复"></a>修改OSD keyring和修复</h2><p><code>OSD</code>启动的时候需要秘钥才可以登录集群，这个秘钥会存在<code>Monitor</code>的数据库中，所以登录的时候就会拿本地的<code>keyring</code>和存在<code>Monitor</code>中的<code>keyring</code>相匹配，正确的话才可以启动成功。</p><p>下面我们将本地的<code>OSD keyring</code>故意改错，然后重启<code>OSD</code>查看效果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"># 更改秘钥文件</div><div class="line">[root@node3 ceph]# cd /var/lib/ceph/osd/ceph-2</div><div class="line">[root@node3 ceph-2]# ls</div><div class="line">activate.monmap  active  block  bluefs  ceph_fsid  fsid  keyring  kv_backend  magic  mkfs_done  ready  systemd  type  whoami</div><div class="line">[root@node3 ceph-2]# cat keyring </div><div class="line">[osd.2]</div><div class="line">key = AQCp8/dZ4BHbHxAA/GXihrjCOB+7kZJfgnSy+Q==</div><div class="line">[root@node3 ceph-2]# vim keyring </div><div class="line">[root@node3 ceph-2]# cat keyring </div><div class="line">[osd.2]</div><div class="line">key = BBBp8/dZ4BHbHxAA/GXihrjCOB+7kZJfgnSy+Q==</div><div class="line">[root@node3 ceph-2]# systemctl restart ceph-osd</div><div class="line">ceph-osd@           ceph-osd@2.service  ceph-osd@5.service  ceph-osd.target     </div><div class="line">[root@node3 ceph-2]# systemctl restart ceph-osd</div><div class="line">ceph-osd@           ceph-osd@2.service  ceph-osd@5.service  ceph-osd.target     </div><div class="line">[root@node3 ceph-2]# systemctl restart ceph-osd@2.service</div><div class="line"># 重启后发现OSD的状态时down</div><div class="line">[root@node3 ceph-2]# ceph osd tree | grep osd.2</div><div class="line"> 2   hdd 0.00980         osd.2    down  1.00000 1.00000</div></pre></td></tr></table></figure><p>查看日志，发现<code>init</code>失败，原因是<code>auth</code>认证出错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">2017-11-27 23:52:18.069207 7fae1e8d2d00 -1 auth: error parsing file /var/lib/ceph/osd/ceph-2/keyring</div><div class="line">2017-11-27 23:52:18.069285 7fae1e8d2d00 -1 auth: failed to load /var/lib/ceph/osd/ceph-2/keyring: (5) Input/output error</div><div class="line">...</div><div class="line">2017-11-27 23:52:41.232803 7f58d15ded00 -1  ** ERROR: osd init failed: (5) Input/output error</div></pre></td></tr></table></figure><p>我们可以通过查询<code>Monitor</code>数据库获取正确的<code>keyring</code>，将错误的<code>keyring</code>修正过来再重启<code>OSD</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"># 查询Monitor数据库中的osd keyring</div><div class="line">[root@node3 ceph-2]# ceph auth get osd.2</div><div class="line">exported keyring for osd.2</div><div class="line">[osd.2]</div><div class="line">key = AQCp8/dZ4BHbHxAA/GXihrjCOB+7kZJfgnSy+Q==</div><div class="line">caps mgr = &quot;allow profile osd&quot;</div><div class="line">caps mon = &quot;allow profile osd&quot;</div><div class="line">caps osd = &quot;allow *&quot;</div><div class="line"># 修正keyring</div><div class="line">[root@node3 ceph-2]# vim keyring </div><div class="line">[root@node3 ceph-2]# cat keyring </div><div class="line">[osd.2]</div><div class="line">key = AQCp8/dZ4BHbHxAA/GXihrjCOB+7kZJfgnSy+Q==</div><div class="line">[root@node3 ceph-2]# systemctl restart ceph-osd@2.service </div><div class="line"># 重启OSD后可以发现osd.2状态已经变为up</div><div class="line">[root@node3 ceph-2]# ceph osd tree | grep osd.2</div><div class="line"> 2   hdd 0.00980         osd.2      up  1.00000 1.00000</div></pre></td></tr></table></figure><p><strong>结论：</strong></p><blockquote><p><code>OSD</code>启动需要正确的<code>keyring</code>，错误的话则无法启动成功，正确的<code>keyring</code>会被存在<code>Monitor</code>的数据库中</p></blockquote><h2 id="修改Client-keyring和修复"><a href="#修改Client-keyring和修复" class="headerlink" title="修改Client keyring和修复"></a>修改Client keyring和修复</h2><p>之前我们通过删除<code>client keyring</code>验证了当<code>auth=cephx</code>的时候，客户端需要<code>keyring</code>才可以访问集群，那么它是像<code>Monitor</code>一样内容不被<code>care</code>还是和<code>OSD</code>一样需要精确匹配<code>keyring</code>呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"># 修改ceph.client.admin.keyring</div><div class="line">[root@node3 ceph-2]# cd /etc/ceph/</div><div class="line">[root@node3 ceph]# ls</div><div class="line">ceph.client.admin.keyring  ceph.conf  ceph-deploy-ceph.log  rbdmap</div><div class="line">[root@node3 ceph]# cat ceph.client.admin.keyring </div><div class="line">[client.admin]</div><div class="line">key = AQDL7fdZWaQkIBAAsFhvFVQYqSeM/FVSY6o8TQ==</div><div class="line">[root@node3 ceph]# vim ceph.client.admin.keyring </div><div class="line">[root@node3 ceph]# cat ceph.client.admin.keyring </div><div class="line">[client.admin]</div><div class="line">key = BBBB7fdZWaQkIBAAsFhvFVQYqSeM/FVSY6o8TQ==</div><div class="line"># 访问集群出错</div><div class="line">[root@node3 ceph]# ceph -s</div><div class="line">2017-11-28 00:06:05.771604 7f3a69ccf700 -1 auth: error parsing file /etc/ceph/ceph.client.admin.keyring</div><div class="line">2017-11-28 00:06:05.771622 7f3a69ccf700 -1 auth: failed to load /etc/ceph/ceph.client.admin.keyring: (5) Input/output error</div><div class="line">2017-11-28 00:06:05.771634 7f3a69ccf700  0 librados: client.admin initialization error (5) Input/output error</div><div class="line">[errno 5] error connecting to the cluster</div></pre></td></tr></table></figure><p>可以看出访问集群需要正确的<code>keyring</code>，这时候如何修复呢？大家应该能够猜到，它和<code>OSD</code>的原理是一样的，正确的<code>keyring</code>也存在与<code>Monitor</code>的数据库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"># 直接获取client.admin出错</div><div class="line">[root@node3 ceph]# ceph auth get client.admin</div><div class="line">2017-11-28 00:08:19.159073 7fcabb297700 -1 auth: error parsing file /etc/ceph/ceph.client.admin.keyring</div><div class="line">2017-11-28 00:08:19.159079 7fcabb297700 -1 auth: failed to load /etc/ceph/ceph.client.admin.keyring: (5) Input/output error</div><div class="line">2017-11-28 00:08:19.159090 7fcabb297700  0 librados: client.admin initialization error (5) Input/output error</div><div class="line">[errno 5] error connecting to the cluster</div><div class="line"># 需要加上monitor的keyring文件才可以获取client.admin.keyring</div><div class="line">[root@node3 ceph]# ceph auth get client.admin --name mon. --keyring /var/lib/ceph/mon/ceph-node3/keyring</div><div class="line">exported keyring for client.admin</div><div class="line">[client.admin]</div><div class="line">key = AQDL7fdZWaQkIBAAsFhvFVQYqSeM/FVSY6o8TQ==</div><div class="line">caps mds = &quot;allow *&quot;</div><div class="line">caps mgr = &quot;allow *&quot;</div><div class="line">caps mon = &quot;allow *&quot;</div><div class="line">caps osd = &quot;allow *&quot;</div><div class="line"># 修正keyring</div><div class="line">[root@node3 ceph]# vim ceph</div><div class="line">ceph.client.admin.keyring  ceph.conf                  ceph-deploy-ceph.log       </div><div class="line">[root@node3 ceph]# vim ceph.client.admin.keyring </div><div class="line">[root@node3 ceph]# cat ceph.client.admin.keyring </div><div class="line">[client.admin]</div><div class="line">key = AQDL7fdZWaQkIBAAsFhvFVQYqSeM/FVSY6o8TQ==</div><div class="line"># 访问集群成功</div><div class="line">[root@node3 ceph]# ceph -s</div><div class="line">  cluster:</div><div class="line">    id:     99480db2-f92f-481f-b958-c03c261918c6</div><div class="line">    health: HEALTH_WARN</div><div class="line">    ...</div></pre></td></tr></table></figure><p>出现了令人惊奇的一幕，就是上面通过<code>ceph auth</code>获取<code>OSD</code>的<code>keyring</code>可以正常获取，而获取<code>client.admin.keyring</code>却要加上<code>monitor.keyring</code>，原因可以从报错信息看出，<code>ceph auth</code>需要以客户端连接集群为前提。</p><p>结论：</p><blockquote><p><code>Client</code>访问集群和<code>OSD</code>一样，需要正确的<code>keyring</code>与存在<code>Monitor</code>数据库中对应的<code>keyring</code>相匹配，并且当<code>client.admin.keyring</code><br>不正确时，通过<code>ceph auth</code>读取<code>keyring</code>的时候需要加上<code>monitor keyring</code>的选项</p></blockquote><h2 id="Mon-Caps"><a href="#Mon-Caps" class="headerlink" title="Mon Caps"></a>Mon Caps</h2><h3 id="r-权限"><a href="#r-权限" class="headerlink" title="r 权限"></a>r 权限</h3><p><code>Monior</code>的<code>r</code>权限就是拥有读权限，对应的读权限都有哪些操作？在这里的读权限其实就是拥有读取<code>Monitor</code>数据库中信息的权限，<code>MON</code>作为集群的状态维护者，其数据库(<code>/var/lib/ceph/mon/ceph-$hostname/store.db</code>)内保存着集群这一系列状态图(<code>Cluster Map</code>)，这些<code>Map</code>包含但不限于：</p><ul><li><code>CRUSH Map</code></li><li><code>OSD Map</code></li><li><code>MON Map</code></li><li><code>MDS Map</code></li><li><code>PG Map</code></li></ul><p>所以接下来我们可以创建一个新的只拥有读权限的用户，进行相关操作验证读权限具体拥有哪些权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">ceph auth get-or-create client.mon_r mon &apos;allow r&apos; &gt;&gt; /root/key</div><div class="line">[root@node3 ceph]# ceph auth get client.mon_r</div><div class="line">exported keyring for client.mon_r</div><div class="line">[client.mon_r]</div><div class="line">key = AQABvRxaBS6BBhAAz9uwjYCT4xKavJhobIK3ig==</div><div class="line">caps mon = &quot;allow r&quot;</div><div class="line"></div><div class="line">ceph --name client.mon_r --keyring /root/key -s      // ok</div><div class="line"></div><div class="line">ceph --name client.mon_r --keyring /root/key osd crush dump     // ok</div><div class="line">ceph --name client.mon_r --keyring /root/key osd getcrushmap -o crushmap.map        // ok</div><div class="line"></div><div class="line">ceph --name client.mon_r --keyring /root/key osd dump       // ok</div><div class="line">ceph --name client.mon_r --keyring /root/key osd tree       // ok</div><div class="line">ceph --name client.mon_r --keyring /root/key osd stat       // ok</div><div class="line"></div><div class="line">ceph --name client.mon_r --keyring /root/key pg dump        // ok</div><div class="line">ceph --name client.mon_r --keyring /root/key pg stat        // ok</div></pre></td></tr></table></figure><p>尝试了下两个写操作，都显示报错权限拒绝</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@node3 ceph]# rados --name client.mon_r --keyring /root/key -p testpool put crush crushmap.map</div><div class="line">error putting testpool/crush: (1) Operation not permitted</div><div class="line"></div><div class="line">[root@node3 ceph]# ceph --name client.mon_r --keyring /root/key osd out osd.0</div><div class="line">Error EACCES: access denied</div></pre></td></tr></table></figure><p><strong>注意：</strong></p><p>虽然上面有<code>osd</code>和<code>pg</code>等信息，但是这些都隶属于<code>crush map</code>的范畴中，所以这些状态数据都是从<code>Monitor</code>获取的</p><p><strong>结论：</strong></p><blockquote><p><code>Monitor</code>的读权限对应的是从<code>Monitor</code>数据库获取一系列的<code>Map</code>信息，具体的上面也都讲的很详细了，并且该权限只能读取状态信息，不能获取具体数据信息，且不能进行<code>OSD</code>等守护进程写操作</p></blockquote><h3 id="w-权限"><a href="#w-权限" class="headerlink" title="w 权限"></a>w 权限</h3><p><code>w</code>权限必须配合<code>r</code>权限才会有效果，否则，单独<code>w</code>权限执行指令时，是会一直<code>access denied</code>的。所以我们在测试<code>w</code>权限时，需要附加上<code>r</code>权限才行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ceph auth get-or-create client.mon_rw mon &apos;allow rw&apos; &gt;&gt; /root/key</div></pre></td></tr></table></figure><p>而<code>w</code>权限就可以做一些对组件的非读操作了，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># 踢出OSD</div><div class="line">ceph osd out</div><div class="line"># 删除OSD</div><div class="line">ceph osd rm </div><div class="line"># 修复PG</div><div class="line">ceph pg repair</div><div class="line"># 替换CRUSH</div><div class="line">ceph osd setcrushmap</div><div class="line"># 删除MON</div><div class="line">ceph mon rm</div><div class="line">...</div><div class="line"># 还有很多操作，就不一一赘述</div></pre></td></tr></table></figure><p><strong>结论：</strong></p><blockquote><p><code>Mon</code>的<code>r</code>权限可以读取集群各个组件的状态，但是不能修改状态，而<code>w</code>权限是可以做到的</p></blockquote><p><strong>注意：</strong></p><blockquote><p>这里的<code>w</code>权限能做到的写权限也只是修改组件的状态，但是并不包括对集群对象的读写权限，因为这些组件状态信息是存在<code>Mon</code>，而对象信息是存在<code>OSD</code>里面的，而这里的<code>w</code>权限也只是<code>Mon</code>的写权限，所以也很好理解了。</p></blockquote><h3 id="x-权限"><a href="#x-权限" class="headerlink" title="x 权限"></a>x 权限</h3><p><code>MON</code>的<code>x</code>权限很局限，因为这个权限仅仅和<code>auth</code>相关，比如<code>ceph auth list</code>，<code>ceph auth get</code> 之类的指令，和<code>w</code>权限类似，<code>x</code>权限也需要<code>r</code>权限组合在一起才能有效力：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"># 用上面创建拥有rw权限的用户访问auth list后auth报错</div><div class="line">[root@node3 ~]# ceph --name client.mon_rw --keyring /root/key auth list</div><div class="line">2017-11-28 21:28:10.620537 7f0d15967700  0 librados: client.mon_rw authentication error (22) Invalid argument</div><div class="line">InvalidArgumentError does not take keyword arguments</div><div class="line"># 创建rw权限的用户访问auth list成功</div><div class="line">[root@node3 ~]# ceph --name client.mon_rx --keyring /root/key auth list</div><div class="line">installed auth entries:</div><div class="line"></div><div class="line">osd.0</div><div class="line">key: AQDaTgBav2MgDBAALE1GEEfbQN73xh8V7ISvFA==</div><div class="line">caps: [mgr] allow profile osd</div><div class="line">caps: [mon] allow profile osd</div><div class="line">caps: [osd] allow *</div><div class="line">...</div><div class="line">...</div></pre></td></tr></table></figure><p>这边需要注意的是徐小胖的原文应该是笔误，他是用的<code>client.mon.rw</code>访问的，所以说实践可以发现很多光看发现不了的东西</p><p><strong>结论：</strong></p><blockquote><p><code>x</code>权限也需要和<code>r</code>权限搭配才有效果，该权限只能处理与<code>auth</code>相关的操作</p></blockquote><h3 id="权限"><a href="#权限" class="headerlink" title="* 权限"></a>* 权限</h3><p>这没什么好说的，猜也能猜到了，就是拥有<code>rwx</code>所有权限</p><h2 id="OSD-Caps"><a href="#OSD-Caps" class="headerlink" title="OSD Caps"></a>OSD Caps</h2><p>这一章需要研究一波再发出来</p><h2 id="丢失所有秘钥的再恢复"><a href="#丢失所有秘钥的再恢复" class="headerlink" title="丢失所有秘钥的再恢复"></a>丢失所有秘钥的再恢复</h2><p>如果所有秘钥全部删除，是否真的能恢复？所有秘钥包括</p><ul><li><code>MON</code> ： <code>/var/lib/ceph/mon/ceph-$hostname/keyring</code></li><li><code>OSD</code> ： <code>/var/lib/ceph/osd/ceph-$hostname/keyring</code></li><li><code>Client</code> ：<code>/etc/ceph/ceph.client.admin.keyring</code></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"># 删除 mon keyring</div><div class="line">[root@node1 ceph-node1]# mv keyring /root/</div><div class="line"># 删除 ceph.conf</div><div class="line">[root@node1 ceph-node1]# mv /etc/ceph/ceph.conf /root/</div><div class="line"># 删除 client.admin.keyring</div><div class="line">[root@node1 ceph-node1]# mv /etc/ceph/ceph.client.admin.keyring /root</div><div class="line"># 尝试访问集群报错</div><div class="line">[root@node1 ceph-node1]# ceph -s</div><div class="line">2017-11-29 23:57:14.195467 7f25dc4cc700 -1 Errors while parsing config file!</div><div class="line">2017-11-29 23:57:14.195571 7f25dc4cc700 -1 parse_file: cannot open /etc/ceph/ceph.conf: (2) No such file or directory</div><div class="line">2017-11-29 23:57:14.195579 7f25dc4cc700 -1 parse_file: cannot open ~/.ceph/ceph.conf: (2) No such file or directory</div><div class="line">2017-11-29 23:57:14.195580 7f25dc4cc700 -1 parse_file: cannot open ceph.conf: (2) No such file or directory</div><div class="line">Error initializing cluster client: ObjectNotFound(&apos;error calling conf_read_file&apos;,)</div><div class="line"># 尝试获取auth list报错</div><div class="line">[root@node1 ceph-node1]# ceph auth list</div><div class="line">2017-11-29 23:57:27.037435 7f162c5a7700 -1 Errors while parsing config file!</div><div class="line">2017-11-29 23:57:27.037450 7f162c5a7700 -1 parse_file: cannot open /etc/ceph/ceph.conf: (2) No such file or directory</div><div class="line">2017-11-29 23:57:27.037452 7f162c5a7700 -1 parse_file: cannot open ~/.ceph/ceph.conf: (2) No such file or directory</div><div class="line">2017-11-29 23:57:27.037453 7f162c5a7700 -1 parse_file: cannot open ceph.conf: (2) No such file or directory</div><div class="line">Error initializing cluster client: ObjectNotFound(&apos;error calling conf_read_file&apos;,)</div></pre></td></tr></table></figure><p>ok，下面开始修复：</p><h3 id="伪造-Mon-keyring"><a href="#伪造-Mon-keyring" class="headerlink" title="伪造 Mon keyring"></a>伪造 Mon keyring</h3><p>在<code>ceph</code>中除了<code>mon.</code>用户以外的的账户密码都保存在<code>Mon</code>的数据库<code>leveldb</code>中，但是<code>mon.</code> 用户的信息并没有保存在数据库里，而是在<code>MON</code>启动时读取<code>Mon</code>目录下的<code>keyring</code> 文件得到的，这也是我们之前验证后得到的结论。所以，我们可以随便伪造一个<code>keyring</code>，放到<code>Mon</code> 目录下去。然后同步到各个<code>Mon</code>节点，然后重启三个<code>Mon</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[root@node1 ceph-node1]# cd /var/lib/ceph/mon/ceph-node1/</div><div class="line">[root@node1 ceph-node1]# ls</div><div class="line">done  kv_backend  store.db  systemd</div><div class="line">[root@node1 ceph-node1]# vim keyring</div><div class="line"># 伪造 keyring，可以看到里面还有tony的字样，可以看出明显是伪造的</div><div class="line">[root@node1 ceph-node1]# cat keyring </div><div class="line">[mon.]</div><div class="line">key = AQCtonyZAAAAABAAQOysx+Yxbno/2N8W1huZFA==</div><div class="line">caps mon = &quot;allow *&quot;</div><div class="line"># 重启 mon</div><div class="line">[root@node1 ceph-node1]# service ceph-mon@node1 restart</div><div class="line">Redirecting to /bin/systemctl restart  ceph-mon@node1.service</div></pre></td></tr></table></figure><p>可以看到效果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># monitor log显示mon.node1@0初始化成功，并被选举成了monitor leader</div><div class="line">2017-11-30 00:15:04.042157 7f8c4e28a700  0 log_channel(cluster) log [INF] : mon.node1 calling new monitor election</div><div class="line">2017-11-30 00:15:04.042299 7f8c4e28a700  1 mon.node1@0(electing).elector(934) init, last seen epoch 934</div><div class="line">2017-11-30 00:15:04.048498 7f8c4e28a700  0 log_channel(cluster) log [INF] : mon.node1 calling new monitor election</div><div class="line">2017-11-30 00:15:04.048605 7f8c4e28a700  1 mon.node1@0(electing).elector(937) init, last seen epoch 937, mid-election, bumping</div><div class="line">2017-11-30 00:15:04.078454 7f8c4e28a700  0 log_channel(cluster) log [INF] : mon.node1@0 won leader election with quorum 0,1,2</div></pre></td></tr></table></figure><p><strong>注意（很重要）：</strong></p><blockquote><p>虽然说<code>mon</code>在启动的时候读取对应的<code>keyring</code>，不在乎内容的正确性，但是不代表这个<code>keyring</code>可以胡乱修改。也就是说这个<code>keyring</code>是要<strong>符合某种规范和格式的</strong>，在实践过程我发现<code>keyring</code>前三位必须为大写的<code>AQC</code>，当然还有其他的格式要求，比如结尾是否必须要是<code>==</code>？长度是否是固定的？这个格式要求可能很多，我没有时间一个一个手动无脑验证，这个可以日后查看源码了解实现思路，有兴趣的童鞋可以试试，说不定可以发现很有趣的现象。当然说了这么多是否意味着很难伪造呢？这个我们也不必担心，最好的做法是从别的集群的<code>Mon keyring</code>拷贝一份过来就可以了，自己胡乱伪造启动会报错如下：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">2017-11-29 23:49:50.134137 7fcab3e23700 -1 cephx: cephx_build_service_ticket_blob failed with error invalid key</div><div class="line">2017-11-29 23:49:50.134140 7fcab3e23700  0 mon.node1@0(probing) e1 ms_get_authorizer failed to build service ticket</div><div class="line">2017-11-29 23:49:50.134393 7fcab3e23700  0 -- 192.168.1.58:6789/0 &gt;&gt; 192.168.1.61:6789/0 conn(0x7fcacd15d800 :-1 s=STATE_CONNECTING_WAIT_CONNECT_REPLY_AUTH pgs=0 cs=0 l=0).handle_connect_reply connect got BADAUTHORIZER</div></pre></td></tr></table></figure><p>###　还原 ceph.conf</p><p>没有<code>/etc/ceph/ceph.conf</code>这个文件，我们是没法执行<code>ceph</code>相关指令的，所以我们需要尽可能的还原它。首先<code>fsid</code>可以通过去任意<code>osd</code>目录（<code>/var/lib/ceph/osd/ceph-$num/</code>）读取<code>ceph-fsid</code>文件获得，然后<code>mon_initial_members</code>和<code>mon_host</code>代表着集群每个节点的<code>hostname</code>和<code>ip</code>，这些都是我们知道的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"># 还原 ceph.conf</div><div class="line">[root@node1 ceph-node1]# cat /var/lib/ceph/osd/ceph-0/ceph_fsid </div><div class="line">99480db2-f92f-481f-b958-c03c261918c6</div><div class="line">[root@node1 ceph-node1]# vim /etc/ceph/ceph.conf</div><div class="line">[root@node1 ceph-node1]# cat /etc/ceph/ceph.conf</div><div class="line">[global]</div><div class="line">fsid = 99480db2-f92f-481f-b958-c03c261918c6</div><div class="line">mon_initial_members = node1, node2, node3</div><div class="line">mon_host = 192.168.1.58,192.168.1.61,192.168.1.62</div><div class="line">auth_cluster_required = cephx</div><div class="line">auth_service_required = cephx</div><div class="line">auth_client_required = cephx</div><div class="line"></div><div class="line">public network = 192.168.1.0/24</div><div class="line"></div><div class="line"># 通过 mon keyring 访问集群状态成功</div><div class="line">[root@node1 ceph-node1]# ceph -s --name mon. --keyring /var/lib/ceph/mon/ceph-node1/keyring</div><div class="line">  cluster:</div><div class="line">    id:     99480db2-f92f-481f-b958-c03c261918c6</div><div class="line">    health: HEALTH_OK</div><div class="line"> </div><div class="line">  services:</div><div class="line">    mon: 3 daemons, quorum node1,node2,node3</div><div class="line">    mgr: node1_mgr(active)</div><div class="line">    osd: 6 osds: 6 up, 6 in</div></pre></td></tr></table></figure><h3 id="恢复-ceph-client-keyring"><a href="#恢复-ceph-client-keyring" class="headerlink" title="恢复 ceph.client.keyring"></a>恢复 ceph.client.keyring</h3><p>有了<code>Mon keyring</code>，并且可以执行<code>ceph</code>指令，那么我们就可以通过<code>ceph auth get</code>去<code>Monitor leveldb</code>获取任意<code>keyring</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"># 通过 Mon 获取 client.admin.keyring</div><div class="line">[root@node1 ceph-node1]# ceph --name mon. --keyring /var/lib/ceph/mon/ceph-node1/keyring auth get client.admin</div><div class="line">exported keyring for client.admin</div><div class="line">[client.admin]</div><div class="line">key = AQDL7fdZWaQkIBAAsFhvFVQYqSeM/FVSY6o8TQ==</div><div class="line">caps mds = &quot;allow *&quot;</div><div class="line">caps mgr = &quot;allow *&quot;</div><div class="line">caps mon = &quot;allow *&quot;</div><div class="line">caps osd = &quot;allow *&quot;</div><div class="line"># 创建 /etc/ceph/ceph.client.admin.keyring，并将上面内容更新到该文件</div><div class="line">[root@node1 ceph-node1]# vim /etc/ceph/ceph.client.admin.keyring</div><div class="line">[root@node1 ceph-node1]# cat /etc/ceph/ceph.client.admin.keyring</div><div class="line">[client.admin]</div><div class="line">key = AQDL7fdZWaQkIBAAsFhvFVQYqSeM/FVSY6o8TQ==</div><div class="line">caps mds = &quot;allow *&quot;</div><div class="line">caps mgr = &quot;allow *&quot;</div><div class="line">caps mon = &quot;allow *&quot;</div><div class="line">caps osd = &quot;allow *&quot;</div><div class="line"></div><div class="line"># 用默认 ceph -s 测试一下，发现可以正常访问了</div><div class="line"></div><div class="line">[root@node1 ceph-node1]# ceph -s</div><div class="line">  cluster:</div><div class="line">    id:     99480db2-f92f-481f-b958-c03c261918c6</div><div class="line">    health: HEALTH_OK</div><div class="line"> </div><div class="line">  services:</div><div class="line">    mon: 3 daemons, quorum node1,node2,node3</div><div class="line">    mgr: node1_mgr(active)</div><div class="line">    osd: 6 osds: 6 up, 6 in</div></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>首先感谢徐小胖给我提供了<code>cephx</code>方面的思路，希望日后多出好文，我也在不断地拜读这些优质文章。这篇文章花了我很长时间，大家从日志的时间可以看出来，跨度已经有好几天了，很多实践真的不是一蹴而就的，需要反复的尝试和思考才能得到最后的成功。<code>Ceph</code>还是要多动手，看别人文章是好事，但是记得要加以实践，否则再好的文章也只是想当然，作者说什么你就跟着他的思路走，你永远不知道别人一句简短的话语和结论的背后花了多少时间去推敲和实践，你看起来一条命令执行成功或者在某一步执行某个命令那也许是别人失败了无数次总结出来的。所以我们要自己实践去验证，除了可以验证原文的观点正确与否，往往可以发现一些其他有用的知识。</p><p>经历这次总结，收获满满，我对<code>cephx</code>的理解又上了一个层次。本文就<code>cephx</code>在不同组件中的角色扮演和依赖关系进行梳理，然后再对各组件的<code>cap</code>进行了研究，最后针对各个<code>keyring</code>的恢复给出了详细的指南和步骤。然后还剩两项任务没有完成，等有空进行完善！</p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/cephx-600x450.jpg&quot; alt=&quot;cephx&quot;&gt;&lt;/center&gt;

&lt;p&gt;本文就阅读完&lt;a href=&quot;http://www.xuxiaopang.com/2017/08/23/easy-ceph-CephX/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;徐小胖的大话Cephx&lt;/a&gt;后，针对一些猜测和疑惑进行了实战演练，对原文的一些说法和结论进行了验证，并进行了一系列的扩展的思考猜想和总结。最后收获满满，不仅对原文的一些结论进行了验证，也发现了其中的一些问题，更多的是自己动手后一些奇妙的场景和发现。&lt;/p&gt;
    
    </summary>
    
      <category term="tech" scheme="https://tony-yin.github.io/categories/tech/"/>
    
    
      <category term="Ceph" scheme="https://tony-yin.github.io/tags/Ceph/"/>
    
      <category term="Cephx" scheme="https://tony-yin.github.io/tags/Cephx/"/>
    
  </entry>
  
  <entry>
    <title>阅读感悟：《Ceph Cookbook》</title>
    <link href="https://tony-yin.github.io/2017/11/26/read-ceph-cookbook/"/>
    <id>https://tony-yin.github.io/2017/11/26/read-ceph-cookbook/</id>
    <published>2017-11-26T14:52:45.000Z</published>
    <updated>2017-11-26T15:55:54.593Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/cookbook-600x450.png" alt="ceph cookbook"></center><p>阅读周期：2017/10/15 ～ 2017/11/26<br>阅读人群：拥有<code>ceph</code>基础知识想进阶的同学<br>阅读评分：4.8</p><p>这本书和之前一本《ceph分布式存储学习指南》是同一个作者：卡兰.辛格。是<code>ceph</code>界最先出版的学习书籍了，对他表示崇高的敬意和感谢。这本书绝不是上一本书的复制品，我觉得我的运气很好，先阅读了上一本然后才看的这一本，没错，在我看来这本书是上一本的进阶版，内容更加饱满和细致。很多方面还是讲解的比较全面的，而不是笼统的说那些道理，基本上每个章节都可以让读者进行实战代码演练。这本书让我对<code>cookbook</code>系列的书籍有着很好的印象。</p><a id="more"></a><h2 id="第1章-Ceph介绍和其他"><a href="#第1章-Ceph介绍和其他" class="headerlink" title="第1章 Ceph介绍和其他"></a>第1章 Ceph介绍和其他</h2><p>第1章没什么好说的，就是传统的介绍和与其他存储做比较。然后第一章还把<code>ceph</code>的部署也插入了进来，估计是不想浪费过多的章节讲解这么基础的 东西吧，嗯，很棒。</p><h2 id="第2章-使用Ceph块存储"><a href="#第2章-使用Ceph块存储" class="headerlink" title="第2章 使用Ceph块存储"></a>第2章 使用Ceph块存储</h2><p>哇，我只想说讲的太全面了，第一本讲解的方式永远是三个存储方式放在一起介绍一下，而这本书是每一个存储方式分了一章。从讲解块设备的创建、映射、调整、快照、克隆到和<code>openstack</code>的集成，面面俱到，为了阐述<code>rbd</code>是<code>openstack</code>的最佳匹配，分别就<code>openstack</code>的<code>glance</code>、<code>cinder</code>和<code>nova</code>讲解了详细的对接挂载方式，过程是可以自己实操的。</p><h2 id="第3章-使用Ceph对象存储"><a href="#第3章-使用Ceph对象存储" class="headerlink" title="第3章 使用Ceph对象存储"></a>第3章 使用Ceph对象存储</h2><p>这一章除了讲解老一套的<code>rados</code>网关配置与<code>S3</code>和<code>Swift</code>对接之外，还讲了<code>rados</code>网关和<code>openstack keystone</code>的集成。最大的特色是讲解了<code>radosgw</code>多区域网关配置和测试，无限逼近线上大规模生产环境的场景。最后就<code>RGW</code>创建文件同步和共享服务进行了介绍，干货多多。</p><h2 id="第4章-使用Ceph文件系统"><a href="#第4章-使用Ceph文件系统" class="headerlink" title="第4章 使用Ceph文件系统"></a>第4章 使用Ceph文件系统</h2><p>借着<code>cephfs</code>介绍了<code>mds</code>一番，然后讲解了多种访问<code>cephfs</code>的方式，然后就是熟悉的将<code>cephfs</code>导出为<code>nfs</code>，这算是很常见的场景了，但是据我所知目前<code>ceph</code>版本的<code>cephfs</code>的性能堪忧，以至于用的比较多的还是<code>rbd</code>，希望<code>ceph</code>可以在之后的版本中将<code>cephfs</code>做的越开越好。最后介绍了<code>ceph-dokan</code>的<code>cephfs</code>的<code>windows</code>客户端，很牛逼，还在持续迭代中。还介绍了如何使得<code>cephfs</code>替换<code>hdfs</code>，这个我之前在<code>ceph</code>线下沙龙南京站听那位中兴的工程师讲的<code>cephfs</code>和<code>hadoop</code>的恋爱史印象非常深刻，讲的蛮好的。</p><h2 id="第5章-用Calamari监控Ceph集群"><a href="#第5章-用Calamari监控Ceph集群" class="headerlink" title="第5章 用Calamari监控Ceph集群"></a>第5章 用Calamari监控Ceph集群</h2><p>先科普了一下各大监控命令和手段，然后介绍了<code>Calamari</code>这个工具的编译和搭建，这个工具主要就是一个<code>dashboard</code>，并不是那种能在<code>UI</code>上操作和管理集群的工具，并且已经很久没再更新了，用于生产环境的请注意，自己玩玩倒是还可以。</p><h2 id="第6章-操作和管理Ceph集群"><a href="#第6章-操作和管理Ceph集群" class="headerlink" title="第6章 操作和管理Ceph集群"></a>第6章 操作和管理Ceph集群</h2><p>先是介绍了两种方式管理各种守护进程和服务。然后讲解了横向扩展和纵向扩展。最后介绍了集群的升级。</p><h2 id="第7章-深入Ceph"><a href="#第7章-深入Ceph" class="headerlink" title="第7章 深入Ceph"></a>第7章 深入Ceph</h2><p>这一章蛮重要的，首先讲解了<code>crush</code>的机制和算法，然后介绍了<code>ceph</code>的身份验证，也就是<code>cephx</code>，最后结合<code>crush</code>和<code>pg</code>创建了定制化的<code>osd</code>和<code>pool</code>。</p><h2 id="第8章-Ceph生产计划和性能优化"><a href="#第8章-Ceph生产计划和性能优化" class="headerlink" title="第8章 Ceph生产计划和性能优化"></a>第8章 Ceph生产计划和性能优化</h2><p>这本书在讲解这一部分明显要比上本书要全面的多，分别针对操作系统、<code>osd</code>、<code>filestore</code>、<code>cilent</code>等性能优化给出参数配置建议。然后介绍了纠删码的各种插件，配了结构图很好理解，最后还是缓存分层，做了测试，更能清楚了了解分层的原理。</p><h2 id="第9章-Ceph虚拟存储管理器（VSM）"><a href="#第9章-Ceph虚拟存储管理器（VSM）" class="headerlink" title="第9章 Ceph虚拟存储管理器（VSM）"></a>第9章 Ceph虚拟存储管理器（VSM）</h2><p>这个工具就要比上面提到的<code>calamari</code>之类的工具要强得多了，不仅有<code>dashboard</code>可以监控集群，还可以操作和管理集群，还有牛逼的是升级<code>ceph</code>方面，你也只需要修改配置要升级版本的网址，便可以实现自动升级，这是<code>intel</code>开发并提供开源的一款产品，值得去尝试一番。</p><h2 id="第10章"><a href="#第10章" class="headerlink" title="第10章"></a>第10章</h2><p>同样的基准测试，不一样的味道。这一章提供了<code>n</code>多种的方式。有<code>dd</code>，有<code>rados bench</code>，有<code>rados load-gen</code>，<code>rdb bench-write</code>和<code>fio</code>等等。从测试网络，池，块设备和模拟负载应有尽有，关键这些都是<code>ceph</code>自带的除了<code>fio</code>。然后介绍了<code>ceph daemon</code>和<code>ceph tell</code>两个高校操作手段，最后介绍了使用<code>Ansible</code>部署<code>Ceph</code>，它可以通过配置文件配置集群信息而搭建集群，也就是说不需要手动的一个一个创建了，这样就显得很高效了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>ceph</code>已经看完两本书了，按理来说不应该再是那种一无所知的小白了，我觉得我缺少的还是大量的实践，所以之后我会对着这两本书照着例子再把代码敲一遍加深印象，然后对<code>ceph</code>应该会有另一番理解吧。接下来的进阶路线应该是中兴出版的《ceph原理和源码分析》了把，这本今年才出版的书我已经入手了，看了第一章，总体觉得还是蛮深入的，大量的源码，需要一定的知识铺垫，正好之后我也有看<code>ceph</code>源码和提供贡献的想法，所以正好那这本书过渡一下，加油！</p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/cookbook-600x450.png&quot; alt=&quot;ceph cookbook&quot;&gt;&lt;/center&gt;

&lt;p&gt;阅读周期：2017/10/15 ～ 2017/11/26&lt;br&gt;阅读人群：拥有&lt;code&gt;ceph&lt;/code&gt;基础知识想进阶的同学&lt;br&gt;阅读评分：4.8&lt;/p&gt;
&lt;p&gt;这本书和之前一本《ceph分布式存储学习指南》是同一个作者：卡兰.辛格。是&lt;code&gt;ceph&lt;/code&gt;界最先出版的学习书籍了，对他表示崇高的敬意和感谢。这本书绝不是上一本书的复制品，我觉得我的运气很好，先阅读了上一本然后才看的这一本，没错，在我看来这本书是上一本的进阶版，内容更加饱满和细致。很多方面还是讲解的比较全面的，而不是笼统的说那些道理，基本上每个章节都可以让读者进行实战代码演练。这本书让我对&lt;code&gt;cookbook&lt;/code&gt;系列的书籍有着很好的印象。&lt;/p&gt;
    
    </summary>
    
      <category term="read" scheme="https://tony-yin.github.io/categories/read/"/>
    
    
      <category term="Ceph" scheme="https://tony-yin.github.io/tags/Ceph/"/>
    
      <category term="Read" scheme="https://tony-yin.github.io/tags/Read/"/>
    
  </entry>
  
  <entry>
    <title>阅读感悟：《Ceph分布式存储学习指南》</title>
    <link href="https://tony-yin.github.io/2017/11/26/read-ceph-guide/"/>
    <id>https://tony-yin.github.io/2017/11/26/read-ceph-guide/</id>
    <published>2017-11-26T14:50:08.000Z</published>
    <updated>2017-11-26T15:55:04.969Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/book-rocket-600x450.png" alt="ceph guide"></center><p>阅读周期：2017/9/5 ～ 2017/10/7<br>阅读人群：入门ceph的研发或者运维<br>阅读评分：4.7</p><p>这本书不到两百页，但是也讲解了<code>ceph</code>的方方面面。对于入门<code>ceph</code>来说，看官网文档是必要的，但是很多时候官方文档太基础，太零散了，而这样一本书籍就可以弥补这样的缺陷，它把所有组件进行总结和概括，并且进行了实战例子的演示。</p><a id="more"></a><h2 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h2><ul><li>第1章 Ceph存储介绍</li><li>第2章 Ceph实战部署</li><li>第3章 Ceph架构和组件</li><li>第4章 Ceph内部构件</li><li>第5章 Ceph部署</li><li>第6章 Ceph存储配置</li><li>第7章 Ceph操作及管理</li><li>第8章 监控Ceph集群</li><li>第9章 Ceph与Openstack的集成</li><li>第10章 Ceph性能调优和基准测试</li></ul><h2 id="具体分析"><a href="#具体分析" class="headerlink" title="具体分析"></a>具体分析</h2><h3 id="第1章"><a href="#第1章" class="headerlink" title="第1章"></a>第1章</h3><p>第1章主要介绍了一下<code>ceph</code>的特点和历史发展，通过与<code>raid</code>，其他存储相比较得出自身的优势和特色，然后着眼于未来的一些设计和解决方案。最后针对<code>ceph</code>三大存储接口：块存储、文件系统存储和对象存储进行了介绍。</p><h3 id="第2章"><a href="#第2章" class="headerlink" title="第2章"></a>第2章</h3><p>这一章其实就是利用<code>ceph-deploy</code>手动搭建集群的一个演示，后续章节还会有相应的补充</p><h3 id="第3章"><a href="#第3章" class="headerlink" title="第3章"></a>第3章</h3><p>第3章重点讲解了<code>ceph</code>的几大组件，<code>rados</code>存储网关，<code>osd</code> 讲的比较多，也是应该的，毕竟是存储的核心，首先对比了目前主流三个文件系统的优劣，然后对日志进行了科普，顺带讲解了一下不推荐在<code>ceph</code>集群中采用<code>raid</code>的原因。之后就是一些<code>osd</code>，<code>monitor</code>和<code>mds</code>的基础命令了。</p><h3 id="第4章"><a href="#第4章" class="headerlink" title="第4章"></a>第4章</h3><p>如果说上一章主要讲的是<code>osd</code>，<code>monitor</code>，<code>mds</code>的话，那么这一章很符合标题内部构件，对应讲解的是<code>pg</code>，<code>crush</code>，对象和<code>pool</code>。<code>pg</code>是对象的载体，<code>pg</code>的状态往往决定着集群的状态，徐小胖有一篇文章叫大话<code>pg</code>讲的挺简单明了的，其实写一个数据然后查看一下存储目录结构就知道七七八八了。<code>ceph</code>池是存储对象的逻辑分区，用户可以根据自己的需求定制池的类型和规则。比如副本池还是<code>EC</code>池，也可以为<code>pool</code>定制<code>crush rule</code>。</p><h3 id="第5章"><a href="#第5章" class="headerlink" title="第5章"></a>第5章</h3><p>这一章也是部署，跟第2章不同的是这一章不用<code>ceph-deploy</code>工具而采用了手工部署的方式。这样做可能要做的事情多一点，繁琐一些，但是会更灵活一些，因为<code>ceph-deploy</code>这种自动化的工具往往存在局限性，比较适用于测试环境，并不适用于生产环境。往往生产环境需要做很多的定制化的改变。最后还讲解了一些如何进行<code>ceph</code>升级。</p><h3 id="第6章"><a href="#第6章" class="headerlink" title="第6章"></a>第6章</h3><p>这一章干货满满，分别就块设备，文件系统和对象存储进行了讲解，还是挺全面的，建议一边看书一边实践，这些命令还是要多用，否则很快也会忘记。目前<code>rbd</code>还是<code>ceph</code>最稳定的存储方式，相比<code>cephfs</code>而言他的性能、稳定和快照复制等功能都做的很全面了。<code>cephfs</code>虽然越来越被更多的应用内嵌，但是还是不能应用与生产环境之上。最后介绍了一下<code>rados</code>网关配置分别和<code>s3</code>，<code>swift</code>对接的流程。</p><h3 id="第7章"><a href="#第7章" class="headerlink" title="第7章"></a>第7章</h3><p>这一章主要介绍了如何运行和管理集群里面的守护进程和相关服务。然后就集群扩容和所容等扩展操作进行了讲解。最后重点讲解了如何管理<code>crushmap</code>，通过配置确定集群存储的结构，定制<code>pool</code>的规则等等。</p><h3 id="第8章"><a href="#第8章" class="headerlink" title="第8章"></a>第8章</h3><p>这一章对应标题讲解了一系列的监控命令，有<code>osd</code>，有<code>pg</code>，还有<code>mon</code>等等。最后引入了一些开源的监控软件，比如<code>kraken</code>，<code>ceph-dash</code>和<code>Calamari</code>，讲的比较简洁，想要具体了解还需要自己动手去搭建，不过貌似有一些已经长时间不维护了，建议动手前看一下。</p><h3 id="第9章"><a href="#第9章" class="headerlink" title="第9章"></a>第9章</h3><p>这一章主要讲<code>ceph</code>和<code>openstack</code>的完美集成，不过讲的也很简洁，其实就是了解歌大概情况，我觉得这对刚入门的小白来说挺好的，讲得太细也没什么用，反而云里雾里的，其实这本书对我最大的帮助就是了解了存储和<code>ceph</code>大概是个什么情况，然后知道了一些命令的用法和应用场景。第一遍熟悉一下就可以了，然后之后可以在深入，否则第一次接触就搞<code>openstack</code>这种高级玩意估计吃不消呢。</p><h3 id="第10章"><a href="#第10章" class="headerlink" title="第10章"></a>第10章</h3><p>最后一章先分别对软件和硬件的性能调优提出了建议，这个东西我觉得还是得到生产环境中不断尝试，虚拟机的话没有任何参考建议。然后集群优化分别介绍了<code>osd</code>，<code>filestore</code>和客户端的相关参数，这个我们可以熟悉一下，自己没事动手改改，看看效果。然后针对<code>ec</code>和缓存分层进行了一些介绍，也是局限于基本够用的层面上。最后介绍了<code>rados bench</code>这个基准测试工具。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这本书专为入门而生，就是在官网文档的基础之上进行规整和总结，如果看不下去官网文档的可以尝试这个，书很薄，很快就可以看完了，看完大概就对<code>ceph</code>没那么陌生了，还是一个比较不错的入门书籍。如果已经了解<code>ceph</code>一段时间的朋友我就不是很推荐了。</p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/book-rocket-600x450.png&quot; alt=&quot;ceph guide&quot;&gt;&lt;/center&gt;

&lt;p&gt;阅读周期：2017/9/5 ～ 2017/10/7&lt;br&gt;阅读人群：入门ceph的研发或者运维&lt;br&gt;阅读评分：4.7&lt;/p&gt;
&lt;p&gt;这本书不到两百页，但是也讲解了&lt;code&gt;ceph&lt;/code&gt;的方方面面。对于入门&lt;code&gt;ceph&lt;/code&gt;来说，看官网文档是必要的，但是很多时候官方文档太基础，太零散了，而这样一本书籍就可以弥补这样的缺陷，它把所有组件进行总结和概括，并且进行了实战例子的演示。&lt;/p&gt;
    
    </summary>
    
      <category term="read" scheme="https://tony-yin.github.io/categories/read/"/>
    
    
      <category term="Ceph" scheme="https://tony-yin.github.io/tags/Ceph/"/>
    
      <category term="Read" scheme="https://tony-yin.github.io/tags/Read/"/>
    
  </entry>
  
  <entry>
    <title>阅读感悟：《Python编程快速上手---让繁琐工作自动化》</title>
    <link href="https://tony-yin.github.io/2017/11/26/read-python-automation/"/>
    <id>https://tony-yin.github.io/2017/11/26/read-python-automation/</id>
    <published>2017-11-26T14:45:48.000Z</published>
    <updated>2017-11-26T15:54:05.204Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/python-automation-600x450.jpg" alt="python automation"></center><blockquote><p>阅读感悟这个系列是针对每次阅读一本书后，先对全本书内容进行整体的总结和评价，然后针对每一章节进行具体分析，分享一下自己从中的收获，这样不但可以在看完整本书后对全书有个完整的加深回顾，还可以对没有阅读过本书的人提供经验和建议或者跟同样阅读过的伙伴相互交流，交换感悟和经验。</p></blockquote><ul><li>阅读周期：2017/7/15 ～ 2017/10/7</li><li>阅读人群：无语言基础的小白，有其他语言基础让入门<code>python</code>的，熟练<code>python</code>想深入学习的请勿下手</li><li>阅读评分：4.7</li></ul><a id="more"></a><p>大家都知道其实一本书可能并不是很贵，一般都是几十元，就算是本烂书对大家的经济损失来说其实并不是很严重，最关键的就是时间了，在这个压力山大和节奏飞快的时代，时间无疑是最宝贵的，所以很多时候我买书之前都会很仔细的看下评论，我个人是比较喜欢买书的，一般会选择在亚马逊上面购买，对比京东而言的话我觉得他的优惠策略更加直接，不需要抢什么券什么的，还有他的物流非常快，最多隔天就到了，包装也很精致，很少出现盗版书这种情况，最后也是最重要的是相比京东而言亚马逊书籍评论更加贴切一些，往往京东一本书下面会有上千条评论，你很少会看到负面的评价，而亚马逊就不一样了，一般评论的都是骨灰级读者了，一旦评论都是很认真并且很全面的，所以也很难得在亚马逊上面看到全五星的书籍。</p><p>这本书是我入门<code>python</code>的第一本书，在此之前我有<code>C</code>，<code>Java</code>和<code>PHP</code>的语言经验。无论是在阅读这本书的过程中还是看完了之后，我都有一种庆幸感，那就是我当初选择这本书真的没错。在阅读前三章的时候，我一度觉得这本书太浅了，这主要可能因为我有其他语言基础，而这本书面对的读者不仅仅有语言基础的，而他这么做对那种小白来说就非常<code>nice</code>了。</p><p>这本书给我最深的印象可以概括为四个字：深入浅出。就是在讲的很细致的同时，同时也会配有一些深入的内容。全本书的最大特色莫过于插图和<code>demo</code>了。一般的书一般是以代码围绕着讲解，而这本书的话往往是通过一些小项目或者小例子讲解一些概念和用法。第一部分主要讲解了语言的基础概念和<code>python</code>重要的数据结构：列表和字典。第二部分主要讲解了自动化知识，就比较深入了，具体比如正则表达式、对文件的操作、调试技巧、获取<code>web</code>信息、处理<code>excel</code>文件、处理<code>pdf</code>和<code>word</code>文档、处理<code>CSV</code>文件和<code>JSON</code>数据、计划任务、邮件和短信、操作图像和操作鼠标和键盘。掌握了列表、字典和字符串这些数据结构就可以进行基础的<code>python</code>编程了，然后学习了正则表达式和文件操作后，就可以很轻松了写一些自动化脚本了。从<code>web</code>抓取信息这一章是专门为喜爱爬虫的小伙伴准备的，提供了很多有用的工具和手段。之后还有对各种类型文件的操作，操作图像这一章我也很喜欢，准备之后做一个小项目，因为我个人对好看的图片很有兴趣。</p><h2 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h2><ul><li>第一部分 Python编程基础<ul><li>第1章 python基础</li><li>第2章 控制流</li><li>第3章 函数</li><li>第4章 列表</li><li>第5章 字典和结构化数据</li><li>第6章 字符串操作</li></ul></li><li>第二部分<ul><li>第7章 模式匹配与正则表达式</li><li>第8章 读写文件</li><li>第9章 组织文件</li><li>第10章 调试</li><li>第11章 从Web抓取信息</li><li>第12章 处理Excel电子表格</li><li>第13章 处理PDF和Word文档</li><li>第14章 处理CSV文件和JSON数据</li><li>第15章 保持时间、计划任务和启动程序</li><li>第16章 发送电子邮件和短信</li><li>第17章 操作图像</li><li>第18章 用GUI自动化控制键盘和鼠标</li></ul></li></ul><h2 id="章节分析"><a href="#章节分析" class="headerlink" title="章节分析"></a>章节分析</h2><h3 id="第1章、第2章和第3章"><a href="#第1章、第2章和第3章" class="headerlink" title="第1章、第2章和第3章"></a>第1章、第2章和第3章</h3><p>这3章对我来说没什么好说的，就是一些语言基础，比如字符串拼接啊，控制流啊，函数什么的，对没有语言基础的小伙伴来说非常的贴心和容易理解，老司机的话可以快速阅读或者略过。</p><h3 id="第4章"><a href="#第4章" class="headerlink" title="第4章"></a>第4章</h3><p>列表是<code>python</code>比较有特色的数据结构了，操作起来非常的方便。这一章分别阐述了获取列表、操作列表（merge、copy、delete）、列表循环和多重赋值技巧。然后就是一些深入的操作技巧了，比如排序、插入和删除。最后引入了字符串和元组和列表加以比较，讲解了可变类型、转换类型、传递引用和深拷贝等，总的来说还是很实用。</p><h3 id="第5章、第6章"><a href="#第5章、第6章" class="headerlink" title="第5章、第6章"></a>第5章、第6章</h3><p>首先围绕字典讲解了一些基本的<code>API</code>，然后通过很好的棋盘建模模拟了字典的数据结构，很形象。字符串的话也差不多一样。</p><h3 id="第7章"><a href="#第7章" class="headerlink" title="第7章"></a>第7章</h3><p>相比其他语言的正则来说，我觉得<code>python</code>的正则表达式无论是理解还是使用上面还算是比较简单的。先讲解了单个匹配和全局匹配，然后针对邮件，电话等常见场景给出了例子。</p><h3 id="第8章"><a href="#第8章" class="headerlink" title="第8章"></a>第8章</h3><p>先讲解了<code>os</code>模块很多有用的<code>API</code>，大多数都是跟文件和目录有关，然后讲解了文件的读写操作，其中提到了<code>shelve</code>模块，这个在需要确保文件保密的场景非常有用。最后通过一个小例子讲解了<code>pyperclip</code>模块如何进行剪切板操作。</p><h3 id="第9章"><a href="#第9章" class="headerlink" title="第9章"></a>第9章</h3><p>讲解了通过<code>shutil</code>模块复制文件和文件夹、移动、重命名、永久删除和安全删除。然后讲解了围绕<code>zipfile</code>模块相应的操作。</p><h3 id="第10章"><a href="#第10章" class="headerlink" title="第10章"></a>第10章</h3><p>断言给我的印象比较深，还有<code>python</code>自带的<code>IDLE</code>的调试器的使用，我本人平时基本上是在<code>linux</code>下<code>vim</code>工作，所以这个工具平时也用不到，以后可以在<code>windows</code>下尝试一下。</p><h3 id="第11章"><a href="#第11章" class="headerlink" title="第11章"></a>第11章</h3><p>这一章学习到了很多通过<code>python</code>取获取<code>web</code>信息的手段，这会在爬虫的时候很受用。比如通过<code>webbrowser</code>模块启动浏览器；通过<code>request</code>模块下载网页；通过<code>BeautifulSoup</code>模块解析<code>html</code>，这个模块非常强，简直和<code>js</code>操作<code>html</code>相媲美。</p><h3 id="第12章、第13章、第14章"><a href="#第12章、第13章、第14章" class="headerlink" title="第12章、第13章、第14章"></a>第12章、第13章、第14章</h3><p>这三章分别针对<code>excel</code>、<code>pdf</code>、<code>word</code>、<code>csv</code>和<code>json</code>类型的文件或数据格式进行操作。对<code>excel</code>的支持还蛮强的，但是<code>pdf</code>和<code>word</code>的话就或多或少可能有问题，这个就不赘述了，用到的时候再查就好了。</p><h3 id="第15章、第16章、第18章"><a href="#第15章、第16章、第18章" class="headerlink" title="第15章、第16章、第18章"></a>第15章、第16章、第18章</h3><p>这几章没什么好说的<br>第15章主要讲解了保持时间、计划任务和启动程序等功能<br>第16章主要讲解了消息通知，包括了邮件和短信接口<br>第18章主要讲解了如何通过<code>python</code>控制键盘和鼠标，其中比较有意思的就是控制键盘原生不存在的一些特殊字符</p><h3 id="第17章"><a href="#第17章" class="headerlink" title="第17章"></a>第17章</h3><p><code>python</code>操作图像还是蛮好用的，本章主要讲解了对图片的裁剪，旋转，改变像素等，后续我会做一个小项目，通过<code>python</code>对图片进行一些操作，顺便深入了解一下这部分的知识。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>第一篇阅读总结感觉写的并不是很好，篇幅虽然还算长，但是感觉内容并不是很饱满，很多地方略显啰嗦。想了一下，之后可以把每一章的具体分析放在平时，每阅读完一章节就可以进行总结了，然后读完全本书就进行一个整体总结就可以了，这样每一章的总结就更加细致了，就不用读完全本书的时候再去回忆，这样效率很低。最后我会在之后有空的情况下分别做一个<code>python</code>的爬虫项目和一个操作图像的项目。</p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/python-automation-600x450.jpg&quot; alt=&quot;python automation&quot;&gt;&lt;/center&gt;

&lt;blockquote&gt;
&lt;p&gt;阅读感悟这个系列是针对每次阅读一本书后，先对全本书内容进行整体的总结和评价，然后针对每一章节进行具体分析，分享一下自己从中的收获，这样不但可以在看完整本书后对全书有个完整的加深回顾，还可以对没有阅读过本书的人提供经验和建议或者跟同样阅读过的伙伴相互交流，交换感悟和经验。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;阅读周期：2017/7/15 ～ 2017/10/7&lt;/li&gt;
&lt;li&gt;阅读人群：无语言基础的小白，有其他语言基础让入门&lt;code&gt;python&lt;/code&gt;的，熟练&lt;code&gt;python&lt;/code&gt;想深入学习的请勿下手&lt;/li&gt;
&lt;li&gt;阅读评分：4.7&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="read" scheme="https://tony-yin.github.io/categories/read/"/>
    
    
      <category term="Read" scheme="https://tony-yin.github.io/tags/Read/"/>
    
      <category term="Python" scheme="https://tony-yin.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>博客主题 shadow</title>
    <link href="https://tony-yin.github.io/2017/11/19/hexo-theme-shadow/"/>
    <id>https://tony-yin.github.io/2017/11/19/hexo-theme-shadow/</id>
    <published>2017-11-19T14:45:52.000Z</published>
    <updated>2017-12-30T14:34:48.145Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/do_blog_600x450.png" alt="blog theme shadow"></center><p>使用了<a href="http://geeksblog.cc/" target="_blank" rel="external">black-blue</a>主题一段时间后，有些地方不符合我个人的审美和习惯，然后自己偶尔改了一些，久而久之还改了不少东西，为了方便存档和以后持续更新，就打造一个自己的专属主题：<a href="https://github.com/tony-yin/hexo-theme-shadow" target="_blank" rel="external">hexo-theme-shadow</a>，大家可以去<a href="http://www.tony-yin.top/" target="_blank" rel="external">我的博客</a>看下实际效果</p><p>如果大家有任何批评和建议，随时可以在<code>github</code>上面提出<code>PR</code>，要是觉得主题还不错的话，欢迎留下你的<code>star</code>哦 ^_^</p><a id="more"></a><p>具体如何配置主题和搭建博客这些基础通用的东西我就不讲了，这边我主要罗列一下我已经更新和以后可能要做的功能点</p><h2 id="已经更新的功能"><a href="#已经更新的功能" class="headerlink" title="已经更新的功能"></a>已经更新的功能</h2><ul><li>添加左侧栏<code>segmentfault</code>小图标</li><li>更新<code>requirejs</code>源为<code>https</code>，避免<code>https</code>网站引入<code>http</code>脚本时浏览器告警</li><li>更新<code>jquery</code>源为<code>https</code>，避免<code>https</code>网站引入<code>http</code>脚本时浏览器告警</li><li>更新<code>baidu</code>分享源到本地，避免<code>https</code>网站引入<code>http</code>脚本时浏览器告警</li><li>更新<code>markdown code</code>的风格，具体参见博客<ul><li>更改了全局的代码颜色样式</li><li>原来项目编号中的代码样式是白色的，很丑陋，也进行了相应的更新</li></ul></li><li>将头像从懒加载改为了直接加载，懒加载头像需要很长时间，用户体验很差</li><li>网站背景音乐支持</li><li>代码块样式修改，每个代码块上面有个蓝色的条条很不好看</li><li>三级、四级和五级标题样式修改</li><li>链接样式修改</li><li>畅言评论支持</li><li>打赏支持</li><li>书签样式修改</li><li>代码块样式修改</li><li>项目编号样式修改</li><li>表格样式修改</li></ul><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>具体使用教程请参考我主题的<code>github</code>地址，在下方有写</p><p>如果大家有什么建议或者问题，可以在<code>github</code>上面提<code>issue</code>或者<code>PR</code>，也可以通过邮箱联系到我</p><p><code>github</code>地址： <code>https://github.com/tony-yin/hexo-theme-shadow</code><br>邮箱地址： <code>1241484989@qq.com</code></p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/do_blog_600x450.png&quot; alt=&quot;blog theme shadow&quot;&gt;&lt;/center&gt;

&lt;p&gt;使用了&lt;a href=&quot;http://geeksblog.cc/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;black-blue&lt;/a&gt;主题一段时间后，有些地方不符合我个人的审美和习惯，然后自己偶尔改了一些，久而久之还改了不少东西，为了方便存档和以后持续更新，就打造一个自己的专属主题：&lt;a href=&quot;https://github.com/tony-yin/hexo-theme-shadow&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;hexo-theme-shadow&lt;/a&gt;，大家可以去&lt;a href=&quot;http://www.tony-yin.top/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;我的博客&lt;/a&gt;看下实际效果&lt;/p&gt;
&lt;p&gt;如果大家有任何批评和建议，随时可以在&lt;code&gt;github&lt;/code&gt;上面提出&lt;code&gt;PR&lt;/code&gt;，要是觉得主题还不错的话，欢迎留下你的&lt;code&gt;star&lt;/code&gt;哦 ^_^&lt;/p&gt;
    
    </summary>
    
      <category term="tech" scheme="https://tony-yin.github.io/categories/tech/"/>
    
    
      <category term="博客" scheme="https://tony-yin.github.io/tags/%E5%8D%9A%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>LVM动态扩展</title>
    <link href="https://tony-yin.github.io/2017/11/14/LVM-Space-Expansion/"/>
    <id>https://tony-yin.github.io/2017/11/14/LVM-Space-Expansion/</id>
    <published>2017-11-14T02:35:39.000Z</published>
    <updated>2017-11-22T01:38:24.571Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/work-for-love-600x450.png" alt="LVM Space Expansion"></center><p>在平时的开发工作中，经常会创建磁盘不足够大的虚拟机，然后往集群里面写一些数据导致磁盘满了。手动编辑虚拟机的磁盘大小是不会文件系统识别的，大多数同学只能无奈的重新装<code>OS</code>，这里我介绍一种基于<code>LVM</code>实现动态的方式。</p><a id="more"></a><h2 id="LVM了解"><a href="#LVM了解" class="headerlink" title="LVM了解"></a>LVM了解</h2><p><code>LVM</code>是逻辑盘卷管理（<code>LogicalVolumeManager</code>）的简称，它是<code>Linux</code>环境下对磁盘分区进行管理的一种机制，<code>LVM</code>是建立在硬盘和分区之上的一个逻辑层，来提高磁盘分区管理的灵活性。通过LVM系统管理员可以轻松管理磁盘分区，如：将若干个磁盘分区连接为一个整块的卷组（<code>volumegroup</code>），形成一个存储池。管理员可以在卷组上随意创建逻辑卷组（<code>logicalvolumes</code>），并进一步在逻辑卷组上创建文件系统。管理员通过<code>LVM</code>可以方便的调整存储卷组的大小，并且可以对磁盘存储按照组的方式进行命名、管理和分配。</p><h2 id="查看分区"><a href="#查看分区" class="headerlink" title="查看分区"></a>查看分区</h2><p>当前默认只有一个采用<code>lvm</code>的分区，一开始<code>sda</code>磁盘容量为<code>16G</code>，后来发现不够用了，编辑磁盘大小为<code>50G</code>，但是可以发现这<code>50G</code>并没有起到扩展分区容量的效果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[root@tony-play ~]# df -h</div><div class="line">Filesystem            Size  Used Avail Use% Mounted on</div><div class="line">/dev/mapper/vg_tonyplay-lv_root</div><div class="line">                       14G  3.4G  9.6G  26% /</div><div class="line">tmpfs                 1.9G   72K  1.9G   1% /dev/shm</div><div class="line">/dev/sda1             477M   42M  410M  10% /boot</div><div class="line"></div><div class="line">[root@tony-play ~]# lsblk</div><div class="line">NAME                           MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</div><div class="line">sr0                             11:0    1 1024M  0 rom  </div><div class="line">sda                              8:0    0   50G  0 disk </div><div class="line">├─sda1                           8:1    0  500M  0 part /boot</div><div class="line">└─sda2                           8:2    0 15.5G  0 part </div><div class="line">  ├─vg_tonyplay-lv_root (dm-0) 253:0    0 13.9G  0 lvm  /</div><div class="line">  └─vg_tonyplay-lv_swap (dm-1) 253:1    0  1.6G  0 lvm  [SWAP]</div></pre></td></tr></table></figure><h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h2><p>可以通过新增一块其他磁盘来扩容，我这边采取的是增大当前磁盘的容量实现扩容。</p><p>有时候因为系统设备处于繁忙状态，所以分区需要重启后才会生效。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">[root@tony-play ~]# fdisk /dev/sda</div><div class="line">WARNING: DOS-compatible mode is deprecated. It&apos;s strongly recommended to</div><div class="line">         switch off the mode (command &apos;c&apos;) and change display units to</div><div class="line">         sectors (command &apos;u&apos;).</div><div class="line">Command (m for help): n</div><div class="line">Command action</div><div class="line">    e   extended</div><div class="line">    p   primary partition (1-4)</div><div class="line">p</div><div class="line">Partition number (1-4): 3</div><div class="line">First cylinder (2089-6527, default 2089):   // 直接回车，用默认值就可以了</div><div class="line">Using default value 2089</div><div class="line">Last cylinder, +cylinders or +size&#123;K,M,G&#125; (2089-6527, default 6527):    // 直接回车，用默认值就可以了</div><div class="line">Using default value 6527</div><div class="line">Command (m for help): w</div><div class="line">The partition table has been altered!</div><div class="line"></div><div class="line"># 可以看到新建的分区sda3已结被创建出来了，采取默认值会将剩余所有空间都分到分区中</div><div class="line">[root@tony-play ~]# lsblk</div><div class="line">NAME                           MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</div><div class="line">sr0                             11:0    1 1024M  0 rom  </div><div class="line">sda                              8:0    0   50G  0 disk </div><div class="line">├─sda1                           8:1    0  500M  0 part /boot</div><div class="line">├─sda2                           8:2    0 15.5G  0 part </div><div class="line">│ ├─vg_tonyplay-lv_root (dm-0) 253:0    0 13.9G  0 lvm  /</div><div class="line">│ └─vg_tonyplay-lv_swap (dm-1) 253:1    0  1.6G  0 lvm  [SWAP]</div><div class="line">└─sda3                           8:3    0   34G  0 part</div></pre></td></tr></table></figure><h2 id="查看当前文件系统"><a href="#查看当前文件系统" class="headerlink" title="查看当前文件系统"></a>查看当前文件系统</h2><p>当前文件系统为<code>ext4</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@tony-play ~]# mount</div><div class="line">/dev/mapper/vg_tonyplay-lv_root on / type ext4 (rw)</div><div class="line">proc on /proc type proc (rw)</div><div class="line">sysfs on /sys type sysfs (rw)</div><div class="line">devpts on /dev/pts type devpts (rw,gid=5,mode=620)</div><div class="line">tmpfs on /dev/shm type tmpfs (rw,rootcontext=&quot;system_u:object_r:tmpfs_t:s0&quot;)</div><div class="line">/dev/sda1 on /boot type ext4 (rw)</div><div class="line">none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)</div></pre></td></tr></table></figure><h2 id="为新分区创建文件系统"><a href="#为新分区创建文件系统" class="headerlink" title="为新分区创建文件系统"></a>为新分区创建文件系统</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">[root@tony-play ~]# sudo mkfs.ext4 /dev/sda3</div><div class="line">mke2fs 1.41.12 (17-May-2010)</div><div class="line">Filesystem label=</div><div class="line">OS type: Linux</div><div class="line">Block size=4096 (log=2)</div><div class="line">Fragment size=4096 (log=2)</div><div class="line">Stride=0 blocks, Stripe width=0 blocks</div><div class="line">2228224 inodes, 8912727 blocks</div><div class="line">445636 blocks (5.00%) reserved for the super user</div><div class="line">First data block=0</div><div class="line">Maximum filesystem blocks=4294967296</div><div class="line">272 block groups</div><div class="line">32768 blocks per group, 32768 fragments per group</div><div class="line">8192 inodes per group</div><div class="line">Superblock backups stored on blocks: </div><div class="line">    32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, </div><div class="line">    4096000, 7962624</div><div class="line"></div><div class="line">Writing inode tables: done                            </div><div class="line">Creating journal (32768 blocks): done</div><div class="line">Writing superblocks and filesystem accounting information: done</div><div class="line"></div><div class="line">This filesystem will be automatically checked every 39 mounts or</div><div class="line">180 days, whichever comes first.  Use tune2fs -c or -i to override.</div></pre></td></tr></table></figure><h2 id="查看卷组信息"><a href="#查看卷组信息" class="headerlink" title="查看卷组信息"></a>查看卷组信息</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">[root@tony-play ~]# vgdisplay</div><div class="line">  --- Volume group ---</div><div class="line">  VG Name               vg_tonyplay     // 卷组名在下面扩展中会用到</div><div class="line">  System ID             </div><div class="line">  Format                lvm2</div><div class="line">  Metadata Areas        1</div><div class="line">  Metadata Sequence No  3</div><div class="line">  VG Access             read/write</div><div class="line">  VG Status             resizable</div><div class="line">  MAX LV                0</div><div class="line">  Cur LV                2</div><div class="line">  Open LV               2</div><div class="line">  Max PV                0</div><div class="line">  Cur PV                1</div><div class="line">  Act PV                1</div><div class="line">  VG Size               15.51 GiB</div><div class="line">  PE Size               4.00 MiB</div><div class="line">  Total PE              3970</div><div class="line">  Alloc PE / Size       3970 / 15.51 GiB</div><div class="line">  Free  PE / Size       0 / 0   </div><div class="line">  VG UUID               Y9usSM-nDU5-ZAUd-Y3Te-u5Pd-uFBr-gcYHf0</div></pre></td></tr></table></figure><h2 id="创建新物理卷"><a href="#创建新物理卷" class="headerlink" title="创建新物理卷"></a>创建新物理卷</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@tony-play ~]# pvcreate /dev/sda3</div><div class="line">  Physical volume &quot;/dev/sda3&quot; successfully created</div></pre></td></tr></table></figure><h2 id="扩展到卷组"><a href="#扩展到卷组" class="headerlink" title="扩展到卷组"></a>扩展到卷组</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">vgextend vg_tonyplay /dev/sda3  // 卷组名在查看卷组信息中</div><div class="line">  Volume group &quot;vg_tonyplay&quot; successfully extended</div></pre></td></tr></table></figure><h2 id="查看逻辑分区"><a href="#查看逻辑分区" class="headerlink" title="查看逻辑分区"></a>查看逻辑分区</h2><p><code>/dev/vg_tonyplay/lv_root</code>就是根分区，也是我们要扩展的分区。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">[root@tony-play ~]# lvdisplay </div><div class="line">  --- Logical volume ---</div><div class="line">    LV Path                /dev/vg_tonyplay/lv_root   // 根分区</div><div class="line">    LV Name                lv_root</div><div class="line">    VG Name                vg_tonyplay</div><div class="line">    LV UUID                IPd7lm-Sx8g-pe7k-llNL-j1wc-mbA2-2cAdsy</div><div class="line">    LV Write Access        read/write</div><div class="line">    LV Creation host, time tony-play, 2017-04-10 17:58:53 -0400</div><div class="line">    LV Status              available</div><div class="line">    # open                 1</div><div class="line">    LV Size                13.91 GiB</div><div class="line">    Current LE             3561</div><div class="line">    Segments               1</div><div class="line">    Allocation             inherit</div><div class="line">    Read ahead sectors     auto</div><div class="line">    - currently set to     256</div><div class="line">    Block device           253:0</div><div class="line"></div><div class="line">    --- Logical volume ---</div><div class="line">    LV Path                /dev/vg_tonyplay/lv_swap</div><div class="line">    LV Name                lv_swap</div><div class="line">    VG Name                vg_tonyplay</div><div class="line">    LV UUID                qX637q-iD6i-8blp-hmmS-MvLy-xZ0y-b4D0BF</div><div class="line">    LV Write Access        read/write</div><div class="line">    LV Creation host, time tony-play, 2017-04-10 17:59:07 -0400</div><div class="line">    LV Status              available</div><div class="line">    # open                 1</div><div class="line">    LV Size                1.60 GiB</div><div class="line">    Current LE             409</div><div class="line">    Segments               1</div><div class="line">    Allocation             inherit</div><div class="line">    Read ahead sectors     auto</div><div class="line">    - currently set to     256</div><div class="line">    Block device           253:1</div></pre></td></tr></table></figure><h2 id="扩展容量到逻辑分区"><a href="#扩展容量到逻辑分区" class="headerlink" title="扩展容量到逻辑分区"></a>扩展容量到逻辑分区</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@tony-play ~]# lvextend /dev/vg_tonyplay/lv_root /dev/sda3</div><div class="line">  Size of logical volume vg_tonyplay/lv_root changed from 13.91 GiB (3561 extents) to 47.91 GiB (12264 extents).</div><div class="line">  Logical volume lv_root successfully resized</div></pre></td></tr></table></figure><h2 id="刷新逻辑分区容量使扩展生效"><a href="#刷新逻辑分区容量使扩展生效" class="headerlink" title="刷新逻辑分区容量使扩展生效"></a>刷新逻辑分区容量使扩展生效</h2><p><code>ext4</code>用<code>resize2fs</code>，<code>xfs</code>用<code>xfs_growfs</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@tony-play ~]# resize2fs /dev/vg_tonyplay/lv_root</div><div class="line">resize2fs 1.41.12 (17-May-2010)</div><div class="line">Filesystem at /dev/vg_tonyplay/lv_root is mounted on /; on-line resizing required</div><div class="line">old desc_blocks = 1, new_desc_blocks = 3</div><div class="line">Performing an on-line resize of /dev/vg_tonyplay/lv_root to 12558336 (4k) blocks.</div><div class="line">The filesystem on /dev/vg_tonyplay/lv_root is now 12558336 blocks long.</div></pre></td></tr></table></figure><h2 id="查看逻辑分区容量"><a href="#查看逻辑分区容量" class="headerlink" title="查看逻辑分区容量"></a>查看逻辑分区容量</h2><p>可以发现<code>/dev/mapper/vg_tonyplay-lv_root</code>已经从开始的<code>14G</code>扩展到了<code>48G</code>。ok，这就说明大功告成了，再也不用通过重装系统这种蹩脚的方式扩容了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[root@tony-play ~]# df -h</div><div class="line">Filesystem            Size  Used Avail Use% Mounted on</div><div class="line">/dev/mapper/vg_tonyplay-lv_root</div><div class="line">                       48G  3.4G   42G   8% /</div><div class="line">tmpfs                 1.9G   72K  1.9G   1% /dev/shm</div><div class="line">/dev/sda1             477M   42M  410M  10% /boot</div></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>至此，<code>lvm</code>扩容工作的过程应该是比较清楚了，之后有机会的话我会再补充一下<code>LVM</code>的压缩、删除等操作过程。</p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/work-for-love-600x450.png&quot; alt=&quot;LVM Space Expansion&quot;&gt;&lt;/center&gt;

&lt;p&gt;在平时的开发工作中，经常会创建磁盘不足够大的虚拟机，然后往集群里面写一些数据导致磁盘满了。手动编辑虚拟机的磁盘大小是不会文件系统识别的，大多数同学只能无奈的重新装&lt;code&gt;OS&lt;/code&gt;，这里我介绍一种基于&lt;code&gt;LVM&lt;/code&gt;实现动态的方式。&lt;/p&gt;
    
    </summary>
    
      <category term="tech" scheme="https://tony-yin.github.io/categories/tech/"/>
    
    
      <category term="Ceph" scheme="https://tony-yin.github.io/tags/Ceph/"/>
    
      <category term="Linux" scheme="https://tony-yin.github.io/tags/Linux/"/>
    
      <category term="LVM" scheme="https://tony-yin.github.io/tags/LVM/"/>
    
  </entry>
  
  <entry>
    <title>Ceph 编译（Giant版本）</title>
    <link href="https://tony-yin.github.io/2017/11/14/Ceph-Compile/"/>
    <id>https://tony-yin.github.io/2017/11/14/Ceph-Compile/</id>
    <published>2017-11-14T01:30:29.000Z</published>
    <updated>2017-11-30T03:09:12.602Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/ceph-600x450.png" alt="Ceph Compile"></center><p>如今入门<code>Ceph</code>的时候，大家一般用<code>ceph-deploy</code>工具比较多，这个工具的确很强大，很方便，对应的也就是很无脑。如果之后想深入<code>Ceph</code>或者想在生产环境中部署<code>Ceph</code>的话，就得熟悉<code>Ceph</code>源码编译了。这对我们熟悉<code>Ceph</code>的<code>feature</code>的变化，<code>component</code>的相互关系以及围绕<code>Ceph</code>各种定制化扩展都大有裨益。本文就笔者<code>Ceph</code>源码编译过程和遇到的问题作出分享，希望有人能够得益于此。</p><a id="more"></a><h2 id="环境声明"><a href="#环境声明" class="headerlink" title="环境声明"></a>环境声明</h2><ul><li>OS： Centos 6.8</li><li>Ceph： Giant</li></ul><h2 id="源码下载"><a href="#源码下载" class="headerlink" title="源码下载"></a>源码下载</h2><h3 id="指定-giant-分支"><a href="#指定-giant-分支" class="headerlink" title="指定 giant 分支"></a>指定 giant 分支</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone -b giant git://github.com/ceph/ceph.git</div></pre></td></tr></table></figure><h3 id="下载子模块"><a href="#下载子模块" class="headerlink" title="下载子模块"></a>下载子模块</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git submodule update --init --recursive</div></pre></td></tr></table></figure><p>这一步我始终更新不了，尝试了一些办法未果，所以就去直接手动下载了源码，这个问题以后有时间看下</p><h2 id="预检"><a href="#预检" class="headerlink" title="预检"></a>预检</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cd ceph </div><div class="line">./autogen.sh </div><div class="line">./configure</div></pre></td></tr></table></figure><h3 id="Autogen"><a href="#Autogen" class="headerlink" title="Autogen"></a>Autogen</h3><p>这一步会频繁的报错一些<code>m4</code>文件没有，这需要我们手动创建这些<code>m4</code>文件夹即可，</p><p>一开始我在<code>ceph</code>根目录创建了<code>m4</code>文件夹，并生成了包括<code>acx_pthread.m4</code>在内的文件，但是还是报错：<code>acx_pthread.m4 not exist</code>，后来发现这时候已经<strong>切换目录</strong>了，不止一个地方需要<code>m4</code>文件夹，一共有这几个地方需要手动创建目录：<code>mkdir m4</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">./src/rocksdb/m4</div><div class="line">./src/gtest/m4</div><div class="line">./src/erasure-code/jerasure/jerasure/m4</div><div class="line">./src/erasure-code/jerasure/gf-complete/m4</div><div class="line">./m4</div></pre></td></tr></table></figure><p>如果还是报错一些文件不存在，并且通过上述方法不能自行初始化生成的话，可以从网上或者已经编译过的<code>ceph</code>环境拷贝过来</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">报错：umdefined macro</div></pre></td></tr></table></figure><p>下载地址：<a href="https://www.gnu.org/software/autoconf-archive/ax_check_classpath.html#ax_check_classpath" target="_blank" rel="external">https://www.gnu.org/software/autoconf-archive/ax_check_classpath.html#ax_check_classpath</a></p><h3 id="Configure"><a href="#Configure" class="headerlink" title="Configure"></a>Configure</h3><p>这一步是编译过程中可能出错的次数最多的，因为可能会因为你的环境缺少相应的包不断报错。不过数量虽多，解决起来还是比较容易的，就根据报错的缺包对应下载安装就好了，下面我先给出一个所有包的安装步骤，然后再针对每个报错环节给出具体的解决方案</p><h4 id="总体解决方案"><a href="#总体解决方案" class="headerlink" title="总体解决方案"></a>总体解决方案</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># 1. 通过yum安装所有可以安装的包</div><div class="line">yum install -y yasm libuuid-devel libblkid-devel libudev-devel cryptopp-devel fuse-devel libunwind-devel libedit-devel libatomic_ops-devel snappy-devel leveldb-devel libaio-devel xfsprogs-devel boost*</div><div class="line"></div><div class="line"># 2. 部分yum不能安装的可以通过rpm安装</div><div class="line">wget https://github.com/gperftools/gperftools/releases/download/gperftools-2.2.1/gperftools-2.2.1.tar.gz</div><div class="line">tar -zxvf gperftools-2.2.1.tar.g</div><div class="line">cd gperftools-2.2.1</div><div class="line">./configure</div><div class="line">make</div><div class="line">make install</div></pre></td></tr></table></figure><h4 id="具体解决方案"><a href="#具体解决方案" class="headerlink" title="具体解决方案"></a>具体解决方案</h4><p>1.yasm</p><p>报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yasm command not found</div></pre></td></tr></table></figure><p>解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install yasm -y</div></pre></td></tr></table></figure><p>2.libuuid</p><p>报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">configure: error: libuuid not found</div></pre></td></tr></table></figure><p>解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install libuuid-devel -y</div></pre></td></tr></table></figure><p>3.libblkid</p><p>报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">configure: error: blkid/blkid.h not found (libblkid-dev, libblkid-devel)</div></pre></td></tr></table></figure><p>解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install libblkid-devel -y</div></pre></td></tr></table></figure><p>4.libudev</p><p>报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">configure: error: libudev.h not found (libudev-dev, libudev-devel)</div></pre></td></tr></table></figure><p>解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install libudev-devel -y</div></pre></td></tr></table></figure><p>5.crypto</p><p>报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">configure: error: no suitable crypto library found</div></pre></td></tr></table></figure><p> 解决：</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install cryptopp-devel -y</div></pre></td></tr></table></figure><p> 6.fuse</p><p> 报错：</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">configure: error: no FUSE found (use --without-fuse to disable)</div></pre></td></tr></table></figure><p> 解决：</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install fuse-devel -y</div></pre></td></tr></table></figure><p> 7.tcmalloc</p><p> 报错：</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">configure: error: no tcmalloc found (use --without-tcmalloc to disable)</div></pre></td></tr></table></figure><p> 解决：</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># 1. 需要先安装libunwind-devel，被gperftools依赖</div><div class="line"> yum install libunwind-devel -y</div><div class="line"></div><div class="line"># 2. 安装tcmalloc（yum无法安装，需要通过rpm的方式）</div><div class="line">wget https://github.com/gperftools/gperftools/releases/download/gperftools-2.2.1/gperftools-2.2.1.tar.gz</div><div class="line">tar -zxvf gperftools-2.2.1.tar.g</div><div class="line">cd gperftools-2.2.1</div><div class="line">./configure</div><div class="line">make</div><div class="line">make install</div></pre></td></tr></table></figure><p>8.libedit</p><p>报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">configure: error: No usable version of libedit found.</div></pre></td></tr></table></figure><p>解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install  libedit-devel -y</div></pre></td></tr></table></figure><p>9.libatomic-ops</p><p>报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">configure: error: no libatomic-ops found (use --without-libatomic-ops to disable)</div></pre></td></tr></table></figure><p>解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install libatomic_ops-devel  -y</div></pre></td></tr></table></figure><p>10.libsnappy</p><p>报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">configure: error: libsnappy not found</div></pre></td></tr></table></figure><p>解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">yum install snappy-devel -y</div><div class="line"></div><div class="line">or </div><div class="line"></div><div class="line">wget ftp://195.220.108.108/linux/centos/6.9/os/x86_64/Packages/snappy-devel-1.1.0-1.el6.x86_64.rpm</div><div class="line">rpm -ivh snappy-devel-1.1.0-1.el6.x86_64.rpm</div></pre></td></tr></table></figure><p>11.libleveldb</p><p>报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">configure: error: libleveldb not found</div></pre></td></tr></table></figure><p>解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install leveldb-devel</div></pre></td></tr></table></figure><p>12.libaio</p><p>报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">configure: error: libaio not found</div></pre></td></tr></table></figure><p>解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install libaio-devel -y</div></pre></td></tr></table></figure><p>13.libxfs</p><p>报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">configure: error: xfs/xfs.h not found (--without-libxfs to disable)</div></pre></td></tr></table></figure><p>解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum -y install xfsprogs-devel</div></pre></td></tr></table></figure><p>14.boost</p><p>报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Can&apos;t find boost spirit headers</div></pre></td></tr></table></figure><p>解决：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install boost* -y</div></pre></td></tr></table></figure><h2 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h2><p>机器配置不好的话，编译需要时间比较长。可以使用<code>make -j</code>增加并发度，<code>4</code>表示同时执行的<code>make</code>方法数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">make -j4</div><div class="line">make install（可选）</div></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><code>ceph</code>手动源码编译遇到的问题还是蛮多的，如果不自己动手经历一下的话很多东西都不知道，当然这都是经验的积累，不断地锻炼自己解决问题的能力，要学会见招拆招，通过问题发现原理和本质。</p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/ceph-600x450.png&quot; alt=&quot;Ceph Compile&quot;&gt;&lt;/center&gt;

&lt;p&gt;如今入门&lt;code&gt;Ceph&lt;/code&gt;的时候，大家一般用&lt;code&gt;ceph-deploy&lt;/code&gt;工具比较多，这个工具的确很强大，很方便，对应的也就是很无脑。如果之后想深入&lt;code&gt;Ceph&lt;/code&gt;或者想在生产环境中部署&lt;code&gt;Ceph&lt;/code&gt;的话，就得熟悉&lt;code&gt;Ceph&lt;/code&gt;源码编译了。这对我们熟悉&lt;code&gt;Ceph&lt;/code&gt;的&lt;code&gt;feature&lt;/code&gt;的变化，&lt;code&gt;component&lt;/code&gt;的相互关系以及围绕&lt;code&gt;Ceph&lt;/code&gt;各种定制化扩展都大有裨益。本文就笔者&lt;code&gt;Ceph&lt;/code&gt;源码编译过程和遇到的问题作出分享，希望有人能够得益于此。&lt;/p&gt;
    
    </summary>
    
      <category term="tech" scheme="https://tony-yin.github.io/categories/tech/"/>
    
    
      <category term="Ceph" scheme="https://tony-yin.github.io/tags/Ceph/"/>
    
      <category term="编译" scheme="https://tony-yin.github.io/tags/%E7%BC%96%E8%AF%91/"/>
    
  </entry>
  
  <entry>
    <title>通过ganesha-nfs导出Ceph为NFS（Luminous）</title>
    <link href="https://tony-yin.github.io/2017/11/08/Ceph-NFS-Ganesha/"/>
    <id>https://tony-yin.github.io/2017/11/08/Ceph-NFS-Ganesha/</id>
    <published>2017-11-08T15:15:26.000Z</published>
    <updated>2017-11-30T03:09:29.197Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/ganesha-600x450.png" alt="ganesha"></center><p>自从<code>Jewel</code>版本，<code>nfs-ganesha</code>开始支持<code>ceph</code>，并且把对接点选择了<code>rados</code>。<code>Ganesha</code>支持两种方式将<code>Ceph</code>导出为<code>NFS</code>，一种通过<code>RGW</code>，一种通过<code>CephFS</code>，通过<code>FSAL</code>模块 连接到<code>RGW</code>或者<code>CephFS</code>， 其中，<code>FSAL_RGW</code>调用<code>librgw2</code>将<code>NFS</code>协议转义为<code>S3</code>协议再通过<code>RGW</code>存入到<code>Ceph</code>中，<code>FSAL_CEPH</code> 调用<code>libcephfs1</code>将<code>NFS</code>转义为<code>Cephfs</code>协议再存入到<code>Ceph</code> 中。所以需要额外安装这两个包。</p><p>本文就<code>Luminous</code>版本的<code>ceph</code>基于<code>ganesha</code>导出<code>nfs</code>部署，并且测试一下<code>rgw</code>和<code>cephfs</code>的性能。<a href="http://www.xuxiaopang.com/2017/03/27/ganesha-nfs-deploy/#more" target="_blank" rel="external">@徐小胖</a>已经就<code>jewel</code>版本的过程进行了大致的讲解，我这边主要分享一下我遇到他文章没提到的和<code>Luminous</code>场景导致的问题。</p><a id="more"></a><h2 id="参考链接："><a href="#参考链接：" class="headerlink" title="参考链接："></a>参考链接：</h2><ul><li><a href="http://www.xuxiaopang.com/2017/03/27/ganesha-nfs-deploy/#more" target="_blank" rel="external">通过ganesha-nfs将 Ceph 导出为 NFS</a></li><li><a href="http://blog.csdn.net/younger_china/article/details/73432726" target="_blank" rel="external">RGW+Ganesha环境部署</a></li></ul><h2 id="环境声明"><a href="#环境声明" class="headerlink" title="环境声明"></a>环境声明</h2><ul><li>os： centos7</li><li>ceph： luminous</li><li>nfs-gnesha： <strong>v2.5 stable</strong>（important）</li></ul><h2 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h2><p>一些编译需要的公共库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install gcc git cmake autoconf libtool bison flex doxygen openssl-devel gcc-c++ krb5-libs krb5-devel libuuid-devel nfs-utils -y</div></pre></td></tr></table></figure><p><code>ubuntu</code>的我也试了一下，主要有以下几个包不同：</p><ul><li><code>gcc-c++</code>   -&gt;   <code>g++</code></li><li><code>libuuid-devel</code> -&gt;  <code>uuid-dev</code></li><li><code>nfs-utils</code>   -&gt;  <code>nfs-kernel-server</code> </li></ul><p>如果要生成<code>FSAL_RGW</code>模块，需要安装<code>librgw2-devel</code>（我装的<code>librgw-devel</code>也可以<code>work</code>，看了<code>so</code>文件发现就是<code>2</code>，只是建立了映射关系，这个看了源码知道了是因为<code>K</code>版本对<code>librgw</code>编译这块做了升级，加了<code>2</code>标识一下）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install librgw2-devel -y</div></pre></td></tr></table></figure><p>如果要生成<code>FSAL_CEPH</code>模块，需要安装<code>libcephfs1-devel</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install libcephfs1-devel -y</div></pre></td></tr></table></figure><h2 id="源码下载"><a href="#源码下载" class="headerlink" title="源码下载"></a>源码下载</h2><p>上面两篇文章一个下载的是<code>v2.3 stable</code>，一个是<code>v2.4 stable</code>，两个我都试过，都会在<code>make</code>到<code>80%</code>左右的时候报错，应该是源码版本和库的版本有冲突导致的，这个问题耽误我挺长时间的，后来猜想可能是版本问题，尝试了一下<code>v2.5 stable</code>的源码就可以了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone -b V2.5-stable https://github.com/nfs-ganesha/nfs-ganesha.git --recursive</div></pre></td></tr></table></figure><p><strong>注意：（重要）</strong></p><p>最近我同事根据这篇文档部署<code>nfs-ganesha</code>的时候，发现之后<code>cmake</code>的操作后<code>USE_FSAL_RGW</code>始终是<code>OFF</code>的状态，一开始检查了一下环境发现<code>ganesha</code>是<code>v2.5</code>，然后<code>ceph</code>也是<code>L</code>版本，<code>centos</code>也是<code>7</code>。</p><p>报错如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">local RGW version is 1.1.4 not suitable match, but required latest RGW version is 1.1.6</div></pre></td></tr></table></figure><p>很好理解，就是我们安装的<code>RGW</code>达不到<code>nfs-ganesha</code>的要求，首先我们尝试去安装新的版本，但是<code>yum</code>的源已经配置了<code>luminous</code>，并且网上搜索了一圈并没有找到更新的。</p><p>ok，那就第二步，那就找原因同样的环境为啥我可以成功？而这位同事却不行？莫非因为我帅？不能这么逆天吧^_^ （明明可以靠脸吃饭，偏偏靠才华，哎……）</p><p>言归正传，通过报错信息查看源代码？定位到了报错文件<code>src/CMakeLists.txt</code>，然后代码中对<code>RGW</code>的版本要求也的确是<code>1.1.6</code>，回过头再看我之前下载下来的源代码，怪异的现象发生了，我代码中对<code>RGW</code>的版本要求只有<code>1.1.3</code>，此时我的第一反应就是应该这个文件被修改过导致两份代码不一样，出于本能直接上了<code>github</code>，果不其然，发现了<code>mattbenjamin</code>同学在<code>10</code>月<code>17</code>号在<code>v2.5</code>的分支上提交了一个<code>commit</code>针对<code>RGW</code>版本做出了修改！具体参看<a href="https://github.com/nfs-ganesha/nfs-ganesha/commit/8d039cd139ea1dcfbe316b7e93e96efe755669ef" target="_blank" rel="external">commit详情</a>，而这位贡献者几乎同时也在<code>ceph</code>提交了相关代码。这样想想就说得通了，我在搭建<code>nfs-ganesha</code>的时候恰好是在他提交之前的，所以我本地<code>RGW</code>本地版本是<code>1.1.4</code>是比要求版本<code>1.1.3</code>要高的，虽然不是完全<code>match</code>，但是也基本符合了要求，而我这位同事脸就比较黑了。。。</p><p>那该怎么解决这个问题呢？</p><p>有两种解决方案：</p><ol><li>手动编译<code>Luminous Ceph</code>把最新的<code>RGW</code>包编译出来，因为现在这个资源还没被公开分享出来；</li><li>克隆这个改动之前的代码</li></ol><p>这么看来第二种更为简单一些，我们也是采用的这种方式，<code>git clone v2.5 stable</code>后，然后<code>git checkout</code>恰当的版本号即可。</p><p><strong>总结：</strong></p><p>其实直接<code>clone</code>实时的代码这是不合理的，因为你不知道他什么时候会更新。正确的方式是我们应该找到稳定的<code>release</code>版本，<code>nfs-ganesha</code>也有提供<a href="https://github.com/nfs-ganesha/nfs-ganesha/releases" target="_blank" rel="external">一系列的release</a>，而我们通过查看<code>2.5 tree</code>上面的<code>commit</code>信息，可以知道<code>RGW</code>的改动是介于<code>2.5.3</code>和<code>2.5.4</code>之间的，所以我们下载<code>2.5.3</code>较为合适，下载地址在<a href="https://github.com/nfs-ganesha/nfs-ganesha/releases/tag/V2.5.3" target="_blank" rel="external">这里</a>。</p><p>这边还需要注意一个问题，这边<code>release</code>包下载下来你会发现<code>libntrirpc</code>这个文件夹没有内容，出现这个问题是因为<code>libntrirpc</code>对应的也是一个<code>git</code>仓库，我们需要去<a href="https://github.com/nfs-ganesha/nfs-ganesha/tree/next/src" target="_blank" rel="external">ntrirpc</a>手动克隆，然后通过<code>nfs-ganesha</code>的目录发现对<code>ntrirpc</code>的版本要求是<code>fadcbde</code>（这些都是上<code>github</code>可以看到的），我们需要做的就是在下载下来的<code>ntrirpc</code>目录下切到<code>fadcbde</code>这个<code>commit</code>上，并把当前的内容拷贝到<code>nfs-ganesha</code>的<code>libntrirpc</code>目录下。</p><p>实在搞不定的童鞋，我提供一个我克隆的<code>nfs-ganesha</code>的代码包，你们可以对比一下，这个我是可以成功部署的</p><p>附：我的<code>nfs-ganesha</code><a href="http://ovv1r40we.bkt.clouddn.com/nfs-ganesha.tar.gz" target="_blank" rel="external">下载地址</a></p><h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><p>编译<code>nfs-ganesha</code>， <strong>注意打开对应的模块：</strong></p><ul><li>如果需要生成<code>FSAL_RGW</code>模块，则在编译选项中添加： <code>-DUSE_FSAL_RGW=ON</code></li><li>如果需要生成<code>FSAL_CEPH</code>模块，则在编译选项中添加： <code>-DUSE_FSAL_CEPH=ON</code></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">cd src/</div><div class="line">mkdir build</div><div class="line">cd /build/</div><div class="line">cmake -DUSE_FSAL_RGW=ON -DUSE_FSAL_CEPH=ON ../</div></pre></td></tr></table></figure><p><code>cmake</code>的过程中会有以下输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">-- Looking for ceph_ll_lookup_root in cephfs - found</div><div class="line">-- Found cephfs libraries: /usr/lib64/libcephfs.so</div><div class="line">-- Found CEPHFS: /usr/include  </div><div class="line">-- Looking for rgw_mount in rgw</div><div class="line">-- Looking for rgw_mount in rgw - found</div><div class="line">-- Found rgw libraries: /usr/lib64/librgw.so</div><div class="line">-- Found RGW: /usr (found suitable version &quot;1.1&quot;, minimum required is &quot;1.1&quot;) </div><div class="line">...</div><div class="line">-- USE_FSAL_CEPH = ON</div><div class="line">-- USE_FSAL_CEPH_MKNOD = OFF</div><div class="line">-- USE_FSAL_CEPH_SETLK = OFF</div><div class="line">-- USE_FSAL_CEPH_LL_LOOKUP_ROOT = ON</div><div class="line">-- USE_FSAL_RGW = ON</div></pre></td></tr></table></figure><p>这一步，很重要，很多时候会因为没有装好的<code>librgw2-devel</code>或者<code>libcephfs1-devel</code>导致这边的<code>USE_FSAL_RGW</code>或者<code>USE_FSAL_CEPH</code>状态为<code>OFF</code></p><p><strong>确保，确保，确保：</strong> <code>-- USE_FSAL_CEPH</code>为<code>ON</code>，以及<code>-- USE_FSAL_RGW</code>为<code>ON</code>。</p><p>如果是<code>OFF</code>，请检查下<code>librgw2-devel</code>或者<code>libcephfs1-devel</code>是否有安装，如果这两个包都已经安装了，还显示为<code>OFF</code>， 可以尝试下清空编译目录：<code>rm -rf build/*</code>，再进行编译，如果依旧为 <code>OFF</code>，可以尝试下删除所有的<code>Ceph</code>包，再重新<code>yum install ceph librgw2-devel libcephfs1-devel -y</code>。</p><p>编译和安装，在<code>build</code>目录下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">make</div><div class="line">make install</div></pre></td></tr></table></figure><blockquote><p>PS:<br>在<code>make install</code>生成的输出中，可以看到:</p><p>– Up-to-date: /usr/share/doc/ganesha/config_samples/rgw.conf<br>…<br>– Up-to-date: /usr/share/doc/ganesha/config_samples/ceph.conf</p><p>这两个文件就是配置将<code>RGW</code>和<code>CephFS</code>配置为<code>ganesha-nfs</code>的配置模板。</p></blockquote><h2 id="编辑配置文件"><a href="#编辑配置文件" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h2><p>注意<code>Path</code>后面的路径需要加引号，<code>rgw</code>替换成创建<code>S3</code>用户生成的用户信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">cat /etc/ganesha/ganesha.conf</div><div class="line">EXPORT</div><div class="line">&#123;</div><div class="line">        Export_ID=1;</div><div class="line">        Path = &quot;/&quot;;</div><div class="line">        Pseudo = /cephfs;</div><div class="line">        Access_Type = RW;</div><div class="line">        NFS_Protocols = 4;</div><div class="line">        Transport_Protocols = TCP;</div><div class="line">        FSAL &#123;</div><div class="line">                Name = CEPH;</div><div class="line">        &#125;</div><div class="line">&#125;</div><div class="line">EXPORT</div><div class="line">&#123;</div><div class="line">        Export_ID=2;</div><div class="line">        Path = &quot;/&quot;;</div><div class="line">        Pseudo = /rgw;</div><div class="line">        Access_Type = RW;</div><div class="line">        Squash = No_root_squash;</div><div class="line">        NFS_Protocols = 4;</div><div class="line">        Transport_Protocols = TCP;</div><div class="line">        FSAL &#123;</div><div class="line">                Name = RGW;</div><div class="line">                User_Id = &quot;admin&quot;;</div><div class="line">                Access_Key_Id =&quot;1MWH3LWM1BS4ZF4HN5IH&quot;;</div><div class="line">                Secret_Access_Key = &quot;cuObxYgtl1lJgqNxOIpENycVqXfxLxZ8z5IXDM0O&quot;;</div><div class="line">        &#125;</div><div class="line">&#125;</div><div class="line">RGW &#123;</div><div class="line">    ceph_conf = &quot;/etc/ceph/ceph.conf&quot;;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="启动-Ganesha"><a href="#启动-Ganesha" class="headerlink" title="启动 Ganesha"></a>启动 Ganesha</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ganesha.nfsd -f /etc/ganesha/ganesha.conf -L /var/log/nfs-ganesha.log -N NIV_DEBUG</div></pre></td></tr></table></figure><p>如果一切顺利，你应该可以看到<code>ganesha.nfsd</code> 进程在那，如果进程不在，那么查看<code>Log</code>，记得在启动进程前，关闭所有<code>CephX</code>配置。</p><p><strong>重要</strong>：<code>librgw init failed (-5)</code> 解决方法</p><p>报错内容如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">RGW-1 : nfs-ganesha-2232083[main] create_export :FSAL :CRIT :RGW module: librgw init failed (-5)</div><div class="line">RGW-1 : nfs-ganesha-2232083[main] mdcache_fsal_create_export :FSAL :MAJ :Failed to call create_export on underlying FSAL</div></pre></td></tr></table></figure><p>经过多次尝试，包括在<code>ganesha.conf</code>内添加<code>init_args</code>指定秘钥和<code>Ceph</code>的用户，<code>ganesha-nfs</code> 均无法启动，报的错如标题，解决方法就是关闭<code>CephX</code>，将<code>/etc/ceph/ceph.conf</code>内的三个 <code>cephx</code>改为<code>none</code>，然后重启<code>ceph-mon</code>，<code>ceph-osd</code>，<code>ceph-radosgw</code>，<code>ceph-mds</code> 进程，再启动<code>ganesha-nfs</code>，即可正常运行。</p><p><strong>需要注意的是：</strong></p><p>当你在当前节点上，关闭<code>cephx</code>后，你用<code>ceph -s</code>查看集群状态时，这时候会报错说明由于没有<code>auth</code>认证导致无法连接集群，所以我当时试了很久，尽管<code>nfs-ganesha</code>已经运行了，但是<code>mount</code>都没有成功<code>export</code>，查看<code>log</code>才发现原来在<code>init</code>配置的时候就失败了，导致这个问题的原因是我只关闭了一个节点的<code>cephx</code>，所以需要做的就是将集群内所有节点的<code>cephx</code>全部关闭，然后集群就可以正常访问了，并且<code>nfs-ganesha</code>也不会因为<code>cephx</code>导致加载配置出错</p><h2 id="Check-Export"><a href="#Check-Export" class="headerlink" title="Check Export"></a>Check Export</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node1 build]# showmount -e  </div><div class="line">Export list for node1:  </div><div class="line">/ (everyone)  </div><div class="line">/ (everyone)</div></pre></td></tr></table></figure><h2 id="挂载-NFS"><a href="#挂载-NFS" class="headerlink" title="挂载 NFS"></a>挂载 NFS</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@node1 mnt]# mount -t nfs4 192.168.1.1:/  /mnt/ceph/  </div><div class="line">root@node1 mnt]# ls ceph/*  </div><div class="line">ceph/cephfs:  </div><div class="line">test  </div><div class="line">   </div><div class="line">ceph/rgw:  </div><div class="line">my-new-bucket</div></pre></td></tr></table></figure><p>说明<code>CephFS</code>和<code>RGW</code>都已经正常对接。<br>如果，你所使用的<code>admin</code>用户名下有很多的桶，那么这些桶都会以<code>/mnt/rgw/xxbucket</code>的结构显示出来，如果你在<code>/mnt/rgw/</code>下建立的一个目录，那么就相当于通过<code>RGW</code>建立了一个桶，所以，你执行<code>touch /mnt/rgw/123</code>是会报错的，因为不符合<code>S3</code>的对象必须位于桶内的规定，简单点说，就是把<code>/mnt/rgw/</code>和<code>S3</code>的根目录一一对应即可。</p><p>同样，<code>CephFS</code>内的内容都会显示在<code>/mnt/cephfs/</code>目录下。可以开始愉快的玩耍了！！</p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/ganesha-600x450.png&quot; alt=&quot;ganesha&quot;&gt;&lt;/center&gt;

&lt;p&gt;自从&lt;code&gt;Jewel&lt;/code&gt;版本，&lt;code&gt;nfs-ganesha&lt;/code&gt;开始支持&lt;code&gt;ceph&lt;/code&gt;，并且把对接点选择了&lt;code&gt;rados&lt;/code&gt;。&lt;code&gt;Ganesha&lt;/code&gt;支持两种方式将&lt;code&gt;Ceph&lt;/code&gt;导出为&lt;code&gt;NFS&lt;/code&gt;，一种通过&lt;code&gt;RGW&lt;/code&gt;，一种通过&lt;code&gt;CephFS&lt;/code&gt;，通过&lt;code&gt;FSAL&lt;/code&gt;模块 连接到&lt;code&gt;RGW&lt;/code&gt;或者&lt;code&gt;CephFS&lt;/code&gt;， 其中，&lt;code&gt;FSAL_RGW&lt;/code&gt;调用&lt;code&gt;librgw2&lt;/code&gt;将&lt;code&gt;NFS&lt;/code&gt;协议转义为&lt;code&gt;S3&lt;/code&gt;协议再通过&lt;code&gt;RGW&lt;/code&gt;存入到&lt;code&gt;Ceph&lt;/code&gt;中，&lt;code&gt;FSAL_CEPH&lt;/code&gt; 调用&lt;code&gt;libcephfs1&lt;/code&gt;将&lt;code&gt;NFS&lt;/code&gt;转义为&lt;code&gt;Cephfs&lt;/code&gt;协议再存入到&lt;code&gt;Ceph&lt;/code&gt; 中。所以需要额外安装这两个包。&lt;/p&gt;
&lt;p&gt;本文就&lt;code&gt;Luminous&lt;/code&gt;版本的&lt;code&gt;ceph&lt;/code&gt;基于&lt;code&gt;ganesha&lt;/code&gt;导出&lt;code&gt;nfs&lt;/code&gt;部署，并且测试一下&lt;code&gt;rgw&lt;/code&gt;和&lt;code&gt;cephfs&lt;/code&gt;的性能。&lt;a href=&quot;http://www.xuxiaopang.com/2017/03/27/ganesha-nfs-deploy/#more&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;@徐小胖&lt;/a&gt;已经就&lt;code&gt;jewel&lt;/code&gt;版本的过程进行了大致的讲解，我这边主要分享一下我遇到他文章没提到的和&lt;code&gt;Luminous&lt;/code&gt;场景导致的问题。&lt;/p&gt;
    
    </summary>
    
      <category term="tech" scheme="https://tony-yin.github.io/categories/tech/"/>
    
    
      <category term="Ceph" scheme="https://tony-yin.github.io/tags/Ceph/"/>
    
      <category term="NFS-Ganesha" scheme="https://tony-yin.github.io/tags/NFS-Ganesha/"/>
    
      <category term="NFS" scheme="https://tony-yin.github.io/tags/NFS/"/>
    
      <category term="Luminous" scheme="https://tony-yin.github.io/tags/Luminous/"/>
    
  </entry>
  
  <entry>
    <title>RGW 安装和创建</title>
    <link href="https://tony-yin.github.io/2017/11/08/Ceph-RGW/"/>
    <id>https://tony-yin.github.io/2017/11/08/Ceph-RGW/</id>
    <published>2017-11-08T15:11:59.000Z</published>
    <updated>2017-11-30T03:09:45.077Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ow0mgad6r.bkt.clouddn.com/gateway-600x450.png" alt="Ceph RGW"></center><p>本文通过<code>ceph-deploy</code>安装和创建<code>RGW</code>，然后分别创建<code>S3</code>和<code>Swift</code>接口并提供了相应的方案。</p><p><code>Ceph RGW</code>基于<code>librados</code>，是为应用提供<code>RESTful</code>类型的对象存储接口。<code>RGW</code>提供两种类型的接口：</p><ul><li>S3：兼容<code>Amazon S3 RESTful API</code></li><li>Swift：兼容<code>OpenStack Swift API</code></li></ul><p><code>S3</code>和<code>Swift API</code>共享同一个命名空间，所以可以使用两种<code>API</code>访问相同的数据。</p><a id="more"></a><p>参考链接: <a href="http://blog.csdn.net/younger_china/article/details/73410918" target="_blank" rel="external">Ceph：创建RGW</a></p><h2 id="部署-RGW"><a href="#部署-RGW" class="headerlink" title="部署 RGW"></a>部署 RGW</h2><h3 id="进入-ceph-目录"><a href="#进入-ceph-目录" class="headerlink" title="进入 ceph 目录"></a>进入 ceph 目录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cd /etc/ceph</div></pre></td></tr></table></figure><h3 id="安装-ceph-object-gateway"><a href="#安装-ceph-object-gateway" class="headerlink" title="安装 ceph object gateway"></a>安装 ceph object gateway</h3><p>我这边是<code>node1</code>，根据<code>hostname</code>对号入座就行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ceph-deploy install --rgw node1</div></pre></td></tr></table></figure><h3 id="Gather-keys"><a href="#Gather-keys" class="headerlink" title="Gather keys"></a>Gather keys</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ceph-deploy gatherkeys node1</div></pre></td></tr></table></figure><h3 id="创建-rgw-实例"><a href="#创建-rgw-实例" class="headerlink" title="创建 rgw 实例"></a>创建 rgw 实例</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ceph-deploy rgw create node1</div></pre></td></tr></table></figure><h3 id="Ceph-CLI"><a href="#Ceph-CLI" class="headerlink" title="Ceph CLI"></a>Ceph CLI</h3><p><code>Ceph CLI</code>工具需要在管理员模式下运行，因此需要执行以下命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ceph-deploy admin node1</div></pre></td></tr></table></figure><h3 id="测试是否安装成功"><a href="#测试是否安装成功" class="headerlink" title="测试是否安装成功"></a>测试是否安装成功</h3><p>一旦<code>RGW</code>开始运行，就可以通过端口<code>7480</code>（如果没有修改的话）来访问。如：<br><code>http://node1:7480</code>，如果<code>RGW</code>运行正常，它应该返回类似的信息： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">This XML file does not appear to have any style information associated with it. The document tree is shown below.</div><div class="line">&lt;ListAllMyBucketsResult xmlns=&quot;http://s3.amazonaws.com/doc/2006-03-01/&quot;&gt;</div><div class="line">&lt;Owner&gt;</div><div class="line">&lt;ID&gt;anonymous&lt;/ID&gt;</div><div class="line">&lt;DisplayName/&gt;</div><div class="line">&lt;/Owner&gt;</div><div class="line">&lt;Buckets/&gt;</div><div class="line">&lt;/ListAllMyBucketsResult&gt;</div></pre></td></tr></table></figure><h2 id="创建-S3-用户"><a href="#创建-S3-用户" class="headerlink" title="创建 S3 用户"></a>创建 S3 用户</h2><p>想正常的访问<code>RGW</code>，需要创建相应的<code>RGW</code>用户，并赋予相应的权限，<code>radosgw-admin</code>命令实现了这些功能。</p><p>其中<code>keys</code>中的<code>user</code>，<code>access_key</code>和<code>secret_key</code>用于之后的<code>S3</code>接口访问确认</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line">[root@node1 ~]# radosgw-admin user create --uid=&quot;admin&quot; --display-name=&quot;First user&quot;</div><div class="line">2017-11-08 16:51:39.883217 7fb6868fac40  0 WARNING: detected a version of libcurl which contains a bug in curl_multi_wait(). enabling a workaround that may degrade performance slightly.</div><div class="line">&#123;</div><div class="line">    &quot;user_id&quot;: &quot;admin&quot;,</div><div class="line">    &quot;display_name&quot;: &quot;First user&quot;,</div><div class="line">    &quot;email&quot;: &quot;&quot;,</div><div class="line">    &quot;suspended&quot;: 0,</div><div class="line">    &quot;max_buckets&quot;: 1000,</div><div class="line">    &quot;auid&quot;: 0,</div><div class="line">    &quot;subusers&quot;: [],</div><div class="line">    &quot;keys&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;user&quot;: &quot;admin&quot;,</div><div class="line">            &quot;access_key&quot;: &quot;1MWH3LWM1BS4ZF4HN5IH&quot;,</div><div class="line">            &quot;secret_key&quot;: &quot;cuObxYgtl1lJgqNxOIpENycVqXfxLxZ8z5IXDM0O&quot;</div><div class="line">        &#125;</div><div class="line">    ],</div><div class="line">    &quot;swift_keys&quot;: [],</div><div class="line">    &quot;caps&quot;: [],</div><div class="line">    &quot;op_mask&quot;: &quot;read, write, delete&quot;,</div><div class="line">    &quot;default_placement&quot;: &quot;&quot;,</div><div class="line">    &quot;placement_tags&quot;: [],</div><div class="line">    &quot;bucket_quota&quot;: &#123;</div><div class="line">        &quot;enabled&quot;: false,</div><div class="line">        &quot;check_on_raw&quot;: false,</div><div class="line">        &quot;max_size&quot;: -1,</div><div class="line">        &quot;max_size_kb&quot;: 0,</div><div class="line">        &quot;max_objects&quot;: -1</div><div class="line">    &#125;,</div><div class="line">    &quot;user_quota&quot;: &#123;</div><div class="line">        &quot;enabled&quot;: false,</div><div class="line">        &quot;check_on_raw&quot;: false,</div><div class="line">        &quot;max_size&quot;: -1,</div><div class="line">        &quot;max_size_kb&quot;: 0,</div><div class="line">        &quot;max_objects&quot;: -1</div><div class="line">    &#125;,</div><div class="line">    &quot;temp_url_keys&quot;: [],</div><div class="line">    &quot;type&quot;: &quot;rgw&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="创建-Swift-用户"><a href="#创建-Swift-用户" class="headerlink" title="创建 Swift 用户"></a>创建 Swift 用户</h2><p><code>Swift</code>用户是作为子用户<code>subuser</code>被创建的，执行以下命令：</p><p>其中<code>swift_keys</code>中的<code>user</code>和<code>secret_key</code>用于之后的<code>swift</code>接口访问确认</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line">[root@node1 ~]# radosgw-admin subuser create --uid=admin --subuser=admin:swift --access=full</div><div class="line">2017-11-08 16:55:05.371174 7fb4cbfc2c40  0 WARNING: detected a version of libcurl which contains a bug in curl_multi_wait(). enabling a workaround that may degrade performance slightly.</div><div class="line">&#123;</div><div class="line">    &quot;user_id&quot;: &quot;admin&quot;,</div><div class="line">    &quot;display_name&quot;: &quot;First user&quot;,</div><div class="line">    &quot;email&quot;: &quot;&quot;,</div><div class="line">    &quot;suspended&quot;: 0,</div><div class="line">    &quot;max_buckets&quot;: 1000,</div><div class="line">    &quot;auid&quot;: 0,</div><div class="line">    &quot;subusers&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;id&quot;: &quot;admin:swift&quot;,</div><div class="line">            &quot;permissions&quot;: &quot;full-control&quot;</div><div class="line">        &#125;</div><div class="line">    ],</div><div class="line">    &quot;keys&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;user&quot;: &quot;admin&quot;,</div><div class="line">            &quot;access_key&quot;: &quot;1MWH3LWM1BS4ZF4HN5IH&quot;,</div><div class="line">            &quot;secret_key&quot;: &quot;cuObxYgtl1lJgqNxOIpENycVqXfxLxZ8z5IXDM0O&quot;</div><div class="line">        &#125;</div><div class="line">    ],</div><div class="line">    &quot;swift_keys&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;user&quot;: &quot;admin:swift&quot;,</div><div class="line">            &quot;secret_key&quot;: &quot;PKRXACd8Ysgx7MCTjd9gHnL3sdpJ2J6wsuy2IS0P&quot;</div><div class="line">        &#125;</div><div class="line">    ],</div><div class="line">    &quot;caps&quot;: [],</div><div class="line">    &quot;op_mask&quot;: &quot;read, write, delete&quot;,</div><div class="line">    &quot;default_placement&quot;: &quot;&quot;,</div><div class="line">    &quot;placement_tags&quot;: [],</div><div class="line">    &quot;bucket_quota&quot;: &#123;</div><div class="line">        &quot;enabled&quot;: false,</div><div class="line">        &quot;check_on_raw&quot;: false,</div><div class="line">        &quot;max_size&quot;: -1,</div><div class="line">        &quot;max_size_kb&quot;: 0,</div><div class="line">        &quot;max_objects&quot;: -1</div><div class="line">    &#125;,</div><div class="line">    &quot;user_quota&quot;: &#123;</div><div class="line">        &quot;enabled&quot;: false,</div><div class="line">        &quot;check_on_raw&quot;: false,</div><div class="line">        &quot;max_size&quot;: -1,</div><div class="line">        &quot;max_size_kb&quot;: 0,</div><div class="line">        &quot;max_objects&quot;: -1</div><div class="line">    &#125;,</div><div class="line">    &quot;temp_url_keys&quot;: [],</div><div class="line">    &quot;type&quot;: &quot;rgw&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="测试-S3-接口"><a href="#测试-S3-接口" class="headerlink" title="测试 S3 接口"></a>测试 S3 接口</h2><p>需要创建一个<code>python</code>测试脚本来测试<code>S3</code>访问。该脚本会连接<code>RGW</code>，创建一个<code>bucket</code>并打印输出所有的<code>bucket</code>。其中，变量<code>access_key</code>和<code>secret_access</code>的值，来自于创建<code>S3</code>用户命令时，<code>radosgw-admin</code>命令返回的<code>keys-&gt;access_key</code>和<code>keys-&gt;secret_key</code>。</p><h3 id="安装-python-boto库"><a href="#安装-python-boto库" class="headerlink" title="安装 python-boto库"></a>安装 python-boto库</h3><p>执行以下步骤，首先安装<code>python-boto</code>库，该库用于连接<code>S3</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install -y python-boto</div></pre></td></tr></table></figure><h3 id="创建脚本"><a href="#创建脚本" class="headerlink" title="创建脚本"></a>创建脚本</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/python  </div><div class="line"># -*- coding:utf-8 -*-  </div><div class="line"></div><div class="line">import boto.s3.connection  </div><div class="line">   </div><div class="line">access_key = &apos;1MWH3LWM1BS4ZF4HN5IH&apos;     </div><div class="line">secret_key =&apos;cuObxYgtl1lJgqNxOIpENycVqXfxLxZ8z5IXDM0O&apos;  </div><div class="line">conn = boto.connect_s3(  </div><div class="line">        aws_access_key_id=access_key,  </div><div class="line">        aws_secret_access_key=secret_key,  </div><div class="line">        host=&apos;&#123;hostname&#125;&apos;,port=&#123;port&#125;,  </div><div class="line">        is_secure=False,calling_format=boto.s3.connection.OrdinaryCallingFormat(),  </div><div class="line">        )  </div><div class="line">   </div><div class="line">bucket = conn.create_bucket(&apos;my-new-bucket&apos;)  </div><div class="line">for bucket in conn.get_all_buckets():  </div><div class="line">    print&quot;&#123;name&#125; &#123;created&#125;&quot;.format(  </div><div class="line">            name=bucket.name,  </div><div class="line">            created=bucket.creation_date,  </div><div class="line">            )</div></pre></td></tr></table></figure><p>需要将上面的<code>{hostname}</code>替换成对应的<code>hostname</code>或者<code>IP</code>,例如<code>192.168.1.1</code>；将<code>{port}</code>替换成<code>RGW</code>运行的端口，默认为<code>7480</code>；前者为字符串，后者为数字</p><h3 id="执行脚本测试"><a href="#执行脚本测试" class="headerlink" title="执行脚本测试"></a>执行脚本测试</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@node1 ceph]# python s3test.py </div><div class="line">my-new-bucket 2017-11-01T10:58:53.670Z</div></pre></td></tr></table></figure><h2 id="测试-Swift-接口"><a href="#测试-Swift-接口" class="headerlink" title="测试 Swift 接口"></a>测试 Swift 接口</h2><h3 id="安装相关软件包"><a href="#安装相关软件包" class="headerlink" title="安装相关软件包"></a>安装相关软件包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pip installpython-setuptools    </div><div class="line">pip installpython-swiftclient</div></pre></td></tr></table></figure><h3 id="命令行访问"><a href="#命令行访问" class="headerlink" title="命令行访问"></a>命令行访问</h3><p>替换<code>{ip}</code>，<code>{port}</code>和<code>{swift_secret_key}</code>，其中<code>{swift_secret_key}</code>为创建<code>Swift</code>用户时，<code>radosgw-admin</code>命令返回的<code>swift_keys-&gt;secret_key</code>的值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">swift -A http://&#123;ip&#125;:&#123;port&#125;/auth/1.0 -Utestuser:swift -K &apos;&#123;swift_secret_key&#125;&apos; list</div></pre></td></tr></table></figure><p>正常输出应该如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@node1 ceph]# swift -Ahttp://192.168.1.1:7480/auth/1.0 -U admin:swift -K &apos;PKRXACd8Ysgx7MCTjd9gHnL3sdpJ2J6wsuy2IS0P&apos; list  </div><div class="line">my-new-bucket</div></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p><code>ceph-deploy</code>命令，大大地简化了对<code>Ceph</code>集群和<code>RGW的</code>安装和配置，可以很快速的搭建测试环境，达到测试效果，但如果要在生产环境中应用的话，可能需要手动做一些配置就，不能完全依赖<code>ceph-deploy</code>了。</p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ow0mgad6r.bkt.clouddn.com/gateway-600x450.png&quot; alt=&quot;Ceph RGW&quot;&gt;&lt;/center&gt;

&lt;p&gt;本文通过&lt;code&gt;ceph-deploy&lt;/code&gt;安装和创建&lt;code&gt;RGW&lt;/code&gt;，然后分别创建&lt;code&gt;S3&lt;/code&gt;和&lt;code&gt;Swift&lt;/code&gt;接口并提供了相应的方案。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Ceph RGW&lt;/code&gt;基于&lt;code&gt;librados&lt;/code&gt;，是为应用提供&lt;code&gt;RESTful&lt;/code&gt;类型的对象存储接口。&lt;code&gt;RGW&lt;/code&gt;提供两种类型的接口：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;S3：兼容&lt;code&gt;Amazon S3 RESTful API&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Swift：兼容&lt;code&gt;OpenStack Swift API&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;S3&lt;/code&gt;和&lt;code&gt;Swift API&lt;/code&gt;共享同一个命名空间，所以可以使用两种&lt;code&gt;API&lt;/code&gt;访问相同的数据。&lt;/p&gt;
    
    </summary>
    
      <category term="tech" scheme="https://tony-yin.github.io/categories/tech/"/>
    
    
      <category term="Ceph" scheme="https://tony-yin.github.io/tags/Ceph/"/>
    
      <category term="RGW" scheme="https://tony-yin.github.io/tags/RGW/"/>
    
  </entry>
  
  <entry>
    <title>使用NFS挂载RBD</title>
    <link href="https://tony-yin.github.io/2017/10/31/RBD-Mount-NFS/"/>
    <id>https://tony-yin.github.io/2017/10/31/RBD-Mount-NFS/</id>
    <published>2017-10-31T14:45:25.000Z</published>
    <updated>2017-11-30T03:10:23.246Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ovv1r40we.bkt.clouddn.com/rbd-london-christmas-600x450.jpg" alt="RBD"></center><p><strong>具体场景</strong></p><ul><li>在<code>Server</code>端创建<code>RBD</code>块设备并挂载到某个目录，然后在<code>Client</code>端通过<code>NFS</code>将<code>Server</code>端之前说的目录再挂载到本地，就可以实现在客户端写文件通过<code>NFS</code>到<code>Server</code>端的块设备上</li><li>这波操作的目的是因为测试<code>EC</code>性能时，<code>Ceph</code>版本还是<code>Hammer</code>，<code>CephFS</code>不是很稳定，性能不行，所以想用<code>RBD</code>的方式取代，但是<code>Hammer</code>版本中<code>EC</code>是只支持<code>RGW</code>的，并不支持<code>CephFS</code>和<code>RBD</code>，至于这个场景具体流程之后会在其他文章分享</li><li>这波操作在之前<code>Ceph</code>的<code>Hammer</code>版本做过，这次是要在新版本<code>Luminous</code>上实践，由于遇到了很多问题，大部分都是新版本缘故引入的，故与大家分享</li></ul><blockquote><p>PS：<code>Luminous</code>新版本提供了新的<code>NFS</code>的处理方式，不再需要用这种老式的<code>RBD</code>的手段，之后也会在其他文章分享出来</p></blockquote><a id="more"></a><h2 id="Hammer版本"><a href="#Hammer版本" class="headerlink" title="Hammer版本"></a>Hammer版本</h2><p>操作步骤</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">1. 使用RBD方式导出NFS，步骤如下：</div><div class="line"></div><div class="line">1.1 create RBD block device image (size unit: MB)</div><div class="line"># rbd create --size 1024 ec-pool/test_image</div><div class="line"></div><div class="line">1.2 map RBD device</div><div class="line"># rbd map ec-pool/test_image</div><div class="line"></div><div class="line">[Optional] check mapped device</div><div class="line"># rbd showmapped</div><div class="line"></div><div class="line">1.3 create filesystem on the device</div><div class="line"># mkfs.ext4 /dev/rbd0</div><div class="line"></div><div class="line">1.4 mount it,</div><div class="line"># mkdir -p /vol/test_image</div><div class="line"># mount /dev/rbd0 /vol/test_image/</div><div class="line"></div><div class="line">1.5 export it, modify the /etc/exports</div><div class="line"># cat /etc/exports</div><div class="line">/vol/test_image *(rw,async,no_subtree_check,no_root_squash)</div><div class="line"># service nfs-kernel-server restart</div><div class="line"># exportfs -r</div><div class="line"></div><div class="line">1.6 check mount info for NFS server</div><div class="line"># showmount -e 192.168.1.167</div><div class="line"></div><div class="line">2. 在客户端以nfs方式mount上述导出的文件夹</div><div class="line"># mount -t nfs 192.168.1.167:/vol/test_image /mnt</div></pre></td></tr></table></figure><h2 id="Luminous版本"><a href="#Luminous版本" class="headerlink" title="Luminous版本"></a>Luminous版本</h2><h3 id="Create-RBD-image"><a href="#Create-RBD-image" class="headerlink" title="Create RBD image"></a>Create RBD image</h3><p>之前<code>EC Pool</code>只能为<code>RGW</code>服务 ，直到<code>Luminous</code>版本，<code>EC Pool</code>也可以应用在<code>RBD</code>和<code>CephFS</code>，并且增加了<code>data-pool</code>这样的新特性，具体请参考官网：<a href="http://docs.ceph.com/docs/luminous/rados/operations/erasure-code/#erasure-coding-with-overwrites" target="_blank" rel="external">http://docs.ceph.com/docs/luminous/rados/operations/erasure-code/#erasure-coding-with-overwrites</a></p><p>所以创建<code>image</code>的方式也有所改变</p><h4 id="Enable-ec-overwrites"><a href="#Enable-ec-overwrites" class="headerlink" title="Enable ec overwrites"></a>Enable ec overwrites</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ceph osd pool set ec_pool allow_ec_overwrites true</div></pre></td></tr></table></figure><h4 id="Create-pool-and-image"><a href="#Create-pool-and-image" class="headerlink" title="Create pool and image"></a>Create pool and image</h4><p>由于<code>EC</code>不支持<code>omap</code>，所以在<code>CephFS</code>或者<code>RBD</code>场景使用<code>EC</code>时，需要将<code>data</code>存在<code>EC Pool</code>中，将<code>metadata</code>存在<code>Replicated Pool</code>中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">// 创建pool</div><div class="line">ceph osd pool create ec-pool 12 12 erasure  // ec pool, store data</div><div class="line">ceph osd pool create md-pool 12 12 replicated   // replicated pool, store metadata</div><div class="line">ceph osd pool create ssd-pool 12 12 replicated  // replicated pool, used as cache pool</div><div class="line">// 创建image</div><div class="line">rbd create --size 1024 --data-pool ec-pool md-pool/test_image</div></pre></td></tr></table></figure><h3 id="Map-RBD"><a href="#Map-RBD" class="headerlink" title="Map RBD"></a>Map RBD</h3><p>这一步之前的操作是<code>rbd map ec-pool/test_image</code>，所以当前需要执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rbd map md-pool/test_image</div></pre></td></tr></table></figure><p>但是一直<code>timeout</code>，通过查看<code>dmesg</code>和网上资料发现是因为<code>linux kernel</code>版本太低，所以升级了一下内核到<code>4.3</code>版本之后就可以<code>work</code>了</p><p>升级内核版本请参考：</p><blockquote><ul><li><a href="http://www.jianshu.com/p/66a724a1f3af" target="_blank" rel="external">内核版本过低导致RBD Feature不支持</a></li><li><a href="http://xiaqunfeng.cc/2017/06/06/ceph-rbd-map-failed/" target="_blank" rel="external">RBD Feature</a></li></ul></blockquote><h3 id="Check-map"><a href="#Check-map" class="headerlink" title="Check map"></a>Check map</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rbd showmapped</div></pre></td></tr></table></figure><h3 id="Create-filesystem-on-RBD"><a href="#Create-filesystem-on-RBD" class="headerlink" title="Create filesystem on RBD"></a>Create filesystem on RBD</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mkfs.ext4 /dev/rbd0</div></pre></td></tr></table></figure><h3 id="Mount"><a href="#Mount" class="headerlink" title="Mount"></a>Mount</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir -p /vol/test_image</div><div class="line">mount /dev/rbd0 /vol/test_image/</div></pre></td></tr></table></figure><h3 id="Modify-export-for-nfs-on-server"><a href="#Modify-export-for-nfs-on-server" class="headerlink" title="Modify export for nfs on server"></a>Modify export for nfs on server</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">vim /etc/exports</div><div class="line">/vol/test_image *(rw,async,no_subtree_check,no_root_squash) // Modify it to /etc/exports</div></pre></td></tr></table></figure><h4 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h4><h5 id="Install-NFS-on-server-and-client"><a href="#Install-NFS-on-server-and-client" class="headerlink" title="Install NFS on server and client"></a>Install NFS on server and client</h5><p><code>Server</code>端执行一下操作</p><h5 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum -y install nfs-utils rpcbind</div></pre></td></tr></table></figure><h5 id="Start-service"><a href="#Start-service" class="headerlink" title="Start service"></a>Start service</h5><p><code>nfs</code>依赖<code>rpcbind</code>，所以必须先启动<code>rpcbind</code>，这很重要</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">service rpcbind start</div><div class="line">service nfs start</div><div class="line">exportfs -r</div></pre></td></tr></table></figure><h4 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h4><p>客户端也执行以上操作，假设客户端<code>ip</code>为<code>192.168.1.1</code>，服务端为<code>192.168.1.2</code></p><h5 id="Check-mount"><a href="#Check-mount" class="headerlink" title="Check mount"></a>Check mount</h5><p>查看是否可以挂载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">showmount -e 192.168.1.2</div></pre></td></tr></table></figure><h5 id="Mount-server-to-client"><a href="#Mount-server-to-client" class="headerlink" title="Mount server to client"></a>Mount server to client</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount -t nfs 192.168.1.2:/vol/test_image /mnt</div></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>遇到的主要问题</p><ul><li><code>EC Pool</code>创建<code>image</code>因为新版本改动</li><li><code>rbd map</code>因为<code>linux kernel</code>版本低</li><li><code>nfs</code>因为<code>nfs</code>在<code>rpcbind</code>前启动</li></ul><p>希望帮助大家尽量少些踩坑 ~~~</p><p>作者： Tony<br>日期： 2017-10-31 22:33</p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ovv1r40we.bkt.clouddn.com/rbd-london-christmas-600x450.jpg&quot; alt=&quot;RBD&quot;&gt;&lt;/center&gt;

&lt;p&gt;&lt;strong&gt;具体场景&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在&lt;code&gt;Server&lt;/code&gt;端创建&lt;code&gt;RBD&lt;/code&gt;块设备并挂载到某个目录，然后在&lt;code&gt;Client&lt;/code&gt;端通过&lt;code&gt;NFS&lt;/code&gt;将&lt;code&gt;Server&lt;/code&gt;端之前说的目录再挂载到本地，就可以实现在客户端写文件通过&lt;code&gt;NFS&lt;/code&gt;到&lt;code&gt;Server&lt;/code&gt;端的块设备上&lt;/li&gt;
&lt;li&gt;这波操作的目的是因为测试&lt;code&gt;EC&lt;/code&gt;性能时，&lt;code&gt;Ceph&lt;/code&gt;版本还是&lt;code&gt;Hammer&lt;/code&gt;，&lt;code&gt;CephFS&lt;/code&gt;不是很稳定，性能不行，所以想用&lt;code&gt;RBD&lt;/code&gt;的方式取代，但是&lt;code&gt;Hammer&lt;/code&gt;版本中&lt;code&gt;EC&lt;/code&gt;是只支持&lt;code&gt;RGW&lt;/code&gt;的，并不支持&lt;code&gt;CephFS&lt;/code&gt;和&lt;code&gt;RBD&lt;/code&gt;，至于这个场景具体流程之后会在其他文章分享&lt;/li&gt;
&lt;li&gt;这波操作在之前&lt;code&gt;Ceph&lt;/code&gt;的&lt;code&gt;Hammer&lt;/code&gt;版本做过，这次是要在新版本&lt;code&gt;Luminous&lt;/code&gt;上实践，由于遇到了很多问题，大部分都是新版本缘故引入的，故与大家分享&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;PS：&lt;code&gt;Luminous&lt;/code&gt;新版本提供了新的&lt;code&gt;NFS&lt;/code&gt;的处理方式，不再需要用这种老式的&lt;code&gt;RBD&lt;/code&gt;的手段，之后也会在其他文章分享出来&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="tech" scheme="https://tony-yin.github.io/categories/tech/"/>
    
    
      <category term="Ceph" scheme="https://tony-yin.github.io/tags/Ceph/"/>
    
      <category term="NFS" scheme="https://tony-yin.github.io/tags/NFS/"/>
    
      <category term="RBD" scheme="https://tony-yin.github.io/tags/RBD/"/>
    
  </entry>
  
  <entry>
    <title>Python Profiler</title>
    <link href="https://tony-yin.github.io/2017/10/10/Python-Profiler/"/>
    <id>https://tony-yin.github.io/2017/10/10/Python-Profiler/</id>
    <published>2017-10-10T13:46:24.000Z</published>
    <updated>2017-11-22T01:39:43.232Z</updated>
    
    <content type="html"><![CDATA[<center><img src="http://ovv1r40we.bkt.clouddn.com/publicenemyno1-600x400.png" alt="Python Profiler"></center><p><code>OSD</code>启用过程耗时较长，需要进行性能优化。期间通过<code>python profilers</code>对代码进行性能分析和数据统计，有坑，有收获，总而言之，这是一个不错的工具</p><a id="more"></a><h2 id="Profilers简介"><a href="#Profilers简介" class="headerlink" title="Profilers简介"></a>Profilers简介</h2><p><code>python profilers</code>内置的主要有三种<code>cprofile</code>, <code>profile</code>和<code>hotshot</code>,<code>cprofile</code>是基于<code>profile</code>之上做的扩展，性能要比后者好很多，所以我用的就是<code>cprofile</code></p><p>更详细的介绍可以查看官网，<code>python profilers</code>的好处在于不用看教程，只要看着官网简短的概述，就能掌握其使用方法</p><ul><li><a href="https://docs.python.org/2/library/profile.html" target="_blank" rel="external">Python Profile</a></li><li><a href="http://www.cnblogs.com/btchenguang/archive/2012/02/03/2337112.html" target="_blank" rel="external">关于Python Profilers性能分析器</a></li></ul><h2 id="Cprofile快速使用"><a href="#Cprofile快速使用" class="headerlink" title="Cprofile快速使用"></a>Cprofile快速使用</h2><h3 id="官网例子"><a href="#官网例子" class="headerlink" title="官网例子"></a>官网例子</h3><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> cProfile</div><div class="line"><span class="keyword">import</span> re</div><div class="line">cProfile.run(<span class="string">'re.compile("foo|bar")'</span>)</div></pre></td></tr></table></figure><h4 id="分析结果"><a href="#分析结果" class="headerlink" title="分析结果"></a>分析结果</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">197 function calls (192 primitive calls) in 0.002 seconds</div><div class="line">Ordered by: standard name</div><div class="line">ncalls  tottime  percall  cumtime  percall filename:lineno(function)</div><div class="line">     1    0.000    0.000    0.001    0.001 &lt;string&gt;:1(&lt;module&gt;)</div><div class="line">     1    0.000    0.000    0.001    0.001 re.py:212(compile)</div><div class="line">     1    0.000    0.000    0.001    0.001 re.py:268(_compile)</div><div class="line">     1    0.000    0.000    0.000    0.000 sre_compile.py:172(_compile_charset)</div><div class="line">     1    0.000    0.000    0.000    0.000 sre_compile.py:201(_optimize_charset)</div><div class="line">     4    0.000    0.000    0.000    0.000 sre_compile.py:25(_identityfunction)</div><div class="line">   3/1    0.000    0.000    0.000    0.000 sre_compile.py:33(_compile)</div></pre></td></tr></table></figure><h4 id="图解"><a href="#图解" class="headerlink" title="图解"></a>图解</h4><center><img src="http://images.cnblogs.com/cnblogs_com/btchenguang/201202/201202031502512968.png" alt="cprofile"></center><h2 id="Cprofile深入"><a href="#Cprofile深入" class="headerlink" title="Cprofile深入"></a>Cprofile深入</h2><p>上面的基本用法可以在脚本中测试某个语句或者函数，然后打印到控制台。<code>cprofile</code>也可以将结果输出到文件中，这是比较常见的做法，因为打印到控制台，第一不能保存结果，第二如果数据量多没法全部浏览，并且影响阅读效果。而放在文件中还可以对结果进行按需排序、筛选等操作</p><h3 id="输出文件"><a href="#输出文件" class="headerlink" title="输出文件"></a>输出文件</h3><ol><li>参数方式</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> cProfile</div><div class="line"><span class="keyword">import</span> re</div><div class="line">cProfile.run(<span class="string">'re.compile("foo|bar")'</span>, <span class="string">'restats'</span>)</div></pre></td></tr></table></figure><ol><li>CLI方式</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python -m cProfile [-o output_file] [-s sort_order] myscript.py</div></pre></td></tr></table></figure><h2 id="Cprofile优雅使用"><a href="#Cprofile优雅使用" class="headerlink" title="Cprofile优雅使用"></a>Cprofile优雅使用</h2><p>上述方式可以使得<code>cprofile</code>在一些测试环境中受用，但是在一些复杂的环境中不能很好的<code>work</code>。由于<code>cprofile</code>是根据<code>python</code>在每个事件中存放的<code>hook</code>进行性能分析，所以在<code>cprofile.run()</code>的时候，要保证他就是最上层，他是调用的源头。</p><p>但是实际场景中，我们经常会对一些<code>API</code>中的某个方法进行性能分析，如果在被调用处使用<code>cprofile</code>，会出现变量或者模块<code>undefined</code>的现象，模块不能识别还可以在<code>run</code>方法中引入，然后通过分号分隔，例如<code>cprofile.run(import re, re.compile(&quot;foo|bar&quot;))</code>，具体可以参考这篇文章：<a href="http://ju.outofmemory.cn/entry/46805" target="_blank" rel="external">Python Profile 工具性能分析</a></p><p>变量无法识别更是让人头疼，所以为了达到测试效果，你会不得不修改一些并不是很少量的源代码，并且测一个方法就要搞一次很麻烦。还有一些多进程或者跨机器的场景导致代码异步执行，这样<code>cprofile</code>更不能达到用户的需求</p><p>还好我们可以通过<code>python</code>装饰器的机制来做，这样既不用改动源代码，也可以很方便的切换函数分析</p><h3 id="装饰器接口"><a href="#装饰器接口" class="headerlink" title="装饰器接口"></a>装饰器接口</h3><p>这里要注意设置全局变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">export PROFILING=y</div></pre></td></tr></table></figure><p>接口定义：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> cProfile</div><div class="line"><span class="keyword">import</span> pstats</div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="comment"># 性能分析装饰器定义</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_cprofile</span><span class="params">(filename)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span><span class="params">(func)</span>:</span></div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">profiled_func</span><span class="params">(*args, **kwargs)</span>:</span></div><div class="line">            <span class="comment"># Flag for do profiling or not.</span></div><div class="line">            DO_PROF = os.getenv(<span class="string">"PROFILING"</span>)</div><div class="line">            <span class="keyword">if</span> DO_PROF:</div><div class="line">                profile = cProfile.Profile()</div><div class="line">                profile.enable()</div><div class="line">                result = func(*args, **kwargs)</div><div class="line">                profile.disable()</div><div class="line">                <span class="comment"># Sort stat by internal time.</span></div><div class="line">                sortby = <span class="string">"tottime"</span></div><div class="line">                ps = pstats.Stats(profile).sort_stats(sortby)</div><div class="line">                ps.dump_stats(filename)</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                result = func(*args, **kwargs)</div><div class="line">            <span class="keyword">return</span> result</div><div class="line">        <span class="keyword">return</span> profiled_func</div><div class="line">    <span class="keyword">return</span> wrapper</div></pre></td></tr></table></figure><h3 id="分析使用"><a href="#分析使用" class="headerlink" title="分析使用"></a>分析使用</h3><p>这时候只需要在调用的函数上面加一个装饰器即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@do_cprofile('filename')</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'hello world'</span></div></pre></td></tr></table></figure><h2 id="pstats分析工具"><a href="#pstats分析工具" class="headerlink" title="pstats分析工具"></a>pstats分析工具</h2><p><code>pstats</code>可以根据<code>cprofile</code>生成的文件进行排序、筛选等处理，呈现更主要的结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pstats</div><div class="line"> </div><div class="line"><span class="comment"># 创建Stats对象</span></div><div class="line">p = pstats.Stats(<span class="string">"result.out"</span>)</div><div class="line"> </div><div class="line"><span class="comment"># strip_dirs(): 去掉无关的路径信息</span></div><div class="line"><span class="comment"># sort_stats(): 排序，支持的方式和上述的一致</span></div><div class="line"><span class="comment"># print_stats(): 打印分析结果，可以指定打印前几行</span></div><div class="line"> </div><div class="line"><span class="comment"># 和直接运行cProfile.run("test()")的结果是一样的</span></div><div class="line">p.strip_dirs().sort_stats(<span class="number">-1</span>).print_stats()</div><div class="line"> </div><div class="line"><span class="comment"># 按照函数名排序，只打印前3行函数的信息, 参数还可为小数,表示前百分之几的函数信息 </span></div><div class="line">p.strip_dirs().sort_stats(<span class="string">"name"</span>).print_stats(<span class="number">3</span>)</div><div class="line"> </div><div class="line"><span class="comment"># 按照运行时间和函数名进行排序</span></div><div class="line">p.strip_dirs().sort_stats(<span class="string">"cumulative"</span>, <span class="string">"name"</span>).print_stats(<span class="number">0.5</span>)</div><div class="line"> </div><div class="line"><span class="comment"># 如果想知道有哪些函数调用了sum_num</span></div><div class="line">p.print_callers(<span class="number">0.5</span>, <span class="string">"sum_num"</span>)</div><div class="line"> </div><div class="line"><span class="comment"># 查看test()函数中调用了哪些函数</span></div><div class="line">p.print_callees(<span class="string">"test"</span>)</div></pre></td></tr></table></figure><p>上述代码摘自：<a href="http://xianglong.me/article/analysis-python-application-performance-using-cProfile/" target="_blank" rel="external">使用cProfile分析Python程序性能</a>，原文还提供了<code>pstats</code>命令行交互工具方式</p><h2 id="图形可视化"><a href="#图形可视化" class="headerlink" title="图形可视化"></a>图形可视化</h2><p>上面的命令行界面的确是有点反人类，不易一下子清晰地分析性能瓶颈，有很多图形可视化工具可以帮助我们生成简洁明了的图片</p><p>工具有：</p><ul><li>gprof2dot</li><li>vprof</li><li>RunSnakeRun</li><li>KCacheGrind &amp; pyprof2calltree</li></ul><p>最终我选择了<code>gprof2dot</code>，比较符合我的口味</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>我的机器是<code>ubuntu</code>，其他类型机器找对应方式，具体参考：<a href="https://github.com/jrfonseca/gprof2dot" target="_blank" rel="external">Github gprof2dot</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">apt-get install python graphviz</div><div class="line">pip install gprof2dot</div></pre></td></tr></table></figure><p>注意：</p><p>如果<code>pip</code>安装软件包报错：’Cannot fetch index base URL  <a href="http://pypi.python.org/simple/" target="_blank" rel="external">http://pypi.python.org/simple/</a>‘</p><p>解决办法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">1. windows下创建/%user%/pip/pop.ini，并添加以下内容。</div><div class="line">[global]  </div><div class="line">index-url=http://pypi.douban.com/simple/</div><div class="line">2. linux创建文件~/.pip/pip.conf，并添加一下内容。</div><div class="line">[global]  </div><div class="line">index-url=http://pypi.douban.com/simple/</div><div class="line">3. 再次使用pip安装相应的包即可。</div></pre></td></tr></table></figure><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>根据<code>cpofile</code>输出的文件生成图片，这边输出的文件名为<code>osd.out</code>，生成的图片名为<code>osd.png</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">gprof2dot -f pstats osd.out | dot -Tpng -o osd.png</div></pre></td></tr></table></figure><p>具体参考这篇文章：<a href="https://zhuanlan.zhihu.com/p/24495603/" target="_blank" rel="external">Python优化第一步: 性能分析实践</a>，写的很好，也很具体</p><h3 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h3><p>这是我进行性能分析产生的两张图</p><p>Picture 1：</p><center><img src="http://ovv1r40we.bkt.clouddn.com/enable_osd3.png" alt="enable_osd1"></center><p>Picture 2：</p><center><img src="http://ovv1r40we.bkt.clouddn.com/enable_osd3-2.png" alt="enable_osd2"></center><h2 id="继续深入"><a href="#继续深入" class="headerlink" title="继续深入"></a>继续深入</h2><ul><li><code>pstats</code>深入了解</li><li><code>gprof2dot</code>深入了解</li><li>其他的可视化工具</li></ul><p>不过最终的目的都是通过性能分析找到性能瓶颈，然后进行优化，适合自己的就好</p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;img src=&quot;http://ovv1r40we.bkt.clouddn.com/publicenemyno1-600x400.png&quot; alt=&quot;Python Profiler&quot;&gt;&lt;/center&gt;

&lt;p&gt;&lt;code&gt;OSD&lt;/code&gt;启用过程耗时较长，需要进行性能优化。期间通过&lt;code&gt;python profilers&lt;/code&gt;对代码进行性能分析和数据统计，有坑，有收获，总而言之，这是一个不错的工具&lt;/p&gt;
    
    </summary>
    
      <category term="tech" scheme="https://tony-yin.github.io/categories/tech/"/>
    
    
      <category term="Profile" scheme="https://tony-yin.github.io/tags/Profile/"/>
    
      <category term="Python" scheme="https://tony-yin.github.io/tags/Python/"/>
    
      <category term="性能优化" scheme="https://tony-yin.github.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
</feed>
